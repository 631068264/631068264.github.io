---
layout:     post
rewards: false
title:      Hadoop
categories:
    - big data
tags:
    - big data
---

# HDFS

Hadoop Distributed File System (HDFS)

旨在存储大量信息，通常为**PB**。

**块结构文件系统**来完成的。单个文件被拆分为固定大小的块，这些块存储在集群上。由多个块组成的文件通常不会将所有块存储在同一台机器上。
为了确保可靠性，块在集群中存在副本。复制因子默认是3，每个块在集群中存在3份。

- NameNote 保存文件系统的元数据
- DataNode 存储组成文件的块

NameNode和DataNode进程可以在一台机器上运行，但HDFS集群通常由运行NameNode进程的专用服务器和可能有数千台运行DataNode进程的计算机组成。

- [snakebite](https://github.com/spotify/snakebite)
- [pyarrow](https://arrow.apache.org/docs/python/)


## NameNode
metadata 包括 文件名，文件权限以及每个文件的每个块的位置。保存在**内存**。
NameNode还跟踪块的**复制因子**，确保机器故障不会导致数据丢失。

由于NameNode是单点故障，因此可以使用辅助NameNode生成主NameNode内存结构的快照，从而降低NameNode失败时数据丢失的风险。
当DataNode失败时，NameNode将复制丢失的块以确保每个块满足最小**复制因子**。

### FsImage EditLog
![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0irtroc0tj317w0ow7cg.jpg)

![](https://ws4.sinaimg.cn/large/006tKfTcgy1g0irxawi8uj31o30u0hdt.jpg)

## SecondNameNode
- 解决EditLog变大，启动慢的问题
> **SecondNameNode** 每隔一段时间**拉取**和**合并**NameNode里的FsImage
> EditLog，这段时间的更新写入到NameNode的EditLog.
> **new合并结束后**,新FsImage发送到NameNode覆盖旧的FsImage，EditLog.new覆盖EditLog

![](https://ws4.sinaimg.cn/large/006tKfTcgy1g0isdlnamvj30yx0u0kfk.jpg)

- 如果NameNode在合并时间段内发生故障，系统会丢数据。



## DataNote

![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0isgoq1osj31bm092468.jpg)

## 读过程
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0isk52mmxj31f209u7cw.jpg)
DataNode列表根据与客户端的**距离**排序
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0iswsz0qzj31f00bodpc.jpg)

## 写过程

![](https://i.loli.net/2019/03/05/5c7e4d8f0f5ea.png)
![](https://i.loli.net/2019/03/05/5c7e4e574bb2f.png)
![](https://i.loli.net/2019/03/05/5c7e7c729cfca.png)

复制流程
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0iswa7qh8j315z0u04qp.jpg)
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0isuhsx4qj31g00liasj.jpg)
数据接收者会向发送者发送**确认包**

## 恢复数据

### NameNode
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0isyx0pekj31g40eqgz4.jpg)

### DataNode
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0it03w47rj31fy0e07gj.jpg)

### 数据
MD5 sha1
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0it1eolexj31ge0ac11v.jpg)

## 局限
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0isngzwnrj31f80g8gxg.jpg)

# YARN

https://www.ibm.com/developerworks/cn/data/library/bd-yarn-intro/index.html

## 局限性
经典 MapReduce 的最严重的限制主要关系到可伸缩性、资源利用和对与 MapReduce 不同的工作负载的支持。在 MapReduce 框架中，作业执行受两种类型的进程控制：

一个称为 JobTracker 的主要进程，它协调在集群上运行的所有作业，分配要在 TaskTracker 上运行的 map 和 reduce 任务。
许多称为 TaskTracker 的下级进程，它们运行分配的任务并定期向 JobTracker 报告进度。


- 单个 JobTracker 导致的可伸缩性瓶颈
- Hadoop 设计为仅运行 MapReduce 作业。随着替代性的编程模型（比如 Apache Giraph 所提供的图形处理）的到来，
除 MapReduce 外，越来越需要为可通过高效的、公平的方式在同一个集群上运行并共享资源的其他编程模型提供支持。

## 改变
我们减少了单个 JobTracker 的职责，将部分职责委派给 TaskTracker，因为集群中有许多 TaskTracker。
在新设计中，这个概念通过将 JobTracker 的双重职责（集群资源管理和任务协调）分开为两种不同类型的进程来反映。

不再拥有单个 JobTracker，一种新方法引入了一个集群管理器，它惟一的职责就是跟踪集群中的活动节点和可用资源，并将它们分配给任务。
对于提交给集群的每个作业，会启动一个专用的、短暂的 JobTracker 来控制该作业中的任务的执行。有趣的是，短暂的 JobTracker 由在从属节点上运行的 TaskTracker 启动。
因此，作业的生命周期的协调工作分散在集群中所有可用的机器上。得益于这种行为，更多工作可并行运行，可伸缩性得到了显著提高。

## yarn
（资源管理，任务调度，任务监控）
- ResourceManager 代替集群管理器 **资源管理**
- ApplicationMaster 代替一个专用且短暂的 JobTracker **任务调度，任务监控**
- NodeManager 代替 TaskTracker
- 一个分布式应用程序代替一个 MapReduce 作业
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0jsw3syxpj311i0qmws5.jpg)
![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0jswj8u2tj31gy0lewp6.jpg)

在 YARN 架构中，一个全局 ResourceManager 以主要后台进程的形式运行，它通常在专用机器上运行，在各种竞争的应用程序之间仲裁可用的集群资源。
ResourceManager 会追踪集群中有多少可用的活动节点和资源，协调用户提交的哪些应用程序应该在何时获取这些资源。
ResourceManager 是惟一拥有此信息的进程，所以它可通过某种共享的、安全的、多租户的方式制定分配（或者调度）决策（例如，依据应用程序优先级、队列容量、ACLs、数据位置等）。

在用户提交一个应用程序时，一个称为 ApplicationMaster 的轻量型进程实例会启动来协调应用程序内的所有任务的执行。
这包括监视任务，重新启动失败的任务，推测性地运行缓慢的任务，以及计算应用程序计数器值的总和。
这些职责以前分配给所有作业的单个 JobTracker。
ApplicationMaster 和属于它的应用程序的任务，在受 NodeManager 控制的资源容器中运行。

NodeManager 是 TaskTracker 的一种更加普通和高效的版本。没有固定数量的 map 和 reduce slots，
NodeManager 拥有许多动态创建的资源容器。容器的大小取决于它所包含的资源量，比如内存、CPU、磁盘和网络 IO。目前，仅支持内存和 CPU (YARN-3)。
未来可使用 cgroups 来控制磁盘和网络 IO。一个节点上的容器数量，由配置参数与专用于从属后台进程和操作系统的资源以外的节点资源总量（比如总 CPU 数和总内存）共同决定。

有趣的是，ApplicationMaster 可在容器内运行任何类型的任务。例如，MapReduce ApplicationMaster 请求一个容器来启动 map 或 reduce 任务，而 Giraph ApplicationMaster 请求一个容器来运行 Giraph 任务。您还可以实现一个自定义的 ApplicationMaster 来运行特定的任务，进而发明出一种全新的分布式应用程序框架，改变大数据世界的格局。您可以查阅 Apache Twill，它旨在简化 YARN 之上的分布式应用程序的编写。


### 一个可运行任何分布式应用程序的集群

ResourceManager、NodeManager 和容器都不关心应用程序或任务的类型。所有特定于应用程序框架的代码都转移到它的 ApplicationMaster，
以便任何分布式框架都可以受 YARN 支持 — 只要有人为它实现了**相应的 ApplicationMaster**。

- 向yarn提交应用程序
- ResourceManager接收处理客户端请求，为应用程序分配一个容器，与容器内NodeManager通信，启动ApplicationMaster。
- ApplicationMaster创建后向ResourceManager注册，ResourceManager可以了解应用程序状态。
- ApplicationMaster向ResourceManager申请资源，成功后，与容器内NodeManager通信，启动Tasks。
- Tasks通过RPC反馈状态到ApplicationMaster。Task失败会ApplicationMaster重启
- Tasks完成,ApplicationMaster向ResourceManager注销，关闭自己。ApplicationMaster失败会ResourceManager重启，知道task完成。


# MapReduce
- [mrjob](https://github.com/Yelp/mrjob)

## map
处理一堆键值对，`mapper`会顺序单独处理每个键值对，产生若干个output键值对

## shuffle sort
相当于根据key聚类

`mapper`运行完，mapper的输出传送到reducers的过程叫shuffle，每一个分类器确保来自同一个key的所有value**<key,value-list>**都发送同一个reducer。
默认根据mapper’s output key的hash值去分类。

到达reducers前，会对key和value进行排序。具有相同key值的数据聚合在一起。

## reduce
唯一key包含不唯一的值，reducer为每个唯一key合并它们的value,产生若干键值对

![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0e5g94fgmj31ia0mewhi.jpg)



# Pig
[pig online doc](https://pig.apache.org/docs/latest/index.html)
- 高级数据流语言 Pig Latin
- 运行Pig Latin程序的执行环境

Pig能够让你专心于数据及业务本身，而不是纠结于数据的格式转换以及MapReduce程序的编写。
![](https://ws4.sinaimg.cn/large/006tKfTcgy1g0jz6f0kp0j31gw0bk7fh.jpg)

## Execution Modes

### local
only requires a single machine. Pig will run on the local host and access the local filesystem.
`pig -x local ...`

### MapReduce
`pig ...`

## Interactive Mode
Pig can be run interactively in the Grunt shell. 
```
pig -x local
...
grunt>
```

## Batch Mode
use pig script
`pig -x local id.pig`

## pig 语法
Each statement is an operator that takes a relation as an input, performs a transformation on that relation,
and produces a relation as an out‐ put. Statements can span multiple lines,`;`结尾。

- A LOAD statement that reads the data from the filesystem
- One or more statements to transform the data
- A DUMP or STORE statement to view or store the results

### load
USING default keyword `\t` 
AS default not named and type bytearray
```pig
LOAD 'data' [USING function] [AS schema];
```

```pig
A = LOAD 'students' AS (name:chararray, age:int);
DUMP A; 

(john,21,3.89) 
(sally,19,2.56) 
(alice,22,3.76) 
(doug,19,1.98) 
(susan,26,3.25)
```

### Transforming Data
条件关系 and or not

#### FILTER
处理列
```
A = LOAD 'students' AS (name:chararray, age:int, gpa:float);

DUMP A; 
(john,21,3.89)
(sally,19,2.56) 
(alice,22,3.76)
(doug,19,1.98)
(susan,26,3.25)

R = FILTER A BY age>=20;
DUMP R; 

(john,21,3.89) 
(alice,22,3.76) 
(susan,26,3.25)
```
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0egcywet8j30zu09m3yr.jpg)

#### FOREACH
处理行 有点像select

```
R = FOREACH A GENERATE *;
```
![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0eghch92lj30ek0bidg5.jpg)

![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0egi7gevyj31hw0imaav.jpg)

#### GROUP
```
B = GROUP A BY age;
```
![](https://ws4.sinaimg.cn/large/006tKfTcgy1g0egkxb7cpj31h60jswfo.jpg)

![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0ehjnt6a6j31hg0jujsk.jpg)

#### STORE

```
STORE alias INTO 'directory' [USING function];
```

```
A = LOAD 'students' AS (name:chararray, age:int, gpa:float);
STORE A INTO 'output' USING PigStore('|');
CAT output;
```
![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0ehsqlwbwj318b0u0wg2.jpg)


## UDF

[pig_util](https://github.com/apache/pig/tree/trunk/src/python/streaming)
```python
from pig.pig_util import outputSchema


@outputSchema('word:chararray')
def reverse(word):
    """
    Return the reverse text of the provided word """
    return word[::-1]


@outputSchema('length:int')
def num_chars(word):
    """
    Return the length of the provided word """
    return len(word)
```
```
REGISTER 'my_udf.py' USING streaming_python AS string_udf;
term_length = FOREACH unique_terms GENERATE word, string_udf.num_chars(word) as length;
```

# Hive

[Hive](/blog/2019/03/03/hive/)

# HBase


## 数据模型概念
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0j0kby1r1j31sw0u07wh.jpg)
![](https://ws4.sinaimg.cn/large/006tKfTcgy1g0iufa0m5hj30ls0euq7x.jpg)
![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0j0ofjbh9j31u80gyqfm.jpg)

### 表

![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0j036smpmj31ai04g771.jpg)

### 行

![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0j063g65gj31w40dutlm.jpg)

### 列族

![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0j08zji2tj31e00u04qp.jpg)

### 限定字符

![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0j0cbtd0uj31ti04ydk6.jpg)

### 单元格

![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0j0davtrdj31ss07cdme.jpg)

### 时间戳

![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0j0emqp1jj31tc0c2tlj.jpg)

## 列族存储

<span class='gp-2'>
    <img src='https://ws2.sinaimg.cn/large/006tKfTcgy1g0j0vyl9z4j31tc0o27hu.jpg' />
    <img src='https://ws4.sinaimg.cn/large/006tKfTcgy1g0j0xh0892j31460u0b29.jpg' />
</span>

![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0j10j0m8lj31ti0gitpj.jpg)

- 降低IO
- 大并发查询
- 高数据压缩比

## 架构
与Hadoop访问过程，结构有点像
![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0j1b6nlxdj31v40t84qp.jpg)
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0j27rn5jmj316g0owwrb.jpg)

###  zookeeper
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0j2e19djxj31dl0u0nof.jpg)

### master
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0j2k466laj31g00p0dzp.jpg)

### region
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0j2l8eelij31ie0dm14t.jpg)

#### 表 Region

![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0j1frorkej31f80u04qp.jpg)
![](https://ws4.sinaimg.cn/large/006tKfTcgy1g0j1ltajqij31uk0b0qcx.jpg)

#### Region 定位

![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0j1x3cpv4j31bc0u0no6.jpg)
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0j200u1u3j31260u01kx.jpg)
![](https://ws4.sinaimg.cn/large/006tKfTcgy1g0j22s6oo9j31800u0x51.jpg)

#### 结构
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0j2qvmpcij313l0u07v1.jpg)

**MemStore**容量有限，周期性写入到**StoreFile**,HLog写入一个标记。每次缓存刷新生成新的**StoreFile**，
当**StoreFile**数量到达某个阈值，会合并一个大**StoreFile**。当大**StoreFile**大小到达某个阈值，会分裂。
![](https://ws4.sinaimg.cn/large/006tKfTcgy1g0j3evboptj31gc0iiwqf.jpg)


![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0j3j6dkl4j31hc0n8avu.jpg)
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0j31qmnmcj31g609ith9.jpg)



#### 读写
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0j2rfgaj2j31gu084tf3.jpg)


## 局限
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0j16237y9j31uw0bwans.jpg)

# NoSQL
不需要事务，读写实时性，没有复杂SQL查询。

## 种类

![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0jl40p0b9j317u0u0nig.jpg)

# Spark

[Spark](/blog/2019/03/01/spark/)

# 流计算

- 静态数据 批量计算 时间充足批量处理海量数据
- 流数据 实时计算
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0l0c3ng4ij31kk0f0gsc.jpg)

## 流数据特征
![](https://ws2.sinaimg.cn/large/006tKfTcly1g0kzn90nq6j31z60g67hy.jpg)

## 实时采集
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0l0iquglqj31620u0e81.jpg)

## 实时计算
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0l0la1nw4j31zs0f6nad.jpg)

## 实时查询
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0l0nnadogj32080r41kx.jpg)

## Storm
![](https://ws4.sinaimg.cn/large/006tKfTcgy1g0l1wd0pygj31og0dok3c.jpg)
![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0l1wr0ns8j31mg08in4f.jpg)

- [streamparse](https://github.com/Parsely/streamparse)

### 基本组件
在Storm上实际上运行的是Topology

#### stream
无限Tuple序列
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0l25gbhzjj31ye0a47ee.jpg)

#### spouts
Tuple序列源头
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0l2789t0gj31y60iek5o.jpg)

#### bolts
处理Tuples ,创建stream。
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0l2955g4dj31yk0ouqkk.jpg)

#### Topology
spouts和bolts组成的网络抽象成Topology，组件之间沟通
![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0l3bj04hgj30ly0eoaax.jpg)

#### Stream Groups
告知Topology如何在两个组件之间进行Tuple传输。
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0l2l4brccj31ze0kmtr7.jpg)


### 架构
![](https://ws1.sinaimg.cn/large/006tKfTcgy1g0l2slgdavj31xy0kah7e.jpg)

Zookeeper作为分布式协调组件，负责Nimbus和多个supervisor之间的协调工作。
![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0l2zth5awj31y00oydve.jpg)

## Spark Streaming
将stream拆分成小量批处理, 做不到**毫秒级别**，**storm** 可以
![](https://ws2.sinaimg.cn/large/006tKfTcgy1g0l3u9pl8lj31y40r4e5z.jpg)

### 对比storm
做不到**毫秒级别**，**storm** 可以
![](https://ws3.sinaimg.cn/large/006tKfTcgy1g0l3xi6k1oj31xq0deh0q.jpg)

