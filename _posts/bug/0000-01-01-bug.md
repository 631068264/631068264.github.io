---
layout:     post
rewards: false
title:      目录章节显示不完整
categories:
    - bug
tags:
    - bug
---
# Bias-Variance Tradeoff
![](https://ws1.sinaimg.cn/large/006tNbRwly1fvlsl4yrwej31kw0aojt0.jpg)
- 方差  varinace

    代表我们使用不同训练集时模型表现的差异
    如果模型具有较大的方差，训练集只要有少许变化，模型会有很大的改变。复杂的模型一般具有更大的方差
- 偏差 bias

    代表实际模型与理想模型的差别

<span class='gp-2'>
    <img src='https://ws1.sinaimg.cn/large/006tNbRwgy1fvlsmh6znpj30x80pcdgh.jpg' />
    <img src='https://ws2.sinaimg.cn/large/006tNbRwgy1fvlsmabzqtj30su0kw74v.jpg' />
</span>

# 过拟合

## 主要原因
- noise
- 模型复杂度太高
- train-set too small

## 解决
- 数据清洗（错误数据的更正，或者删除）
- 简化模型
- 更多数据 （如果没有办法获得更多的训练集，对已知的样本进行简单的处理、变换，从而获得更多的样本）
- [regularization](#regularization)
- 减少特征
- [validation](#validation)

## 维度灾难
当模型很复杂的时候 ，复杂度本身就会引入一种**noise**，
所以即使高阶无noise，模型也不能很好泛化。

# 欠拟合
- 增加模型的迭代次数
- 生成更好特征供训练使用
- 降低正则化水平

# Regularization
正则化 给予model惩罚 **减低model复杂度**

# Validation
## 普通
set 分train and test => Modelargmin(E_test) => 得到model再用整体数据集训练 分量4:1

## Leave-One-Out

每次从数据集中取一个样本作为test-set，直到N个样本都作过验证集，共计算N次，最后对验证误差求平均

>计算量大
稳定性，例如对于二分类问题，取值只有0和1两种，预测本身存在不稳定的因素，那么对所有的Eloocv计算平均值可能会带来很大的数值跳动
所以Leave-One-Out方法在实际中并不常用

## V-Fold Cross Validation

Leave-One-Out是将N个数据分成N分，那么改进措施是将N个数据分成V份（例如V=10），计算过程与Leave-One-Out相似。这样可以减少总的计算量，又能进行交叉验证，这种方法称为V-折交叉验证。Leave-One-Out就是V-折交叉验证的一个极端例子

### example
cross_val_score K-fold cross-validation
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fvlwae5a39j31kw0twdkj.jpg)

```python
from sklearn.model_selection import cross_val_score
cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring="accuracy")
```

# 归一化
原始数据进行线性变换把数据映射到[0,1]
最大值与最小值非常容易受异常点影响，所以这种方法鲁棒性较差，只适合传统精确小数据场景。

$$\text{x'=}\frac{x-min}{max-min}$$

# 标准化
数据均值为0，标准差为1 其中μ是样本的均值，σ是样本的标准差 在已有样本足够多的情况下比较稳定，适合现代嘈杂大数据场景

$$x'=\frac{x-\mu}\sigma$$

如果想保留原始数据中由标准差所反映的潜在权重关系应该选择归一化

# 非线性变换
**用不太复杂的model 解决非线性问题**
通过非线性变换，将非线性模型映射到另一个空间，转换为线性模型，再来进行线性分类
- 特征转换
- 训练线性模型

例如
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fvep9slkq7j31bi0esdi0.jpg)

模型太复杂容易带来过拟合
![](https://ws4.sinaimg.cn/large/006tNbRwgy1fvep83x6wpj30ik0cymxk.jpg)
非线性变换可能会带来的一些问题：**时间复杂度和空间复杂度的增加**，尽可能使用简单的模型，而不是模型越复杂越好

# Loss
## 对数损失
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fw6yz3xo0sj313m11otbn.jpg)
## 回归 mse rmse
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fw6yztvrdgj312u0pggmq.jpg)
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fw6z057ku4j314m0tgmzk.jpg)
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fw6z0oqh57j311s0kmq4r.jpg)

# 二元分类
**数据不均衡有效**
Confusion Matrix 混淆矩阵
![](https://ws4.sinaimg.cn/large/006tNbRwgy1fvlwqmr86tj31kw0dx77y.jpg)
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fvlwfo7nbqj315o06wgmp.jpg)

```python
from sklearn.model_selection import cross_val_predict
y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)

instead of returning the evaluation scores, it returns the predic‐ tions made on each test fold

>>> from sklearn.metrics import confusion_matrix
>>> confusion_matrix(y_train_5, y_train_pred)
    array([[53272, 1307],
          [ 1077,  4344]])
          
row actual class
cloumn pridect class

            PN  PT
        AN  TN ,FP
        AP  FN,TP
best TN TP only
```

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fvlwu96c1uj31kw0u8wgc.jpg)
![](https://ws2.sinaimg.cn/large/006tNbRwgy1fvly0vrq5bj311a0rymz3.jpg)

## Precision
the accuracy of the positive predictions

$${precision\;=\;\frac{TP}{TP\;+\;FP}}$$

## Recall
truepositive rate
the ratio of positive instances that are correctly detected by the classifier

$$recall\;=\;\frac{TP}{TP\;+\;FN}$$

```python
>>> from sklearn.metrics import precision_score, recall_score
>>> precision_score(y_train_5, y_pred) # == 4344 / (4344 + 1307) 0.76871350203503808
>>> recall_score(y_train_5, y_train_pred) # == 4344 / (4344 + 1077) 0.79136690647482011
```

>不同情况关注点不一样
防小孩看到黄暴视频，分类器拒绝很多好的视频(low recall)，只保留最安全的(high precision)

## F score
![](https://ws2.sinaimg.cn/large/006tNbRwly1fvlx6iy1ccj313e08oweu.jpg)

```python
>>> from sklearn.metrics import f1_score >>> f1_score(y_train_5, y_pred) 0.78468208092485547
```

## threshold
find threshold for recall and precision
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fvlxmyhmdtj31kw0lrabo.jpg)

>lowering the threshold increases recall and reduces precision

```python
y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,
                                 method="decision_function")
```

```python
from sklearn.metrics import precision_recall_curve
precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)
```

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fvlxkyt105j31kw18e78n.jpg)
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fvlxlfm8foj31d20feq5p.jpg)
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fvlxlme5r7j31kw0wswfl.jpg)

## ROC Curve
The receiver operating characteristic (ROC) curve is another common tool used with binary classifiers

**ROC** similar to the precision/recall curve
**AUC** area under the ROC curve

```python
from sklearn.metrics import roc_curve
fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)
```

```python
>>> from sklearn.metrics import roc_auc_score 
>>> roc_auc_score(y_train_5, y_scores)
0.97061072797174941
```
![](https://ws4.sinaimg.cn/large/006tNbRwgy1fvlxsdq9y9j318c11kwg8.jpg)
ROC曲线的纵轴是真阳率（TPR），横轴是假阳率（FPR）。
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fw6v7jozcsj311k0c0t91.jpg)

对所有样本的预测值（属于**正类的概率值）降序排列**，然后依次将预测的概率值作为阈值，每次得到该阈值下模型预测结果为正类、
负类的样本数，然后生成一组 (FPR, TPR) 值，这样就可以得到ROC曲线上的一点，最后将所有的点连接起来就出现了ROC曲线。ROC曲线越靠近左上角，表示效果越好。

>PR curve or ROC curve

PR : positive class is rare or care more about the FP than the FN，**其他情况选roc**

# 多元分类
multiple classes ： Random Forest classifiers and naive Bayes classifiers

strictly binary classifiers :Support Vector Machine classifiers or Linear classifiers

perform multiclass classification using multiple binary classifiers

<span class='gp-2'>
    <img src='https://ws1.sinaimg.cn/large/006tNbRwgy1fvemmhtfnfj31ba0sudjc.jpg' />
    <img src='https://ws1.sinaimg.cn/large/006tNbRwgy1fvemicb1k3j31ga120dok.jpg' />
</span>

以上的判别方式难以处理多元分类 太**硬**了 不灵活

## OVR
二元分类 One-Versus-Rest(OVR)

>n class fn(d)-> if n for d in data select max(fn(d))

<span class='gp-2'>
    <img src='https://ws3.sinaimg.cn/large/006tNbRwgy1fvemrqkqeuj31ea11u42i.jpg' />
    <img src='https://ws4.sinaimg.cn/large/006tNbRwgy1fvemtedghvj31hs162wle.jpg' />
</span>

优点是简单高效
缺点是如果数据类别很多时，正负类之间的数量差别就很大（数据unbalanced），这样会影响分类效果

## OVO
> 二元分类 每组二元分类 N × (N – 1) / 2 classifiers ，遍历所有二元分类配对 算出最高票

**投票**
<span class='gp-2'>
    <img src='https://ws3.sinaimg.cn/large/006tNbRwgy1fvenhm2786j31fs0vcq6a.jpg' />
    <img src='https://ws1.sinaimg.cn/large/006tNbRwgy1fvenjvvzjyj31kw11z44p.jpg' />
</span>

优点是更加高效，虽然分类次数增加，但是比较时数据量减少只使用两个类别的数据。而且一般不会出现数据unbalanced的情况。
缺点是需要分类的次数多$C_k^2$个，时间复杂度>空间复杂度

**一般用OVR**
小训练集上训练许多分类器比在大训练集上训练少量分类器更快 however, **OVR is preferred**
Scikit-Learn detects when you try to use a binary classification algorithm for a multi‐class classification task, and it automatically runs OVR 

```python
from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier
```

## 多元混淆矩阵
多分类问题，这就意味着每两两类别的组合都对应一个二元的混淆矩阵。
- 先在各个混淆矩阵中分别计算出结果，再计算平均值，这种方式称为**宏平均**。
<img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fw6q6ouwbgj30lm0g8mxt.jpg" style="zoom:50%"/>
- 二元混淆矩阵的对应的元素进行平均，得到 TP、TN、FP、FN 的平均值，然后再根据这些平均值来计算，这种方式称为**微平均**
<img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fw6q7160dzj30lq0esaam.jpg" style="zoom:50%"/>

# 多标签分类
一个样例输出多个类别，比如对于同一张图片，它识别出几个人
```python
from sklearn.neighbors import KNeighborsClassifier

y_train_large = (y_train >= 7)
y_train_odd = (y_train % 2 == 1)
y_multilabel = np.c_[y_train_large, y_train_odd]

knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_multilabel)
```

# 类别不平衡 class-imbalance
当面对不平衡的数据集时，机器学习算法倾向于产生不令人满意的分类器。
在数据分析过程中面临的主要问题是-**如何通过为这些异常获取大量样本来获得平衡数据集？**，因为它们很少发生。
当面对不平衡的数据集时，传统的模型评估方法不能准确地测量模型性能。往往只预测majority class数据。
minority class被视为噪音，往往被忽视。因此，与majority class相比，minority class错误分类概率很高。

[imbalanced-classification-problem](https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/)
[8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)

## 重采样
增加少数群体的频率或降低多数群体的频率

### SMOTE
Synthetic Minority Over-sampling Technique

遵循该技术以避免在将少数例子的精确复制品添加到主数据集时发生的过度拟合。从少数类中获取数据子集作为示例，然后创建新的合成类似实例。然后将这些合成实例添加到原始数据集中。新数据集用作训练分类模型的样本。

<span class='gp-2'>
    <img src='https://ws4.sinaimg.cn/large/006tNbRwgy1fw7l7hmavaj30j00fcjrr.jpg' />
    <img src='https://ws1.sinaimg.cn/large/006tNbRwgy1fw7l7zbze3j30mq0a80tb.jpg' />
</span>

### MSMOTE
SMOTE 改进版
通过计算少数类样本和训练数据样本之间的距离 将少数类分成三组 – Security/Safe samples, Border samples, and latent nose samples.

安全样本是那些可以改善分类器性能的数据点。另一方面，噪声是可能降低分类器性能的数据点。难以归类为两者中任何一个的那些被归类为边界样本。

## 集成算法
修改现有的分类算法，使其适用于不平衡的数据集


>在大多数情况下，SMOTE和MSMOTE等合成技术的性能将优于传统的过采样和欠采样方法。
为了获得更好的效果，可以使用合成采样方法，如SMOTE和MSMOTE，以及先进的增强方法，如渐变增强和XG增强。

## 更改性能指标
准确性不是使用不平衡数据集时使用的[度量标准](#二元分类)。我们已经看到它具有误导性。