---
layout:     post
rewards: false
title:      trick
categories:
    - ml
---
# Bias-Variance Tradeoff
![](https://ws1.sinaimg.cn/large/006tNbRwly1fvlsl4yrwej31kw0aojt0.jpg)
- 方差  varinace
  代表我们使用不同训练集时模型表现的差异 
  如果模型具有较大的方差，训练集只要有少许变化，模型会有很大的改变。复杂的模型一
般具有更大的方差
- 偏差 bias
  代表实际模型与理想模型的差别
<img src="https://ws1.sinaimg.cn/large/006tNbRwgy1fvlsmh6znpj30x80pcdgh.jpg" style="zoom:30%"/>
<img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fvlsmabzqtj30su0kw74v.jpg" style="zoom:30%"/>

# 过拟合
## 造成overfit 主要是
- noise
- 模型复杂度太高
-  train-set too small
## 解决
- 数据清洗（错误数据的更正，或者删除）
- 简化模型
- 更多数据 （如果没有办法获得更多的训练集，对已知的样本进行简单的处理、变换，从而获得更多的样本）
- [regularization](#regularization)
- 减少特征
- [validation](#validation)
## 维度灾难 
当模型很复杂的时候 ，复杂度本身就会引入一种**noise**，
所以即使高阶无noise，模型也不能很好泛化。

# 欠拟合
- 增加模型的迭代次数
- 生成更好特征供训练使用
- 降低正则化水平

# Regularization
正则化 给予model惩罚 **减低model复杂度**

# Validation
## 普通
set 分train and test => Modelargmin(E_test) => 得到model再用整体数据集训练 分量4:1

## Leave-One-Out

每次从数据集中取一个样本作为test-set，直到N个样本都作过验证集，共计算N次，最后对验证误差求平均

>计算量大 
稳定性，例如对于二分类问题，取值只有0和1两种，预测本身存在不稳定的因素，那么对所有的Eloocv计算平均值可能会带来很大的数值跳动
所以Leave-One-Out方法在实际中并不常用

## V-Fold Cross Validation

Leave-One-Out是将N个数据分成N分，那么改进措施是将N个数据分成V份（例如V=10），计算过程与Leave-One-Out相似。这样可以减少总的计算量，又能进行交叉验证，这种方法称为V-折交叉验证。Leave-One-Out就是V-折交叉验证的一个极端例子

### example
cross_val_score K-fold cross-validation
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fvlwae5a39j31kw0twdkj.jpg)

```python
from sklearn.model_selection import cross_val_score
cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring="accuracy")
```

# 归一化
原始数据进行线性变换把数据映射到[0,1]
最大值与最小值非常容易受异常点影响，所以这种方法鲁棒性较差，只适合传统精确小数据场景。

$\text{x'=}\frac{x-min}{max-min}$

# 标准化
数据均值为0，标准差为1 其中μ是样本的均值，σ是样本的标准差 在已有样本足够多的情况下比较稳定，适合现代嘈杂大数据场景

$x'=\frac{x-\mu}\sigma$

如果想保留原始数据中由标准差所反映的潜在权重关系应该选择归一化

# 非线性变换
**用不太复杂的model 解决非线性问题**
通过非线性变换，将非线性模型映射到另一个空间，转换为线性模型，再来进行线性分类
- 特征转换
- 训练线性模型

例如
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fvep9slkq7j31bi0esdi0.jpg)

模型太复杂容易带来过拟合
![](https://ws4.sinaimg.cn/large/006tNbRwgy1fvep83x6wpj30ik0cymxk.jpg)
非线性变换可能会带来的一些问题：**时间复杂度和空间复杂度的增加**，尽可能使用简单的模型，而不是模型越复杂越好

# 二元分类 指标
**数据不均衡有效**
Confusion Matrix
![](https://ws4.sinaimg.cn/large/006tNbRwgy1fvlwqmr86tj31kw0dx77y.jpg)
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fvlwfo7nbqj315o06wgmp.jpg)
```python
from sklearn.model_selection import cross_val_predict
y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)

instead of returning the evaluation scores, it returns the predic‐ tions made on each test fold

>>> from sklearn.metrics import confusion_matrix 
>>> confusion_matrix(y_train_5, y_train_pred) 
    array([[53272, 1307],
          [ 1077,  4344]])
          
row actual class
cloumn pridect class

            PN  PT
        AN  TN ,FP
        AP  FN,TP
best TN TP only
```
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fvlwu96c1uj31kw0u8wgc.jpg)
![](https://ws2.sinaimg.cn/large/006tNbRwgy1fvly0vrq5bj311a0rymz3.jpg)
## Precision
the accuracy of the positive predictions

$${precision\;=\;\frac{TP}{TP\;+\;FP}}$$

## Recall
truepositive rate 
the ratio of positive instances that are correctly detected by the classifier

$$recall\;=\;\frac{TP}{TP\;+\;FN}$$

```python
>>> from sklearn.metrics import precision_score, recall_score
>>> precision_score(y_train_5, y_pred) # == 4344 / (4344 + 1307) 0.76871350203503808
>>> recall_score(y_train_5, y_train_pred) # == 4344 / (4344 + 1077) 0.79136690647482011
```
>不同情况关注点不一样
防小孩看到黄暴视频，分类器拒绝很多好的视频(low recall)，只保留最安全的(high precision)

## F score
![](https://ws2.sinaimg.cn/large/006tNbRwly1fvlx6iy1ccj313e08oweu.jpg)

```python
>>> from sklearn.metrics import f1_score >>> f1_score(y_train_5, y_pred) 0.78468208092485547
```
## threshold
find threshold for recall and precision
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fvlxmyhmdtj31kw0lrabo.jpg)
>lowering the threshold increases recall and reduces precision

```python
y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,
                                 method="decision_function")
```
```python
from sklearn.metrics import precision_recall_curve
precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)
```
![](https://ws2.sinaimg.cn/large/006tNbRwgy1fvlxkyt105j31kw18e78n.jpg)
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fvlxlfm8foj31d20feq5p.jpg)
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fvlxlme5r7j31kw0wswfl.jpg)

## ROC Curve
The receiver operating characteristic (ROC) curve is another common tool used with binary classifiers

**similar to the precision/recall curve**

**area under the curve (AUC)**

```python
from sklearn.metrics import roc_curve
fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)
```

```python
>>> from sklearn.metrics import roc_auc_score 
>>> roc_auc_score(y_train_5, y_scores)
0.97061072797174941
```
![](https://ws4.sinaimg.cn/large/006tNbRwgy1fvlxsdq9y9j318c11kwg8.jpg)

## PR curve or ROC curve
PR : positive class is rare or care more about the FP than the FN

**其他情况选roc**

# 多元分类
multiple classes ： Random Forest classifiers and naive Bayes classifiers

strictly binary classifiers :Support Vector Machine classifiers or Linear classifiers

perform multiclass classification using multiple binary classifiers
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fvemmhtfnfj31ba0sudjc.jpg)
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fvemicb1k3j31ga120dok.jpg)

以上的判别方式难以处理多元分类 太**硬**了 不灵活
## OVR
二元分类 One-Versus-Rest(OVR)
 
>n class fn(d)-> if n for d in data select max(fn(d))

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fvemrqkqeuj31ea11u42i.jpg)
![](https://ws4.sinaimg.cn/large/006tNbRwgy1fvemtedghvj31hs162wle.jpg)
优点是简单高效
缺点是如果数据类别很多时，正负类之间的数量差别就很大（数据unbalanced），这样会影响分类效果

## OVO 
> 二元分类 每组二元分类 N × (N – 1) / 2 classifiers
  遍历所有二元分类配对 算出最高票
  
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fvenhm2786j31fs0vcq6a.jpg)
投票
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fvenjvvzjyj31kw11z44p.jpg)

优点是更加高效，虽然分类次数增加，但是比较时数据量减少只使用两个类别的数据。而且一般不会出现数据unbalanced的情况。
缺点是需要分类的次数多$C_k^2$个，时间复杂度>空间复杂度

**一般用OVR**
小训练集上训练许多分类器比在大训练集上训练少量分类器更快 however, **OVR is preferred**
Scikit-Learn detects when you try to use a binary classification algorithm for a multi‐class classification task, and it automatically runs OVR 

```python
from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier
```