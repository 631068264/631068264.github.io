---
layout:     post
rewards: false
title:      目标检测
categories:
    - ml
tags:
    - cnn
---

# Object Localization
目标定位和目标检测（包含多目标检测）
![](https://cdn.jsdelivr.net/gh/631068264/img/006tNc79gy1fvu813kh3vj31iw0rwgpz.jpg)

# Landmark Detection
除了**矩形区域检**测目标类别和位置外，我们还可以仅对**目标的关键特征点坐标**进行定位，这些关键点被称为landmarks。
![](https://cdn.jsdelivr.net/gh/631068264/img/006tNc79gy1fvu8e34tgij31ii0patbx.jpg)

# Object Detection
**目标检测**的一种简单方法是**滑动窗算法**。这种算法**首先**在训练样本集上搜集相应的各种目标图片和非目标图片。
注意训练集图片尺寸较小，**尽量仅包含相应目标**。然后，使用这些训练集构建CNN模型，使得模型有较高的识别率。
                          
最后，在测试图片上，选择大小适宜的窗口、合适的步进长度，进行从左到右、从上倒下的滑动。每个窗口区域都送入之前构建好的CNN模型进行识别判断。
若判断有目标，则此窗口即为目标区域；若判断没有目标，则此窗口为非目标区域。

- 滑动窗算法的优点是原理简单，且不需要人为选定目标区域（检测出目标的滑动窗即为目标区域）。
- 缺点：**滑动窗的大小和步进长度都需要人为直观**设定。滑动窗过小或过大，步进长度过大均会降低目标检测正确率。
**如果滑动窗和步进长度较小**，整个目标检测的算法**运行时间会很长**。所以，滑动窗算法虽然简单，但是**性能不佳，不够快，不够灵活**。

## Turn Fc layer into conv layer
全连接层转变成为卷积层，只需要使用与上层尺寸一致的滤波算子进行卷积运算即可。窗口步进长度与选择的MAX POOL大小有关。如果需要步进长度为4，只需设置MAX POOL为4 x 4即可
![](https://cdn.jsdelivr.net/gh/631068264/img/006tNc79ly1fvuqosjf5dj31gi0mg75x.jpg)
利用卷积操作代替滑动窗算法，则不管原始图片有多大，只需要进行一次CNN正向计算，因为其中共享了很多重复计算部分，这大大节约了运算成本。之前的滑动窗算法需要反复进行CNN正向计算。

## Bounding Box Predictions
滑动窗口算法有时会出现**滑动窗不能完全涵盖目标**的问题,**YOLO**（You Only Look Once）算法将原始图片分割成n x n网格，每个网格代表一块区域
<span class='gp-2'>
    <img src='https://cdn.jsdelivr.net/gh/631068264/img/006tNc79gy1fvuricv4xuj307607c76r.jpg' />
    <img src='https://cdn.jsdelivr.net/gh/631068264/img/006tNc79gy1fvuriegb44j309h08q0va.jpg' />
</span>

然后，利用上一节卷积形式实现滑动窗口算法的思想，对该原始图片构建CNN网络，得到的的输出层维度为3 x 3 x 8。其中，3 x 3对应9个网格，每个网格的输出包含8个元素：

$$
y=\left [
\begin{matrix}
Pc \\
bx \\
by \\
bh \\
bw \\
c1 \\
c2 \\
c3
\end{matrix}
\right ]$$

如果目标中心坐标$(b_x,b_y)$不在当前网格内，则当前网格Pc=0；相反，则当前网格Pc=1（即只看中心坐标是否在当前网格内）。
判断有目标的网格中，$b_x,b_y,b_h,b_w$限定了目标区域。值得注意的是，当前网格左上角坐标设定为(0, 0)，右下角坐标设定为(1, 1)，
$(b_x,b_y)$范围限定在[0,1]之间，但是$b_h,b_w$可以大于1。**因为目标可能超出该网格，横跨多个区域**，如上图所示。目标占几个网格没有关系，**目标中心坐标必然在一个网格之内**。
划分的网格可以更密一些。**网格越小，则多个目标的中心坐标被划分到一个网格内的概率就越小**，这恰恰是我们希望看到的。

## Intersection Over Union
交集与并集之比，可以用来评价目标检测区域的准确性。
真实目标区域,检测目标区域 之间的**交集I**, **并集U** :

$$IoU=\frac IU$$

IoU可以表示**任意两块区域的接近程度**。IoU值介于0～1之间，且越接近1表示两块区域越接近。

## Non-max Suppression
YOLO算法中,可能几个相邻网格都判断出同一目标的中心坐标在其内。使用**非最大值抑制**（Non-max Suppression）算法。
![](https://cdn.jsdelivr.net/gh/631068264/img/006tNc79gy1fvus0s8rpwj30a5083gqt.jpg)
- 图示每个网格的Pc值可以求出，**Pc值反映了该网格包含目标中心坐标的可信度**。
- 首先选取Pc最大值对应的网格和区域，
- 然后计算该区域与所有其它区域的IoU，剔除掉IoU大于阈值（例如0.5）的网格（**剔除与该网格交叠较大的网格**）。这样就能保证**同一目标只有一个网格与之对应**，且该网格Pc最大，最可信。
- 接着，再从剩下的网格中选取Pc最大的网格，重复上一步的操作。最后，就能使得每个目标都仅由一个网格和区域对应。

## Anchor Boxes
之前都是一个网格至多只能检测一个目标。那对于**多个目标重叠**的情况，使用不同形状的**Anchor Boxes**
<span class='gp-3'>
    <img src='https://cdn.jsdelivr.net/gh/631068264/img/006tNc79gy1fvusgf9aq8j30rw0s0guh.jpg' />
    <img src='https://cdn.jsdelivr.net/gh/631068264/img/006tNc79gy1fvusgom66ej30vi0dy74r.jpg' />
    <img src='https://cdn.jsdelivr.net/gh/631068264/img/006tNc79gy1fvush0rcd7j30v40miacn.jpg' />
</span>
同一网格出现了两个目标：人和车。为了同时检测两个目标，我们可以设置两个Anchor Boxes，Anchor box 1检测人，Anchor box 2检测车。
每个Anchor box都有一个Pc值，若两个Pc值均大于某阈值，则检测到了两个目标。
每个网格多加了一层输出。原来的输出维度是 3 x 3 x 8，现在是3 x 3 x 2 x 8（也可以写成3 x 3 x 16的形式）。这里的2表示有两个Anchor Boxes

>使用YOLO算法时，只需对每个Anchor box使用上一节的非最大值抑制即可。Anchor Boxes之间并行实现。
Anchor Boxes形状的选择可以通过人为选取，也可以使用其他机器学习算法，例如k聚类算法对待检测的所有目标进行形状分类，选择主要形状作为Anchor Boxes

## Region Proposals
滑动窗算法会对原始图片的每个区域都进行扫描,为了避免对无用区域的扫描，降低算法运行效率，耗费时间，可以使用**Region Proposals**的方法
对原始图片进行分割算法处理，然后支队分割后的图片中的块进行目标检测。

Region Proposals共有三种方法：
- R-CNN: 滑动窗的形式，一次只对单个区域块进行目标检测，运算速度慢。
- Fast R-CNN: 利用卷积实现滑动窗算法。
- Faster R-CNN: 利用卷积对图片进行分割，进一步提高运行速度。

比较而言，Faster R-CNN的运行速度还是比YOLO慢一些。
