---
layout:     post
rewards: false
title:      CNN基础
categories:
    - ml
---
卷积神经网络，随着层数的增加，捕捉的区域更大，特征更加复杂，从边缘到纹理再到具体物体。


机器视觉（Computer Vision）是深度学习应用的主要方向之一。一般的CV问题包括以下三类:
- 图片识别
- 目标检测
- 图片风格迁移

如果图片尺寸较大,普通神经网络输入层的维度,网络权重W非常庞大
- 神经网络结构复杂，数据量相对不够，容易出现过拟合；
- 所需内存、计算量较大

![](https://ws4.sinaimg.cn/large/006tNc79gy1fvtrpf66nbj31e60pmjsq.jpg)
                              
# 卷积层计算
神经网络由浅层到深层，分别可以检测出图片的边缘特征 、局部特征（例如眼睛、鼻子等）、整体面部轮廓。

图片边缘有两类：
- 垂直边缘（vertical edges）
- 水平边缘（horizontal edges）

图片的边缘检测可以通过与相应滤波器进行卷积来实现

## 卷积层计算过程
input中与filter相同size的矩阵，对应格相乘得到的结果再相加得到output，通过filter不断移动step=1,获得完整output
![](https://ws3.sinaimg.cn/large/006tNc79gy1fvtpo29rmdj30um0qowgf.jpg)
卷积用conv_forward()表示；tensorflow中，卷积用tf.nn.conv2d()表示；keras中，卷积用Conv2D()表示。

## 边缘检测example
<span class='gp-2'>
    <img src='https://ws4.sinaimg.cn/large/006tNc79gy1fvtpz3njfaj30va0m8mxt.jpg' />
    <img src='https://ws1.sinaimg.cn/large/006tNc79gy1fvtq0ea7d0j30pk0fyq3g.jpg' />
</span>

filter的数值一般需要通过模型训练得到，类似于**标准神经网络中的权重W一样由梯度下降算法反复迭代求得**。
CNN的主要目的就是**计算出这些filter的数值**。确定得到了这些filter后，CNN浅层网络也就实现了对图片所有边缘特征的检测。

# padding
原始图片尺寸为n x n，filter尺寸为f x f，则卷积后的图片尺寸为(n-f+1) x (n-f+1)，注意f一般为奇数。
- 卷积运算后，输出图片尺寸缩小
- 原始图片边缘信息对输出贡献得少，输出图片丢失边缘信息

为了解决图片缩小的问题，可以使用padding方法，即把原始图片尺寸进行扩展，**扩展区域补零**，用**p来表示每个方向扩展的宽度**。
经过padding之后，原始图片尺寸为(n+2p) x (n+2p)，filter尺寸为f x f，则卷积后的图片尺寸为(n+2p-f+1) x (n+2p-f+1)。
若要**保证卷积前后图片尺寸不变**，则p应满足：

$$p=\frac{f-1}{2}$$

- 没有padding操作，p=0，我们称之为**Valid convolutions**
- 有padding操作，$p=\frac{f-1}{2}$，我们称之为**Same convolutions**，保证卷积前后尺寸不变。

# 卷积步长（Strided convolutions）
**stride**表示filter在原图片中水平方向和垂直方向每次的步进长度。之前我们默认**stride=1**。
![](https://ws2.sinaimg.cn/large/006tNc79gy1fvtqy5wo1hj31ii0oqwfy.jpg)

# 三维卷积（Convolutions over volumes）
检测灰度图像的特征，也想检测RGB彩色图像的特征,对应红绿、蓝三个通道。
三维分别表示图片的高度（height）、宽度（weight）和通道（channel），**图像的通道数必须和过滤器的通道数匹配**。

**过程**是将每个单通道与对应的filter进行卷积运算，然后再将3通道的和相加，得到输出图片的一个像素值。**不同通道的滤波算子可以不相同**。

![](https://ws4.sinaimg.cn/large/006tNc79gy1fvtrkn0kjaj31jk0rwjst.jpg)

# 单层卷积网络（One layer of a convolutional network）
![](https://ws2.sinaimg.cn/large/006tNc79ly1fvtsfeb97wj31iq0rkabi.jpg)
选定滤波器组后，参数数目与输入图片尺寸无关。所以，就**不存在由于图片尺寸过大，造成参数过多**的情况。参数=filter.H*filter.W*filter.C*滤波器组数
例如一张1000x1000x3的图片，标准神经网络输入层的维度将达到3百万，而在CNN中，**参数数目只由滤波器组决定**，数目相对来说要少得多，这是CNN的优势之一。

最后，我们总结一下CNN单层结构的所有标记符号，设层数为l。


- $f^{[l]}$ = filter size
- $p^{[l]}$ = padding
- $s^{[l]}$ = stride
- $n_c^{[l]}$ = number of filters

输入维度为：$n_W^{[l-1]} * n_H^{[l-1]} * n_c^{[l-1]}$

每个滤波器组维度为：$f^{[l]} * f^{[l]} * n_c^{[l-1]}$

权重维度为：$f^{[l]} * f^{[l]} * n_c^{[l-1]} * n_c^{[l]}$

偏置维度为：$1 * 1 * 1 * n_c^{[l]}$

输出维度为：$n_H^{[l]} * n_W^{[l]} * n_c^{[l]}$
其中，

$$n_H^{[l]}=\lfloor \frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \rfloor$$

$$n_W^{[l]}=\lfloor \frac{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \rfloor$$

如果有m个样本，进行向量化运算，相应的输出维度为：$m * n_H^{[l]} * n_W^{[l]} * n_c^{[l]}$

# Simple Convolutional Network
![](https://ws1.sinaimg.cn/large/006tNc79gy1fvtyn5wgmij30nb06xmxa.jpg)
输出层可以是一个神经元，即二元分类（logistic）；也可以是多个神经元，即多元分类（softmax）。最后得到预测输出ŷ 。
随着CNN层数增加，$n_H^{[l]}和n_W^{[l]}一般逐渐减小，而n_c^{[l]}一般逐渐增大$。

CNN有三种类型的layer：
- Convolution层（CONV）卷积层
- Pooling层（POOL）池化层
- Fully connected层（FC）全连接层

# 池化层（Pooling layers）
使用池化层来**缩减模型的大小**，提高计算速度，同时提高所提取特征的鲁棒性

Pooling layers的做法比convolution layers简单许多，没有卷积运算，
仅仅是在滤波器算子滑动区域内取最大值，即max pooling，这是最常用的做法。
如果是**多个通道，那么就每个通道单独进**行max pooling操作。除了max pooling之外，
还有一种做法：**average pooling**。max pooling比average pooling更为常用。

![](https://ws3.sinaimg.cn/large/006tNc79gy1fvtz4k5tctj30dt0600sr.jpg)

Max pooling的好处是**只保留区域内的最大值**（特征），忽略其它值，**降低noise**影响，提高模型健壮性。
而且，max pooling需要的超参数仅为滤波器尺寸f和滤波器步进长度s，没有其他参数需要模型训练得到，**计算量很小**。
<span class='gp-2'>
    <img src='https://ws1.sinaimg.cn/large/006tNc79gy1fvtzfb870zj31kw0l7acn.jpg' />
    <img src='https://ws2.sinaimg.cn/large/006tNc79gy1fvtzgavx0aj31gy0sejvf.jpg' />
</span>

# 1x1 Convolutions
filter的维度为1x1，可以用来缩减channel数目,获得filter个数的channel数，池化层压缩它的高度和宽度
![](https://ws4.sinaimg.cn/large/006tNc79ly1fvut9u9dypj30sa0dgaa4.jpg)

# Inception network motivation
代替人工来确定卷积层中的过滤器类型，或者确定是否需要创建卷积层或池化层
![](https://ws4.sinaimg.cn/large/006tNbRwly1fvutt80pzgj30mv08ejrp.jpg)
Inception Network使用不同尺寸的filters并将CONV和POOL混合起来，将所有功能输出组合拼接，再由神经网络本身去学习参数并选择最好的模块。

提升性能的同时，计算量大。
<span class='gp-2'>
    <img src='https://ws2.sinaimg.cn/large/006tNbRwly1fvutunc7xnj30cz06bwei.jpg' />
    <img src='https://ws2.sinaimg.cn/large/006tNbRwly1fvutuqfxkbj30va09nmxl.jpg' />
</span>
由(28×28×32)x(5×5×192) => (28x28x16)x192+(28x28x32)x(5x5x16) 计算量减少了近90%
# Why CNN
相比标准神经网络，CNN的优势之一就是**参数数目要少得多**。参数数目少的原因有两个：

- 参数共享：一个特征检测器（例如垂直边缘检测）对图片某块区域有用，同时也可能作用在图片其它区域。
- 连接的稀疏性：因为滤波器算子尺寸限制，每一层的每个输出只与输入部分区域内有关。

除此之外，由于CNN参数数目较小，所需的训练样本就相对较少，从而一定程度上不容易发生过拟合现象。
而且，CNN比较擅长捕捉区域位置偏移。也就是说CNN进行物体检测时，不太受物体所处图片位置的影响，**增加检测的准确性和系统的健壮性**。

