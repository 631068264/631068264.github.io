---
layout:     post
rewards: false
title:      NN
categories:
    - ml
---
![](https://ws4.sinaimg.cn/large/006tNbRwgy1fvkdfiryu9j31hm0uu7bu.jpg)
![](https://ws1.sinaimg.cn/large/006tNbRwgy1fvkdo1d99cj31jc12811p.jpg)

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fvke8z09loj31hy12u48w.jpg)

![](https://i.loli.net/2018/09/24/5ba853af28a7e.png)

# 求W
## 损失函数
- 分类交叉熵
- 回归MSE
## 反向传播
$cost=\frac12\left(\mathrm{真实值}-\mathrm{预测值}\right)^2$ 方便求导
求 cost的min 

梯度下降SGD 不断修正W
$W\;=\;W\;-\;\frac{\partial\;cost}{\partial W}$

Example :
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fvkhiehkemj31hk0c2aay.jpg)
目标求$\frac{\partial\;P}{\partial W_2},\frac{\partial\;P}{\partial W_1}$

链式偏导
$\frac{\partial\;P}{\partial W_2} = \frac{\partial\;P}{\partial Z}*\frac{\partial\;Z}{\partial W_2}$ 恒等变换
![](https://ws4.sinaimg.cn/large/006tNbRwgy1fvkhiu718sj31540le75y.jpg)
整理一下
![](https://ws4.sinaimg.cn/large/006tNbRwgy1fvkhm5vzh5j319i0iwjt3.jpg)

从后往前推导微分
当网络复杂时 偏导路径 很多
反向传播: 重复偏导的地方 重复使用不再算 省时间（链式偏导+动态规划）
![](https://ws2.sinaimg.cn/large/006tNbRwgy1fvkhydyjz1j30zu0nu445.jpg)


# 优化NN
NN 结果对W初始值敏感 一般选随机

复杂度 神经网络中神经元的个数,权值的数量D O(VD) 
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fvkibqyo4hj30z80om0xo.jpg)
![](https://ws2.sinaimg.cn/large/006tNbRwgy1fvkif9r2xrj316s0qadk8.jpg)

# dNN

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fvkkhlvgmwj31ik138do7.jpg)
![](https://ws4.sinaimg.cn/large/006tNbRwgy1fvkkumuflnj31io132153.jpg)