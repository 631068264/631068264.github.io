# 语言

## python

### GC

**引用计数法**   reference counting

一旦对象的引用计数为0，该对象立即被回收，对象占用的内存空间将被释放。它的[缺点](language/py/key/2018-08-17-GC.md#引用计数法Reference Counting)是

When an object's reference count reaches zero, it is  reclaimed and the memory space freed

使用引用计数法来管理对象的话，他们并不会被回收，它会一直驻留在内存中，就会造成了内存泄漏memory leaks（内存空间在使用完毕后未释放）。为了解决对象的**循环引用**circular references问题，Python引入了标记-清除mark-and-sweep和分代回收generational garbage collection两种GC机制。

**[标记-清除](language/py/key/2018-08-17-GC.md#标记清除)**

它通过标记可达对象和清除不可达对象的方式来回收内存空间。

在标记阶段，垃圾回收器从根对象开始遍历所有可达对象并标记为活动对象。

During the marking phase，the garbage collector starts from the root objects and traverses all reachable objects, marking them as active objects

然后，在清除阶段，垃圾回收器遍历堆内存，将未标记的对象视为垃圾并释放其内存空间。

during the sweep phase, the garbage collector traverses the heap memory and treats the unmarked objects as garbage, freeing their memory space.

**[分代回收](language/py/key/2018-08-17-GC.md#分代回收)**

**整个应用程序会被暂停，为了减少应用程序暂停的时间** minimize the frequency of garbage collection

**对象存在时间越长，越可能不是垃圾，应该越少去收集。这样在执行标记-清除算法时可以有效减小遍历的对象数，从而提高垃圾回收的速度。**  divide objects into different generations,  the younger generations have a higher rate as a garbage.

根据对象的存活时间将其划分为不同的代

### GIL

全局解释器锁Global Interpreter Lock （[GIL](language/py/key/2018-06-06-GIL.md#Python 运行流程)）是Python编程语言中的一种互斥锁机制，确保同一时间只有一个线程可以执行Python字节码。保证了解释器级别的线程安全。ensures only one thread can execute Python bytecode at a time

- [协同式多任务处理  Cooperative multitasking ](language/py/key/2018-06-06-GIL.md#协同式多任务处理)是一种协作模式，**任务之间主动让出执行权**给其他任务，可以通过生成器函数、协程或异步编程库来实现。

  tasks will yield the execution control to other tasks

- [抢占式多任务处理 Preemptive multitasking](language/py/key/2018-06-06-GIL.md#抢占式多任务处理)是由操作系统控制的方式，**操作系统**决定任务的执行顺序和任务切换，可以使用线程或进程来实现。 the operating system determines the execution order of tasks and handles task switching

绕过GIL的两种思路

```
1. 绕过CPython，使用JPython等别的实现；



2. 把关键性能代码放到其他语言中实现，比如C++。
```



### AIO asynchronous

[异步编程过程](language/py/key/2018-03-20-aio.md#事件循环+回调)

- 在异步编程中，首先创建一个事件循环，并向其注册需要执行的异步任务。

  create an event loop and register the asynchronous tasks that need to be executed.

- 异步任务可以是协程、异步函数或使用回调方式编写的函数。

- 当一个任务遇到阻塞的I/O操作时，会将控制权交还给事件循环，以便其他任务继续执行。

  When a task get a blocking I/O operation, it yield the control to the event loop, allowing other tasks to continue executing.

- 事件循环会在适当的时机调度和执行任务，并在任务完成时触发相应的回调函数。

  The event loop schedules and executes tasks at the suitable time and triggers the callback functions when a task is completed.

### 协程

协程可以在执行过程中暂停并恢复执行，实现异步编程和并发处理。协程通过等待异步操作的结果来管理任务的执行顺序和并发性。

在Python AIO中，[协程](language/py/key/2018-03-20-aio.md#协程)通过与事件循环（event loop）结合使用，实现了高效处理I/O密集型任务的能力 。事件循环负责管理和分配不同任务的执行，注册这些任务并处理它们之间的控制流。当一个协程遇到I/O操作时，它会主动释放CPU的控制权，并将控制权交还给事件循环，从而让其他协程有机会执行 。

协程的非阻塞特性使得程序能够在等待I/O操作完成时继续执行其他任务，提高了程序的性能和响应性 。通过并发执行多个任务，协程能够充分利用计算资源，避免长时间的阻塞。而且，协程的非抢占式调度确保了程序能够按照预期的顺序执行，避免了竞争和冲突。

然而，需要注意的是，由于Python的全局解释器锁（GIL）的存在，协程无法有效地利用多核处理器。这意味着在处理CPU密集型任务时，协程可能无法提供相同的性能优势。Coroutines can't  use multi-core perfectly,  CPU-intensive tasks bad performance  I/O-intensive tasks 

## GO

[包结构，mod   vendor 依赖查找流程   init流程 main启动流程](language/go/key/2019-07-27-go pkg.md)



### 基本结构

[声明赋值](language/go/key/2019-07-27-go rule.md#声明赋值)

声明赋值 **:= 结构不能在函数外使用**

[切片](language/go/key/2019-07-27-go rule.md#切片)

一个slice由三个部分构成：指针、长度和容量

Go 中切片扩容的策略是这样的：

- 首先判断，如果新申请容量（cap）大于2倍的旧容量（old.cap），最终容量（newcap）就是新申请的容量（cap）

- 否则判断，如果旧切片的长度小于1024，则最终容量(newcap)就是旧容量(old.cap)的两倍，即（newcap=doublecap）

- 否则判断，如果旧切片长度大于等于1024，则最终容量（newcap）从旧容量（old.cap）开始循环增加原来的 1/4，即

- 如果最终容量（cap）计算值溢出，则最终容量（cap）就是新申请容量（cap）

- **新切片指向的数组是一个全新的数组。并且 cap 容量也发生了变化**，gc 会负责回收旧的底层数组的内存。

append 操作

- slice底层数组是否有足够的容量来保存新添加的元素。如果有足够空间的话，直接扩展slice

- 没有足够的增长空间的话，会先分配一个足够大的slice用于保存新的结果，先将输入的x复制到新的空间，然后添加y元素


[map](language/go/key/2019-07-27-go rule.md#map)

通过哈希查找表实现 map，用链表法解决哈希冲突。

**通过 key 的哈希值将 key 散落到不同的桶中，每个桶中有 8 个 cell。哈希值的低位决定桶序号，高位标识同一个桶中的不同 key。**

**当向桶中添加了很多 key，造成元素过多，或者溢出桶太多，就会触发扩容。扩容分为等量扩容和 2 倍容量扩容。扩容后，原来一个 bucket 中的 key 一分为二，会被重新分配到两个桶中。**

**扩容过程是渐进的，主要是防止一次扩容需要搬迁的 key 数量过多，引发性能问题。触发扩容的时机是增加了新元素，bucket 搬迁的时机则发生在赋值、删除期间，每次最多搬迁两个 bucket。**

[defer panic error](language/go/key/2019-07-27-go rule.md#错误处理)

- `panic` 只会触发**当前 Goroutine** 的 `defer`
- `recover` 只有在 `defer` 中调用才会生效， `recover` 只有在发生 `panic` 之后调用才会生效
- defer、return、返回值三者的执行顺序应该是：return最先给返回值赋值；接着defer开始执行一些收尾工作；最后RET指令携带返回值退出函数。
- 当存在多个`defer`语句时，它们的执行顺序是"后进先出"（Last In, First Out）的原则。

[**new make 区别**](language/go/key/2019-07-27-go rule.md#new make 区别)

- `new` 用于值类型对象的创建，返回的是指向新分配对象的**指针**，并将**对象初始化为零值。**
- `make` 用于引用类型对象的创建，返回的是**已初始化并准备好使用的对象**，不返回指针。
- `new` 适用于创建结构体、基本类型等值类型对象。
- `make` 适用于**创建切片、map、chan等引用类型对象**，并可以指定初始长度或容量。



### lock chan select context

[锁](language/go/key/2019-08-10-go lock.md#sync.Mutex)

多读单写 RWMutex读写锁    互斥锁 Mutex

**mutex会阻塞其他goroutines，比原子操作慢**

每次调用从`sync/atomic`包转换为一组特殊的机器指令，这些机器指令基本上在**CPU级别上运行**

[chan](language/go/key/2019-08-10-go lock.md#chan原理)

写:如果缓冲区中没有空余位置，将待发送数据写入G，将当前G加入sendq，进入睡眠，等待被读goroutine唤醒; 

读:如果缓冲区中没有数据，将当前goroutine加入recvq，进入睡眠，等待被写goroutine唤醒;

lock、buff、qcount、closed(关闭状态)、sendx/recvx(队列下标用于数组循环队列)、sendq(等待写消息队列)、recvq(等待读消

息队列)

```go
type hchan struct {
	qcount   uint			//Channel 中的元素个数
	dataqsiz uint			// Channel 中的循环队列的长度
	buf      unsafe.Pointer //Channel 的缓冲区数据指针
	elemsize uint16
	closed   uint32
	elemtype *_type
	sendx    uint  //Channel 的发送操作处理到的位置
	recvx    uint  //Channel 的接收操作处理到的位置
	recvq    waitq
	sendq    waitq // 缓冲区空间不足而阻塞的 Goroutine 列表  双向链表

	lock mutex
}
```

[select](language/go/key/2019-08-10-go lock.md#select)

select 会阻塞到某个分支可以继续执行为止，这时就会执行该分支。

当多个分支都准备好时会随机选择一个执行。

当 select 中的其它分支都没有准备好时，default 分支就会执行。
为了在尝试发送或者接收时不发生阻塞，可使用 default 分支

[context](language/go/key/2019-08-10-go lock.md#context)

context 用来解决 goroutine 之间**退出通知**、**元数据传递**的功能

### 内存逃逸

[内存逃逸](language/go/key/2021-06-07-go总结.md#内存逃逸)

栈一般由操作系统来分配和释放，[堆由程序员通过编程语言来申请创建与释放。](language/go/key/2021-06-07-go总结.md#堆栈)

栈用来存放函数的参数、返回值、局部变量、函数调用时的临时上下文等，堆用来存放全局变量。

**在 Go 语言中，当一个函数内部创建的变量（包括局部变量和函数参数）逃逸到函数外部时，称为内存逃逸。内存逃逸发生时，变量将在堆上分配内存，而不是在栈上分配。**

内存逃逸的影响是变量的生命周期得以延长，需要在堆上分配和回收内存，可能会增加垃圾回收的负担。为了避免不必要的内存逃逸，可以尽量在函数内部使用局部变量，避免将变量返回给调用函数，并且避免将变量存储在逃逸到堆上的数据结构中。

- 内存逃逸发生在函数内部创建的变量逃逸到函数外部时。
- 编译器进行逃逸分析，决定变量的生命周期和存储位置。
- 内存逃逸的原因包括变量被分配给全局变量、被返回给调用函数、存储在切片或映射中，或存储在逃逸到堆上的数据结构中。
- 内存逃逸会导致变量在堆上分配和回收内存，增加垃圾回收的负担。
- 可以通过优化代码，避免不必要的内存逃逸，提高性能。

变量发生逃逸的情况可以总结

- **方法内返回局部变量指针**  返回时被外部引用，因此其生命周期大于栈，则溢出
- **发送指针或带有指针的值到 channel 中**  编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。
- **在一个切片上存储指针或带指针的值**  导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。
- **slice append 时可能会超出其容量( cap )** 它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配
- **在 interface 类型上调用方法。** 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。`Printf Sprintf等等`



### GMP

[GMP](language/go/key/2021-06-07-go总结.md#Goroutine调度 GMP)

1、先从本地队列拿，2、没有从全局队列里拿一半回本地队列，3、从网络轮询器里获取并Inject到全局队列里，4、 从别的P里偷一半放到本地，注:每个P都会每61次会从全局队列里获取一个，防止在全局队列里的G饿死。

只有当 M 与一个 P 关联后才能执行 Go 代码。除非 M 发生阻塞或在进行系统调用时间过长时，没有与之关联的 P

- 从处理器本地的运行队列中查找待执行的 Goroutine
- 从全局队列里拿回本地队列
- 从网络轮询器中查找是否有 Goroutine 等待运行
- 尝试从其他随机的处理器中窃取待运行的 Goroutine
- 当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行

![image-20240209170515088](https://cdn.jsdelivr.net/gh/631068264/img/202402091705170.png)

[GMP 触发调度条件](language/go/key/2021-06-07-go总结.md#触发调度)



### GC

[GC](language/go/key/2021-06-07-go总结.md#GC)

Go 的垃圾回收器采用了并发标记清除（Concurrent Mark and Sweep）的算法，并结合了三色标记法（Tricolor Marking）和写屏障（Write Barrier）等技术来实现高效的垃圾回收。

并发标记清除（Concurrent Mark and Sweep）

- 在三色标记法中，我们将对象分为三个不同的颜色：
  - **白色**：表示对象尚未被扫描。
  - **灰色**：表示对象已经被扫描，但其引用的其他对象尚未被扫描。
  - **黑色**：表示对象及其引用的其他对象都已经被扫描。
- 算法从根对象（例如全局变量、栈中的对象等）开始，递归地遍历对象图，并根据引用关系将对象标记为灰色或黑色。

因为增量和并发两种方式都可以与用户程序交替运行，所以我们需要**使用屏障技术**（对象引用发生变化时，通知垃圾回收器，以便垃圾回收器能够正确地跟踪对象的可达性。）保证垃圾收集的正确性；与此同时，应用程序也不能等到内存溢出时触发垃圾收集，因为当内存不足时，应用程序已经无法分配内存，这与直接暂停程序没有什么区别，增量和并发的垃圾收集需要提前触发并在内存不足前完成整个循环，避免程序的长时间暂停。



### 其他优化 内存对齐

go 优化

-  [pprof](language/go/2021-08-27-go优化.md#pprof)

  先使用 cpu profile 找出耗时最多的函数，进行优化。如果发现 gc 执行比较多的时候，找出内存分配最多的代码以及引发内存分配的函数，进行优化。

  可分析(堆、哪个方法占用cpu时间多、协程数、系统线程数、阻塞耗时block、互斥锁耗时mutex) go tool pprof连接进行

  pprof采集，默认采集30秒。go tool graphviz生成svg文件或火焰图观察链路和耗时或生成信息放在本地进入pprof终端查看。pprof可 分析golang程序cpu占用过高问题或系统线程数过多cpu负载高。

- [竞态检测](language/go/2021-08-27-go优化.md#竞态检测)

  协程资源竞争

- [内存对齐](language/go/2021-08-27-go优化.md#内存对齐)

  合理的内存对齐可以提高内存读写的性能，并且便于实现变量操作的原子性。

  CPU 访问内存时，并不是逐个字节访问，而是以字长（word size）为单位访问。是**减少 CPU 访问内存的次数，加大 CPU 访问内存的吞吐量。**


# 进程线程

[进程](language/py/key/2018-03-20-aio.md#进程线程协程 )是表示资源分配的基本单位

basic unit for resource allocation

都有自己的独立内存空间 上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大

independent memory space  

context switch has a big overhead    stack, registers, virtual memory, file handles, and more.

线程是操作系统能够进行运算调度的最小单位 共享进程的内存空间

is the smallest unit for computation share the memory space

**通过操作系统内核来完成**  operating system kernel.

**进程上下文切换与线程上下文切换最主要的区别就是线程的切换虚拟空间内存是相同的（因为都是属于自己的进程），但是，进程切换的虚拟空间内存则是不同的。**

The main difference between process context switching and thread context switching

threads share the same virtual memory space

**进程切换分两步**
1.切换页目录以使用新的地址空间  Switching page directories to use a new address space
2.切换内核栈和硬件上下文。   Switching kernel stacks and hardware context

对于linux来说，线程和进程的最大区别就在于地址空间。
对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。所以明显是进程切换代价大



**进程状态转换**     [详解](language/py/key/2018-01-23-unix进程间通信.md#进程状态转换)

![img](https://cdn.jsdelivr.net/gh/631068264/img/008i3skNgy1gxpv4isfisj30be03lq2w.jpg)

unix进程间通信方式  [详解](language/py/key/2018-01-23-unix进程间通信.md#unix进程间通信方式)

管道  信号  消息（Message）队列 共享内存（Shared Memory） 信号量（Semaphore） 套接字（Socket）

## 协程对比

协程是在**用户空间中实现**的，不依赖于操作系统内核的调度。**协程的调度和管理由用户程序自己负责**，通常使用事件循环来调度协程的执行。

Coroutines are implemented in **user space** **The scheduling and management of coroutines are the responsibility of the user program itself**

**协程优点**

- 无需线程上下文切换的开销 No overhead of thread context switching

- 无需原子操作锁定及同步的开销  No overhead of atomic operation locking and synchronization

- 方便切换控制流 Convenient for switching control flow

- 高并发低成本  High concurrency at low cost

[协程是一种用户态的轻量级线程](language/py/key/2018-03-20-aio.md#协程对比)，**协程切换**完全在用户空间进行，协程切换只涉及基本的CPU上下文切换，所谓的 CPU 上下文，就是一堆寄存器，里面保存了 CPU运行任务所需要的信息。**协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈**。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。一般来说一次协程上下文切换最多就是几十ns 这个量级。

**Coroutine switching** occurs entirely in user space， only basic CPU context switching。

**Coroutine scheduling is entirely controlled by the user. Coroutines have their own register context and stack**

协程又称为轻量级线程，每个协程都自带了一个栈，可以认为一个协程就是一个函数和这个存放这个函数运行时数据的栈，这个栈非常小，一般只有几十kb。

[协程之间区别](language/py/key/2018-03-20-aio.md#两种协程对比)

py协程 **运行在同一个线程中，由语言的运行时中的 EventLoop（事件循环）来进行调度**。适合IO密集型。通过`await`,`yield`关键字挂起执行，等待异步操作的结果，期间可以执行其他协程或任务，方便地实现协作式多任务。

Python coroutines run in the same thread and are scheduled by  EventLoop. They are suitable for IO-intensive tasks. Using the `await` and `yield` keywords,  wait for the result of asynchronous operations. During the wait, other coroutines or tasks can be executed, making it easy to implement cooperative multitasking.

Go协程在**多线程环境下执行**，由Go语言运行时的调度器进行调度，采用基于信号量的协程模型。

- [select阻塞时，io(文件，网络)读写阻塞, channel阻塞时, 锁，sleep](language/go/key/2021-06-07-go总结.md#触发调度)



# AI

**梯度消失**
激活函数sigmoid将负无穷到正无穷的数映射到0和1之间
神经网络的反向传播是逐层对函数偏导相乘，因此当神经网络层数非常深的时候，
最后一层产生的偏差就因为乘了很多的小于1的数而越来越小，最终就会变为0，

When the network has many layers, the small values less than 1 can cause the gradients to become smaller , finally zero.

从而导致层数比较浅的权重没有更新，这就是梯度消失。

This can lead to the weights in the earlier layers not being effectively updated

此深层网络的学习就等价于只有后几层的浅层网络的学习

**梯度爆炸** gradient explosion.

when the network has a large number of layers, the weight initialization is too high, or the learning rate is set too high

Gradient explosion can lead to excessive parameter updates, making it difficult for the network to learn and converge stably.

初始化权值过大，前面层会比后面层变化的更快，就会导致权值越来越大，梯度爆炸的现象就发生了

梯度消失：（1）隐藏层的层数过多；（2）采用了不合适的激活函数(更容易产生梯度消失，但是也有可能产生梯度爆炸)

梯度爆炸：（1）隐藏层的层数过多；（2）权重的初始化值过大 **权重正则化**



reduce the num of hidden layers,  use suitable activation funcations , weight  regularization

用ReLU、Leaky-ReLU、P-ReLU、R-ReLU、Maxout等替代sigmoid函数。

用Batch Normalization。这个输入值的分布强行拉回到接近均值为0方差为1的标准正太分布，具有加速网络收敛速度

can accelerate the convergence of the network and improve its stability

LSTM的结构设计也可以改善RNN中的梯度消失问题。 LSTM通过它内部的“门”可以接下来更新的时候“记住”前几次训练的”残留记忆“

残差结构



**[DeepSpeed](LLM/key/2023-09-09-分布式AI训练原理.md#Deepspeed实践)的功能**： Ds本质还是dp

- **分布式训练** **Distributed Training**：DeepSpeed支持单个GPU、多GPU和分布式环境下的训练。
- **混合精度训练 **Mixed Precision Training：它允许使用半精度（FP16）进行训练，从而提高训练速度。
- **优化技术**  **Optimization  **Techniques：DeepSpeed包含了一些优化技术，例如ZeRO（用于减少显存占用）、自动张量并行 automatic tensor parallelism、通信优化等。
- **模型压缩**：DeepSpeed支持模型压缩，以减小模型的存储和计算开销。

百亿（70B）以上就有点吃力

**[Megatron-LM](LLM/key/2023-09-09-分布式AI训练原理.md#Megatron-LM实践)**







word2vec

**CBOW**  相当于一句话中扣掉一个词，让你猜这个词是什么。 完形填空

**Skip-gram**  用当前词来预测上下文。

Word2vec (用来产生词向量的相关模型。这些模型为浅层双层的神经网络,词的顺序是不重要的。) 

经常采用 2 种加速方式：

- Negative Sample（负采样）

- Hierarchical Softmax 层次 Softmax

  传统的 Softmax 需要计算所有词汇的概率分布，计算量较大。层次 Softmax 使用二叉树结构来近似词汇表，通过减少计算的复杂度来提高训练效率。

  虽然极大地提升了效率，但是如果是一个生僻词，那么需要向下走很久，所以采用ns来求解





## [大模型原理](LLM/key/2023-09-03-self-attention transformer原理 MOE.md)



**Decoderonly的架构**

- 首先淘汰掉BERT这种encoder-only，因为它用masked language modeling预训练，不擅长做生成任务
- decoder-only的模型用next token prediction预训练，兼顾理解和生成，在各种下游任务上的**zero-shot和few-shot泛化性能都很好**
  - **注意力满秩的问题**，双向attention的注意力矩阵容易退化为低秩状态，而causal attention的注意力矩阵是下三角矩阵，必然是满秩的，建模能力更强
  - **预训练任务难度问题**，纯粹的decoder-only架构+next token predicition预训练，每个位置所能接触的信息比其他架构少，要预测下一个token难度更高，当模型足够大，数据足够多的时候，decoder-only模型学习通用表征的上限更高；
  - **上下文学习为decoder-only架构带来的更好的few-shot性能**，因为prompt可以更加直接地作用于decoder每一层的参数，微调的信号更强
  - **decoder-only支持一直复用KV-Cache**，对多轮对话更友好，因为每个token的表示只和它之前的输入有关，而encoder-decoder和PrefixLM就难以做到
  - OpenAI作为开拓者勇于挖坑踩坑，以decoder-only架构为基础摸索出了一套行之有效的训练方法和Scaling Law，后来者鉴于时间和计算成本，自然不愿意做太多结构上的大改动，继续沿用decoder-only架构。在工程生态上，decoder-only架构也形成了先发优势，Megatron和flash attention等重要工具对causal attention的支持更好。
  - causal attention （就是decoder-only的单向attention）具有隐式的位置编码功能 ，打破了transformer的位置不变性，而带有双向attention的模型，如果不带位置编码，双向attention的部分token可以对换也不改变表示，对语序的区分能力天生较弱。
- 双向attention的encoder-decoder，也能兼顾理解和生成，泛化性能也不错。为什么？
  - causal attention （就是decoder-only的单向attention）具有隐式的位置编码功能 ，打破了transformer的位置不变性，而带有双向attention的模型，如果不带位置编码，双向attention的部分token可以对换也不改变表示，对语序的区分能力天生较弱。




## bert

对比OpenAI GPT(Generative pre-trained transformer)，BERT是双向的Transformer block连接；就像单向RNN和双向RNN的区别，直觉上来讲效果会好一些。

对比ELMo，虽然都是“双向”，但目标函数其实是不同的。ELMo是分别以𝑃(𝑤𝑖|𝑤1,...𝑤𝑖−1) 和 𝑃(𝑤𝑖|𝑤𝑖+1,...𝑤𝑛) 作为目标函数，独立训练处两个representation然后拼接，而BERT则是以 𝑃(𝑤𝑖|𝑤1,...,𝑤𝑖−1,𝑤𝑖+1,...,𝑤𝑛) 作为目标函数训练LM。



这里的Embedding由三种Embedding求和而成：

- Token Embeddings是词向量，第一个单词是CLS标志，可以用于之后的分类任务
- Segment Embeddings用来区别两种句子，因为预训练不光做LM还要做以两个句子为输入的分类任务
- Position Embeddings和之前文章中的Transformer不一样，不是三角函数而是学习出来的

在预训练阶段，BERT用大量的**无监督**文本通过自监督训练的方式(通过使用受完形填空任务启发的**Masked Language Model**预训练目标)训练，把文本中包含的语言知识（包括：词法、语法、语义等特征）以参数的形式编码到Transformer-encoder layer中。预训练模型学习到的是文本的通用知识，不依托于某一项NLP任务

**bert 只能做到根据任务进行微调，GPT可以使用prompt(few shot)**

**GPT的训练相对于BERT有以下不同之处：**

- GPT使用的是Transformer模型，而BERT使用的是双向Transformer模型。
- GPT的预训练数据来源是大量的网络文本数据，而BERT的预训练数据来源是两个大型语料库，包括Wikipedia和BooksCorpus。
- GPT预训练过程中，采用了语言模型的方法，即通过预测下一个词来学习语言模型，而BERT预训练过程中采用了双向预测的方法，即通过预测句子中丢失的词来学习语言模型。
- GPT微调时，需要指定输入输出的语言模型任务，而BERT微调时，可以应用在多种任务上，例如文本分类、命名实体识别等。

**GPT和BERT在使用场景上有明显的不同：**

- GPT主要用于自然语言生成任务，如文本自动补全、问答系统、文本翻译等。它可以根据给定的文本上下文生成有意义的文本，并且能够产生连贯的、人类水平的文本。
- BERT则主要用于自然语言理解任务，如问题回答、文本分类、句子关系分析等。它可以理解文本中的语义和关系，并能够找出语句之间的联系。
- GPT在文本生成场景中更常见，如聊天机器人，智能问答系统等。BERT在文本理解场景中更常见，如文本分类，问题回答等。
- GPT对于文本生成更为敏感，而BERT对于文本理解更为敏感。
- GPT在进行文本生成时需要较长的上下文，而BERT在进行文本理解时需要较短的上下文。
- 总的来说，GPT主要用于文本生成任务，而BERT则主要用于文本理解任务。





查询（Q）： 代表模型当前关注的项目。 在序列中，查询就像对特定元素提出问题。 键（K）： 代表序列中模型可能关注的所有项目。 键是查询用来比较的对象，以确定应该给予多少注意力。 值（V）： 每个键都与一个值相关联。 一旦模型确定了哪些键是重要的（基于查询），就会使用相应的值来构建输出。 


每一个output **b**，都是**考虑所有的a 生成的**，计算输入序列中每个位置与其他位置之间的关联程度，从而为每个位置生成一个上下文向量。它能够对序列中的不同位置进行全局关联性建模，无论位置的距离远近。  Self-attention calculates the correlation between each position in the input sequence and other positions, generating a context vector for each position. It can model global relationships between different positions in the sequence, regardless of their distance.

"Soft-max, do a normalization process."

**向量分别乘以对应不同的矩阵，得到q,k向量，再内积**

Multiply the vectors by their corresponding matrices to obtain the q and k vectors, and then take their dot product.

**multi-head**  表示多个关系

*q* represents a query vector used to calculate the attention scores between the input elements. The multiple relationships multiple query vectors  can be used

**位置信息**

在Transformer模型中，Positional Encoding（位置编码）用于为输入序列中的每个位置添加独特的位置信息。由于Transformer没有像循环神经网络（RNN）那样的显式顺序处理机制，它无法捕捉到序列中元素的相对位置信息。为了解决这个问题，Transformer引入了位置编码。

In the Transformer model, Positional Encoding is used to add unique positional information to each position in the input sequence. Unlike (RNNs)  can handle the input by order, Transmformer can't get  positional information of elements in the sequence. To address this issue, the Transformer introduces positional encoding.

Positional Encoding是通过将位置信息编码为一个向量序列，**并将其与输入向量相加来实现的**。这样，每个位置的输入向量将包含来自位置编码的信息和原始输入的信息。**位置编码的目的是为了在Transformer模型中引入关于输入序列中元素顺序的信息，以便更好地处理序列数据。**

Positional Encoding is achieved by encoding the position information into a sequence of vectors and adding them to the input vectors. **Transformer , in order to better process sequential data.**



**Why Masked:** Masking is used because the input to the decoder is determined this way; inputs are processed one by one, and it's impossible to consider later vectors.  输入逐个进行处理，无法考虑后面的向量。

Cross-attention calculate the output of an encoder and the output of a masked layer  as the input for the encoder

编码器的输出和掩码层的输出作为编码器的输入来计算输出。

**When does the decoder stop:** The length of the output sequence is determined by the model itself. In the vocabulary, a stop token is added, which can be the same or different from the begin token.

输出序列的长度由模型自身确定。在词汇表中，添加了一个停止令牌



**block详解**。使用**residual(input + output 作为下一层input) + layer norm**

residual network can avoid vanishing or exploding gradients in deep network layers.  残差网络可以避免在深度网络层中出现梯度消失或梯度爆炸的问题。

**Layer Normalization**  but not batch Normalization  perform well in mini-batch training  and have a good convergence

In an attention architecture, Layer Normalization is more commonly used than Batch Normalization since the attention mechanism is frequently applied to sequential data

小批量训练中表现良好，并且具有良好的收敛性, 在注意力架构中，层归一化比批归一化更常用，因为注意力机制经常应用于序列数据。



**CNN  RNN**区别

Self-attention calculates the correlation between each position in the input sequence and other positions, generating a context vector for each position. It can model global relationships between different positions in the sequence, regardless of their distance.    计算输入序列中每个位置与其他位置之间的相关性，为每个位置生成一个上下文向量。它可以建模序列中不同位置之间的全局关系，而不考虑它们之间的距离。

CNN   extract features using convolution operations with a sliding window and downsampling through pooling operations

卷积操作和池化操作提取特征。卷积操作使用滑动窗口来进行特征提取，而池化操作通过降采样来进一步提取特征。

Self-attention allowing for more flexible capture of relationships between different positions without relying on fixed-size convolutional kernels

- 单向RNN只能考虑最先输入的向量，而不是整个句子。双向RNN，最右边的黄色output，很容易忘记最左边的蓝色input。但是self-attention可以通过QK联系起来。

  RNNs consider the first vector not whole sentences only and remerber the last input but forget first input. self-attention  can connect the whole   sentences .

- self-attention可以并行计算，RNN只能等上一个向量处理完后的输出才作为下一个的输入，不能并行计算。

  Self-attention can be computed in parallel







**FLASHATTENTION** loops through
blocks of the K and V matrices and loads them to fast  SRAM. In each block, FLASHATTENTION
loops over blocks of Q matrix , loading them to SRAM, and writing the output  back to HBM.

**Vision Transformer**

dividing the image into small patches   after Patch Embedding   compress it into a fixed-dimensional vector.  cls_token is always placed at position 0.

**DDPM**

generating an image with noise of a specific size  ，proceed step by step to denoise the image finally get a clear picture.

Noise Predicter  predicting what the noise should look like.

生成一个具有特定大小的噪声图像，按照以下步骤进行去噪，最终得到清晰的图像 ,噪声预测器会预测噪声应该是什么样子的。



**灾难性遗忘Catastrophic forgetting**

How to avoid

- 确认灾难性遗忘是否影响到你使用场景 Confirm if catastrophic forgetting affects your use case.

- 在pretrain阶段加入新知识

- 在仅用SFT做领域模型时，资源有限时可以在Chat模型基础上训练，资源充足时可以在Base模型上训练。

- 如果需要其他任务的泛化能力，可以多任务一齐微调。良好的多任务微调，**可能需要50-100,000个例子跨多个任务** If you need the generalization ability for other tasks, you can fine-tune multiple tasks together.

- 使用PEFT保留原始LLM权重，并且只训练少量特定任务的适配器层和参数。由于大部分预训练权重保持不变，PEFT对灾难性遗忘有更大的鲁棒性

  PEFT (Parameter Efficient Fine-Tuning)  can retains the original weights of the LLM . Only trains a small number of adapter layers and parameters for specific tasks.  Due to the majority of pre-training weights remaining unchanged, PEFT exhibits greater robustness against catastrophic forgetting

**缓解大模型幻觉**

- 调整模型的 **temperature 参数** 以限制创造力。
- 优化 **提示工程**，要求模型逐步思考，并在回复中提供事实性信息和参考来源。
- 整合 **外部知识源** 来改进答案验证。

**通用大模型的训练流程**

- 预训练阶段 （进行预训练，让模型学习通用知识和语言能力，进行词表扩充，以适应特定语言和领域）
- **微调  Supervised Finetuning，SFT**  通常需要在训练语料中加入一些领域数据，帮助模型理解特定领域的概念和名词
- RLHF





## [peft](LLM/key/2023-09-10-LLM 微调  PEFT RLHF 模型压缩.md)

**Adapters**

adapters is to add small fully connected networks after Transformer sub-layers and learn those parameters.

Adapters的作用是在Transformer的子层之后添加小型全连接网络，并学习这些参数。

**Prompt-Tuning** 

We connect the prompt embeddings with the sequence embeddings. We use this new information to pass into the language model      prompt embeddings 和 sequence embeddings  叠加起来，进行训练

**Prefix Tuning**

 fed to all layers of the transformer , use the soft-prompt as input for  a fully connected network

每层给FC, 训练

**P-Tuning**

encoding the prompt using an LSTM     prompt给LSTM训练

**LORA**

Freeze most of the original LLM weights.   冻结大部分原始LLM权重。

Inject 2 rank decomposition matrices  注入两个秩分解矩阵。

Train the weights of the smaller matrices   训练较小矩阵的权重。

## [RLHF](LLM/key/2023-09-10-LLM 微调  PEFT RLHF 模型压缩.md#RLHF(Reinforcement Learning from Human Feedback))

- **预训练语言模型**：Pre-trained language model

  - RLHF首先使用已经经过传统预训练目标（例如，下一个标记预测损失）的语言模型作为起点。这些预训练的模型可以是GPT-3的较小版本，也可以是其他规模更大的变体。

  - 这些预训练模型已经具备一定的语言理解能力，但还需要进一步优化以适应特定任务或人类偏好。They can adapt to specific tasks or human preferences

- **收集数据和训练奖励模型**：**Data Collection and Training of Reward Models**

  - RLHF需要收集人类反馈数据，以便创建奖励信号。这些反馈可以是人类对生成文本的评价，例如“好”或“不好”。

    gathering human feedback data to create reward signals

  - 奖励模型的任务是将输入文本序列映射到标量奖励值。这个奖励值可以根据生成的文本是否符合人类偏好来计算。

    This reward value can be calculated based on how well the generated text aligns with human preferences.

  - 通过训练奖励模型，我们可以获得更好的衡量生成文本质量的指标。

    By training the reward model, we can get better metrics for measuring the quality of the generated text.

- **强化学习微调语言模型**： Reinforcement learning to fine-tune language models

  - 最后，我们使用强化学习来微调预训练的语言模型。这意味着我们使用奖励模型提供的奖励信号来优化模型的参数。

  - 在强化学习中，模型根据环境（文本生成或理解）进行交互，并学习采取行动（选择单词或预测含义）以最大化奖励信号（例如生成连贯的句子或准确理解输入）。

## 参数

[模型压缩 剪枝 蒸馏](LLM/key/2023-09-10-LLM 微调  PEFT RLHF 模型压缩.md#模型压缩)



[量化](LLM/key/2024-07-20-LLM量化.md)





[评估显存](LLM/key/2023-11-21-参数调优.md#估计)

[训练](LLM/key/2023-11-21-参数调优.md#训练显存)8倍，[推理](LLM/key/2023-11-21-参数调优.md#推理显存)2倍

节省显存，内存



[调节训练参数](LLM/key/2023-11-21-参数调优.md#调节训练参数)

[加载参数](LLM/key/2023-11-21-参数调优.md#加载参数)



## Tensor

[tensorrt](LLM/key/推理/2024-06-27-TensorRT.md)

[openvino](LLM/key/推理/2024-07-23-openvino.md)

[cuda编程](LLM/key/推理/2024-08-20-cuda 编程.md)





## 降低精度 量化

[小量化原理](LLM/key/2024-07-20-LLM量化.md)

 

**当然也可以使用量化模型(Quantized model)，或者更低精度**（加载模型时候使用torch_dtype，一般加载用torch.float16或者torch.bfloat16）。**通常用BF16 （精度低，范围大），因为FP16（half, 半精度,精度高） 会经常溢出，导致数值不稳定、模型不收敛**(non-convergence) ，新卡支持BF16

It is common to use the BF16 (bfloat16) data type because it offers a larger range while maintaining a lower precision. This can be beneficial in avoiding frequent overflow issues that may arise with the FP16 (half precision) data type, which can lead to numerical instability and non-convergence of the model. It's great to know that the new cards support BF16, as it provides a good balance between precision and range for improved model stability and convergence.

**int8**   mixed precision

In Matrix multiplication will use  **Vector-wise **     split two parts outliers and non-outlier 

- 从输入隐藏状态中，按列提取异常值（即大于特定阈值的值） Extracting outliers (values greater than a specific threshold) from the input hidden state column-wise.
- 对 FP16 中的离群值矩阵和 int8 中的非离群值矩阵分别执行矩阵乘法 Performing matrix multiplication on the outlier matrix in FP16 and the non-outlier matrix in int8.
- 对非离群值矩阵结果进行反量化，并将离群值和非离群值结果相加，以获得 FP16 中的完整结果。 Dequantizing the result of the non-outlier matrix and adding it to the outlier matrix to obtain the complete result in FP16.

**int4** 

NF4

Based on the standard normal distribution, I generated 16 quantized values and scaled them to the range of [-1, 1]

double quantization to reduce storage space, using int8 for absmax.

When GPU memory ,transfer optimizer's parameters to CPU memory , prevent out-of-memory (OOM) errors



## [量化 PEFT 代码实战](LLM/key/2023-11-21-参数调优.md#PEFT)

## [RAG](LLM/key/2023-10-10-RAG.md)

![image-20231125113114096](https://cdn.jsdelivr.net/gh/631068264/img/202311251131349.png)

use less token and perform well in specific task

reduce hallucinations 







## [评测](LLM/key/2023-10-10-RAG.md#RAG 测评工具  Evaluation Tool)

answer context  question

- answer context  如果答案中提出的所有主张都可以从给定的上下文中推断出来，则生成的答案被认为是忠实的
- answer,  question  不完整或包含冗余信息的答案将获得较低分数。
- context  question 相关的rag的排序较高
- context  ground truth 对比

ROUGE (召回率导向的摘要评估)主要用于通过将自动生成的摘要与人工生成的参考摘要进行比较，来评估摘要的质量。

- ROUGE主要关注生成文本与参考文本之间的重叠程度，即召回率，而对精确度的关注不足。这可能导致系统生成的摘要虽然包含了大部分关键信息，但可能包含很多不相关的内容。

- 不考虑词序和语法结构，**对同义词和改写不敏感**

BLEU (双语评估) 用于翻译评估

- BLEU能够平衡精确度和召回率，更全面地评估翻译质量。
- 它过于关注词序和语法结构。
- 它可能对生成文本的长度过于敏感，有时候可能会惩罚较短的文本。







## [向量索引](LLM/key/2024-02-19-向量索引.md)



## [分布式训练](LLM/key/2023-09-09-分布式AI训练原理.md)

训练数据规模和单步计算量和模型相关相对固定，

- $$\mathrm{训练耗时}\;=\;\mathrm{训练数据规模}\;\ast\;\mathrm{单步计算量}/\mathrm{计算速率} $$

- $$\mathrm{计算速率}\;=\;\mathrm{单设备计算速率}（\mathrm{摩尔定律或者算法优化}）\ast\mathrm{设备数}\;\ast\;\mathrm{多设备并行效率}（\mathrm{加速比}）$$

但是可以**提高计算速率**

- 混合精度，算子融合，梯度累加 (单设备计算速率)
- 服务器架构，通信拓扑优化 (设备数)
- 数据并行 模型并行  流水并行 （加速比）

[通信原语](LLM/key/2023-09-09-分布式AI训练原理.md#集合式通信原语)

[并行策略](LLM/key/2023-09-09-分布式AI训练原理.md#并行策略)

[Deepspeed实战](LLM/key/2024-05-31-分布式AI训练框架.md#Deepspeed实战)



## [agent](LLM/key/2023-10-10-agent.md#总结)

先思考两个问题

- 每个agent的功能
- agent之间怎样连接

## ML

[分类指标](ml/key/优化/2018-05-10-分类 指标trick.md)

<img src="https://cdn.jsdelivr.net/gh/631068264/img/202404131146382.png" alt="image-20240413114608055" style="zoom:25%;" />

准确率=**(TP+TN)/(TP+TN+FP+FN)**     

- 正负样本不平衡，**导致了得到的高准确率结果含有很大的水分。即如果样本不平衡，准确率就会失效。**

精准率Precision=**TP/(TP+FP)**

- 对预测为正样本结果中的预测准确程度

召回率Recall=**TP/(TP+FN)**

- 对实际为正样本结果中的预测准确程度

找到二者之间的一个**平衡点**（阈值，P==R），**F1分数**=2\*精准率\*召回率 / (精准率 + 召回率)，选取合适的阈值点要根据实际需求

**ROC曲线无视样本不平衡**,**AUC（ROC 曲线下的面积）**

真阳率（TPR） = **TP/(TP+FN)** 

假阳率（FPR） =  **FP/(FP+TN)**  模型虚报程度

ROC曲线的纵轴是真阳率（TPR），横轴是假阳率（FPR），**ROC曲线越靠近左上角，AUC越大，表示效果越好**。一般AUC的值是介于0.5到1之间的

PR : positive class is rare or care more about the FP than the FN，**其他情况选roc**

- 当对比两个分类器效果的时候看auc面积；当选定好最佳分类器后，

- 需要决定一个分类阈值时，例如取阈值0.65得到最佳的分类效果，是通过看pr曲线来确定的。



[Bias-Variance  拟合 标准 归一  正则 loss](ml/key/优化/2018-05-10-Bias_Variance_trick.md)

[ML流程详解](ml/key/优化/2018-09-25-ML细化.md)

[正则  梯度爆炸/消失  模型优化效果详细](ml/key/优化/2018-09-29-base model.md)

[激活函数](ml/key/概念/2018-09-28-Shallow Neural Network.md#激活函数 Activation functions)

[CNN](ml/key/概念/2018-10-02-CNN基础.md)

[RNN](ml/key/概念/2018-10-03-RNN基础.md)


## AI编译器

[AI编译器架构](LLM/key/2024-05-27-AI编译器.md#AI 编译器架构)

**IR 中间表达**

编译器主要分为前后端，分别针对于硬件无关和硬件相关的处理。每一个部分都有自己的 IR (Intermediate Representation，中间表达)，每个部分也会对进行优化：

- High-level IR：用于表示计算图，其出现主要是为了解决传统编译器中难以表达深度学习模型中的复杂运算这一问题，为了实现更高效的优化所以新设计了一套 IR。
- Low-level IR：能够在更细粒度的层面上表示模型，从而能够针对于硬件进行优化，文中将其分为了三类。

**Frontend 前端优化**

构造计算图后，前端将应用图级优化。因为图提供了计算全局概述，所以更容易在图级发现和执行许多优化。前端优化与硬件无关，这意味着可以将计算图优化应用于各种后端目标。前端优化分为三类

- 节点级优化，如 Zero-dim-tensor elimination、Nop Elimination
- 块级优化，如代数简化、常量折叠、算子融合
- 数据流级优化，如Common sub-expression elimination、DCE

**Backend 后端优化**

特定硬件的优化

- 目标针对特定硬件体系结构获取高性能代码。
  - 1）低级IR转换为LLVM IR，利用LLVM基础结构生成优化的CPU/GPU代码。
  - 2）使用领域知识定制优化，这可以更有效地利用目标硬件。
- 自动调整
  - 由于在特定硬件优化中用于参数调整的搜索空间巨大，因此有必要利用自动调整来确定最佳参数设置。
    - 1）Halide/TVM允许调度和计算表达分开，使用自动调节来得出较佳配置。
    - 2）应用多面体模型 Polyhedral model 进行参数调整。
- 优化内核库
  - 厂商特定优化内核库，广泛用于各种硬件上的加速DL训练和推理。特定优化原语可以满足计算要求时，使用优化的内核库可显著提高性能，否则可能会受到进一步优化的约束。



## AI计算图

[AI计算图.md](LLM/key/2024-05-29-AI计算图.md)

计算图基本结构  张量， 算子

[自动微分](LLM/key/2024-05-29-AI计算图.md#自动微分)



[图优化 – 图调度与执行](LLM/key/2024-05-29-AI计算图.md#图优化 – 图调度与执行)



[控制流](LLM/key/2024-05-29-AI计算图.md#控制流)





## AI推理引擎

[模型推理系统.md](LLM/key/2024-05-23-模型推理系统.md) 



[推理流程全景](LLM/key/2024-05-23-模型推理系统.md#推理流程全景) 

[推理引擎整体架构](LLM/key/2024-05-23-模型推理系统.md#推理引擎整体架构) 

- [模型小型化](LLM/key/2024-05-23-模型推理系统.md#推理引擎整体架构#模型小型化) 
- [模型压缩](LLM/key/2023-09-10-LLM 微调  PEFT RLHF 模型压缩.md#模型压缩) 
- [模型转化与图优化](LLM/key/2024-05-23-模型推理系统.md#模型转化与图优化) 





## 知识图谱

[知识图谱](LLM/key/2024-04-22-知识图谱.md)





## 推荐系统

[推荐系统](LLM/key/2024-04-22-推荐系统.md)

[推荐链路](LLM/key/2024-04-22-推荐系统.md#推荐链路)

[召回双塔模型](LLM/key/2024-04-22-推荐系统.md#双塔模型)

[精排多目标排序模型](LLM/key/2024-04-22-推荐系统.md#多目标排序模型)

[粗排三塔模型](LLM/key/2024-04-22-推荐系统.md#粗排)

[重排clip 为了多样性](LLM/key/2024-04-22-推荐系统.md#重排)

[物品冷启动](LLM/key/2024-04-22-推荐系统.md#物品冷启动)



## 搜索引擎

[搜索引擎](LLM/key/2024-05-04-搜索引擎.md)



 



# db

## mysql

### 索引

InnoDB存储引擎的默认索引实现为：B+树索引

B+tree性质：

- n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。
- 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
- 所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。
- B+ 树中，数据对象的插入和删除仅在叶节点上进行。
- B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。

[B树B+树](db/mysql/key/2018-01-23-索引优缺.md#B树B+树)

B和B+树的区别在于，**B+树的非叶子结点只包含导航信息，不包含实际的值**，所有的叶子结点和相连的节点使用链表相连，**便于区间查找和遍历**。因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子节点上关联的数据也具有更好的缓存命中率。

**B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。**

**AVL 数和红黑树基本都是存储在内存中才会使用的数据结构**。在大规模数据存储的时候，红黑树往往出现由于**树的深度过大**而造成磁盘IO读写过于频繁，**磁盘查找存取的次数往往由树的高度所决定**，所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度。

[对比hash B树](db/mysql/key/2018-01-23-索引优缺.md#对比hash B树)

**回表:在流程中从非主键索引树搜索回到主键索引树搜索的过程**

**[索引覆盖](db/mysql/key/2018-01-23-索引优缺.md#索引覆盖):从非主键索引中就能查到的记录，而不需要查询主键索引中的记录，避免了回表的产生减少了树的搜索次数，显著提升性能**



[mysql对的索引选择](db/mysql/key/2018-01-23-索引优缺.md#mysql对的索引选择)

扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。

- 分析sql
- 预估全表搜索成本
- 根据sql条件查询可能会使用到的索引
- 分析各个索引使用成本
- 执行sql

[索引建立，匹配原则   失效](db/mysql/key/2018-01-23-索引优缺.md#优化)



### mysql 执行流程

**Server层**：

**连接器**  进行用户的身份认证，包括校验账户密码，权限等操作

**查询缓存** 如果无法命中缓存,就继续走到分析器的的一步,如果命中缓存就直接返回给客户端 。如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。

**分析器**  词法分析 提取关键字    语法分析 是否符合mysql的语法

**优化器**  最优的执行方案去执行

**执行器**  调用存储引擎的API，返回接口执行的结果

**存储引擎层**： 

主要负责数据的存储和读取，支持多个存储引擎，其中InnoDB引擎有自有的日志模块redolog 模块。 **[select](db/mysql/key/2021-05-22-mysql过程.md#查询)不会记录到binlog中,只有update/delete/insert才会记录到binlog中。而[update](db/mysql/key/2021-05-22-mysql过程.md#更新)会采用两阶段提交的方式,记录都redolog中**

**2PC** 两阶段提交的目的是保证两个日志（**redo log** 和 **binlog**）的一致性。我们把整个过程拆分为三个部分：

1、prepare阶段 (写入redo undo log)

2、 写binlog 

3 、commit

当实例宕机后，恢复的过程如下：

情况1：当在2之前崩溃时

重启恢复：后发现没有commit，回滚。

备份恢复：没有binlog 。

重启恢复和备份恢复一致

情况2：当在3之前崩溃

重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。

备份恢复：有binlog.

重启恢复和备份恢复一致

[redo log 写入机制](db/mysql/key/2021-05-22-mysql过程.md#redo log 写入机制)

[redo log与binlog区别](db/mysql/key/2021-05-22-mysql过程.md#redo log与binlog区别)

### 锁

共享锁   可以并发读取，查询数据。但不能修改

排它锁  只允许T读取和修改A，其他任何事务都不能再对A加任何类型的锁，直到T释放A上的锁

[间隙锁](db/mysql/key/2021-08-14-锁.md#间隙锁)

间隙锁会封锁该条记录相邻两个键之间的空白区域，防止其它事务在这个区域内插入、修改、删除数据，这是为了防止出现 幻读 

**唯一索引**只有锁住多条记录或者一条不存在的记录的时候，才会产生间隙锁，指定给某条存在的记录加锁的时候，只会加记录锁，不会产生间隙锁

**普通索引**列上，不管是何种查询，只要加锁，都会产生间隙锁，这跟唯一索引不一样

### 事务

[ACID](db/mysql/key/2018-08-19-事务.md#ACID)   原子性（Atomicity）一致性（Consistency） 隔离性（Isolation）持久性（Durability）

[脏读？幻读？不可重复读](db/mysql/key/2018-08-19-事务.md#脏读？幻读？不可重复读？)   

[事务四个隔离级别](db/mysql/key/2018-08-19-事务.md#事务四个隔离级别对比)

### 集群  主从 多主

[mysql 集群方案](db/mysql/2021-10-23-mysql 集群.md)

**半同步复制**通过引入同步确认机制，确保主数据库在提交事务之前，至少有一个从数据库已经接收并确认了复制。



### 存储引擎不同

[文件存储结构](db/mysql/key/2018-08-19-MyISAM与InnoDB的主要区别.md#文件存储结构)

MyISAM

- 适合读多写少，不支持事务

- MyISAM的索引和数据是分开的，并且索引是有压缩的，内存使用率就对应提高了不少。能加载更多索引，而Innodb是索引和数据是紧密捆绑的，没有使用压缩从而会造成Innodb比MyISAM体积庞大不小

- AUTO_INCREMENT 更快，自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引

- 保存表具体行数 select count(*) from table，包含 where条件时，两种表的操作是一样的

- 表锁，并发性差

InnoDB

- 支持事务，外键，故障恢复快
- 如果你的数据执行大量的**INSERT**或**UPDATE**，出于性能方面的考虑，应该使用InnoDB表
- 提供行锁
- InnoDB不支持FULLTEXT类型的索引

## redis

### [why 快](db/redis/2021-05-21-redis.md#why 快)

- 完全基于内存，绝大部分请求是纯粹的内存操作
- 数据结构简单，对数据操作也简单
- 单线程  **避免了不必要的上下文切换和竞争条件**，也不存在多进程或者多线程导致的切换而消耗 CPU，**不用去考虑各种锁的问题**，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗
- 多路I/O复用模型，非阻塞IO







### [底层结构](db/redis/2021-05-21-redis.md#底层结构)

![](https://cdn.jsdelivr.net/gh/631068264/img/008i3skNgy1gqq12gulemj30ts0kzdgj.jpg)

### [过期删除策略](db/redis/2021-05-21-redis.md#删除策略)

Redis 会将每一个设置了 expire 的键存储在一个独立的字典中，以后会定时遍历这个字典来删除过期的 key。除了定时遍历外，它还会使用惰性删除策略来删除过期的 key。

**惰性删除：**键过期后不管，每次读取该键时，判断该键是否过期，如果过期删除该键返回空，然后删除key

### [持久化](db/redis/2021-03-09-aof_rdb.md)

- **RDB**（Redis 数据库）：RDB 持久性以指定的时间间隔执行数据集的时间点快照。
- **AOF**（仅追加文件）：AOF 持久性记录服务器接收到的每个写操作。然后可以在服务器启动时再次重播这些操作，从而重建原始数据集。命令使用与 Redis 协议本身相同的格式进行记录

### [**异步更新从库**](db/redis/2021-05-21-redis.md#同步)

刚开始：从服务器向主服务器发送 sync 命令，rdb全量更新，缓冲区记录的写命令增量更新

[断线后重复制](db/redis/2021-05-21-redis.md#psync)：Slave在同步掉线时 不用再全局同步,可以在原来的位置继续同步



### [**哨兵**](db/redis/2021-05-21-redis.md#哨兵)

**哨兵的核心功能是主节点的自动故障转移**

它由两部分组成，哨兵节点和数据节点：

- 哨兵节点：哨兵系统由一个或多个哨兵节点组成，哨兵节点是特殊的redis节点，不存储数据。
- 数据节点：主节点和从节点都是数据节点。

单哨兵监测到并转为主观下线，通知其他哨兵，N/2+1哨兵主观下线转客观下线 ，主库下线，哨兵 们发起投票由谁成为leader进行选主(**1:从库优先级、2:从库复制进度、3:从库 ID 号**，一般优先级一样，找复制进度最快的减少数据 不一致)

### [**redis-cluster模式**](db/redis/2021-05-21-redis.md#集群) 

集群中的节点分为主节点和从节点：只有主节点负责读写请求和集群信息的维护；从节点只进行主节点数据和状态信息的复制。

高可用流程，某个节点主观下线 通知其他节点，过半主观下线则客观下线。然后各个主节点去故障的从节 点进行选举投票找出最合适的从节点替换成主节点(和哨兵一样，也是选复制进度快的)。

### [数据分区原理   一致性哈希算法](db/redis/2021-05-21-redis.md#分区原理)

**事务操作**:(mutli exec最好就同一key)、lua原子操作



## kafka

### why快

1. 分布式架构：Kafka使用分布式架构，可以将数据分散存储在多个服务器上，**允许多个消费者并行地读取和处理数据。这种水平扩展的能力使得Kafka能够处理大规模数据流，并提供高吞吐量。**
2. 高效的存储机制：Kafka使用磁盘存储消息，而不是将消息保留在内存中。这种设计允许Kafka存储大量的消息，而不会受到内存大小的限制。此外，Kafka使用**顺序写入磁盘**的方式，以最大化写入性能。
3. 零拷贝技术：**Kafka使用零拷贝技术**来改善性能。传统的数据传输通常涉及将数据从一个缓冲区复制到另一个缓冲区，而零拷贝技术可以避免这种复制操作，提高数据传输的效率。
4. 批量处理：Kafka支持**批量处理消息**，可以将多个消息一起发送和处理，减少了网络开销和处理的次数。这种批量处理的方式可以显著提高整体吞吐量。
5. 基于磁盘的持久化：Kafka将消息持久化到磁盘中，这意味着即使在消息被消费之后，它们仍然可以保留在磁盘上一段时间。这种方式使得Kafka在处理大量数据时能够保持高性能。

### [分区](db/kafka/2018-01-12-Kafka 结构.md#分区)

一组消息归纳为一个主题
每个主题又被分成一个或多个分区
每个分区由一系列有序、不可变的消息组成，一个有序队列。
每个分区又有一至多个 副本( Replica)，分区的副本分布在集群的不同代理上，以提高可用性



Kafka 只能保证一个分区之内消息的有序性，并**不能保证跨分区消息的有序性** 。 每条消息被追加到相应的分区中，是顺序写磁盘，因此效率非常高，这是 Kafka 高吞吐率的 一个重要保证。



已被消费的消息删除策略

- 一是基于消息己存储的时间长度

- 二是基于分区的大小



 一个副本作为 Leader 副本，而该分区其他副本即为 Follower 副本，只有 Leader 副 本才负责处理客户端读/写请求， Follower 副本从 Leader 副本同步数据。

[消息到达分区策略](db/kafka/2018-01-12-Kafka 结构.md#消息到达分区策略)





### [日志](db/kafka/2018-01-12-Kafka 结构.md#log)

**kafka以` <topic>-<partition> `为存储文件夹名，里面的文件按日志追加形式进行分段 (有很多个小文件，方便旧的整块删除)**



### [Broker](db/kafka/2018-01-12-Kafka 结构.md#代理 Broker)

![image-20210319112910850](https://cdn.jsdelivr.net/gh/631068264/img/202402122024311.jpg)

### [消费者](db/kafka/2018-01-12-Kafka 结构.md#消费者 Consumers)

kafka采用的是拉模式消费，消费速度由consumer控制，防止broker推送速度大于consumer消费速度而崩溃。

![image-20210320154146826](https://cdn.jsdelivr.net/gh/631068264/img/202402122036136.jpg)

消费者线程数不能大于分区数(当消费者总数大于分区数的话，多余的消费 者进程会一直挂着什么都不干，但是当某个消费者线程down掉的话，之前那些多余的消费者线程会顶替上来)，多个消费者组订阅同一 个topic组成广播。

### [工作流](db/kafka/2018-01-12-Kafka 结构.md#工作流)

- Producers定期向Topic发送消息
- Broker确保消息在分区之间平均分享,如果制作者发送两条消息并且有两个分区，则Kafka将在第一个分区中存储一条消息，并在第二个分区中存储第二条消息。
- Consumers订阅特定Topic
- 当消费者订阅了一个主题，Kafka将向消费者提供该主题的当前偏移量，并且还将该偏移量保存在Zookeeper集合中。
- Consumers 定期pull message
- Kafka收到生产者的消息后，会将这些消息转发给消费者
- 消费者将收到消息并进行处理
- 当消息被处理，消费者将向Broker**发送确认**。
- Kafka收到确认后，会将偏移量更改为新值并在Zookeeper中更新它。 由于在Zookeeper中维护了偏移量，因此即使在服务器繁忙期间，使用者也可以正确读取下一条消息。
- 循环以上
- 消费者可以随时选择倒带/跳至期望的主题偏移量并阅读所有后续消息

### [数据可靠性](db/kafka/2018-01-12-Kafka 结构.md#数据可靠性)

消息确认机制

Topic 分区副本 （[ISR 选主分区](db/kafka/2018-01-12-Kafka 结构.md#ISR)）

在 ZooKeeper 中动态维护了一个ISR,保存同步的副本列表，该列表中保存的是与Leader 副本保持消息同步的所有副本对应的代理节点 id

### [数据一致性](db/kafka/2018-01-12-Kafka 结构.md#数据一致性)

High Water Mark 取决于 **ISR 列表里面偏移量最小的分区**，对应于上图的副本2，这个很类似于木桶原理。

这样做的原因是还没有被足够多副本复制的消息被认为是“不安全”的，如果 Leader 发生崩溃，另一个副本成为新 Leader，那么这些消息很可能丢失了。如果我们允许消费者读取这些消息，可能就会破坏一致性。

### [Rebalance](db/kafka/2018-01-12-Kafka 结构.md#Rebalance机制分析)

规定了所有 consumer 怎样分配订阅 Topic 的每个分区，Rebalance的目的是确保消费者组中的所有消费者均匀地处理消息，并且每个消费者负责处理的分区数量大致相等。

topic过多顺序IO会降为随机IO(很多文件一起写变成随机io)，不停的动态订阅topic会不停的触发rebalance。

- 组成员个数发生变化。例如有新的 consumer 实例加入该消费组或者离开组。
- 订阅的 Topic 个数发生变化。
- 订阅 Topic 的分区数发生变化。

## clickhouse

### [OLAP](db/clickhouse/key/2019-05-05-clickhouse base.md#what is OLAP **Online analytical processing** )

### [vs mysql](db/clickhouse/key/2019-05-05-clickhouse base.md#vs mysql)

### [vs ES](db/clickhouse/key/2019-05-05-clickhouse base.md#vs ES)

### [what is clickhouse](db/clickhouse/key/2019-05-05-clickhouse base.md#what is clickhouse )

### [MergeTree 好处](db/clickhouse/key/2021-07-28-ck存储结构.md#MergeTree 好处)

### [存储结构](db/clickhouse/key/2021-07-28-ck存储结构.md#存储结构)

### [查询](db/clickhouse/key/2021-07-28-ck存储结构.md#查询)

### [Mutation 删改操作 ](db/clickhouse/key/2021-07-28-ck存储结构.md#Mutation)

### [异步Merge&Mutation ](db/clickhouse/key/2021-07-28-ck存储结构.md#异步Merge&Mutation)

### [MergeTree 引擎系列](db/clickhouse/key/2021-08-17-clickhouse-引擎.md#MergeTree系列)



## ES

### [倒排结构](db/es/key/2020-03-30-es_索引机制.md#倒排结构)

![](https://cdn.jsdelivr.net/gh/631068264/img/202402131026069.jpg)



![](https://cdn.jsdelivr.net/gh/631068264/img/202402131031512.jpg)

Mysql 是以 b-tree 排序的方式存储在磁盘上的。检索一个 term 需要**若干次随机 IO** 的磁盘操作。而 Lucene 在 term dictionary 的基础上添加了term index来加速检索，term index 以树的形式缓存在内存中。从 term index 查到对应的 term dictionary 的 block 位置之后，再去磁盘上找 term，大大减少了**磁盘的随机IO次数**。

### [分片](db/es/key/2020-05-30-es_分片插入机制.md#分片)

![](https://cdn.jsdelivr.net/gh/631068264/img/202402131048905.jpg)

Rebalance（再平衡），当集群中节点数量发生变化时，将会触发es集群的rebalance，即重新分配shard。Rebalance的原则就是尽量使shard在节点中分布均匀，**primary shard和replica shard不能分配到一个节点上的**，达到负载均衡的目的。

[分片设计](db/es/key/2020-05-30-es_分片插入机制.md#分片设计)



![](https://cdn.jsdelivr.net/gh/631068264/img/202402131127180.jpg)

![](https://cdn.jsdelivr.net/gh/631068264/img/202402131127298.jpg)

### [分片机制 写入原理](db/es/key/2020-05-30-es_分片插入机制.md#分片机制 写入原理)

删除的文档不会立即清理

数据先入buffer buffer 到 segment过程叫refresh，refresh后才数据会被搜索到

![img](https://cdn.jsdelivr.net/gh/631068264/img/202402131152125.jpg)

**写入操作的延时**就等于latency = Latency(Primary Write) + Max(Replicas Write)。只要有副本在，写入延时最小也是两次单Shard的写入时延总和，写入效率会较低。

Elasticsearch是先写内存，最后才写[TransLog](db/es/key/2020-05-30-es_分片插入机制.md#Transaction Log)，一种可能的原因是Lucene的内存写入会有很复杂的逻辑，很容易失败，比如分词，字段长度超过限制等，比较重，为了避免TransLog中有大量无效记录，减少recover的复杂度和提高速度，所以就把写Lucene放在了最前面。二是写Lucene内存后，并不是可被搜索的，需要通过Refresh把内存的对象转成完整的Segment后，然后再次reopen后才能被搜索，一般这个时间设置为1秒钟，导致写入Elasticsearch的文档，最快要1秒钟才可被从搜索到



![img](https://cdn.jsdelivr.net/gh/631068264/img/202402131157576.jpg)

![image-20201004232327765](https://cdn.jsdelivr.net/gh/631068264/img/202402131157177.jpg)



### [搜索机制](db/es/key/2020-10-05-es_内部机制.md#搜索机制)

两步 query + fetch  先从各分片拿到到doc id 再拿doc

- 分片越多  算分越不准
- 分片越多需要处理的doc越多

[query then fetch 问题](db/es/key/2020-10-05-es_内部机制.md#query then fetch 问题)

降低分片数

### [聚合机制](db/es/key/2020-10-05-es_内部机制.md#聚合机制)

![image-20201005133721163](https://cdn.jsdelivr.net/gh/631068264/img/202402131215687.jpg)

聚合不精准问题，数据分布在不同分片

- 降低分片数
- 增大shard_size（限制每个分片返回的文档数量）

### [并发处理机制](db/es/key/2020-10-05-es_内部机制.md#聚合机制)

乐观并发

通过**if_seq_no** 和 **if_primary_term** 控制

1. 在执行更新操作之前，首先获取要更新文档的当前序列号和主要项。可以通过执行Get API请求来获取文档的元数据，其中包括`_seq_no`和`_primary_term`字段。
2. 在更新请求中，使用`if_seq_no`和`if_primary_term`参数指定要匹配的序列号和主要项。



### [故障转移 集群容灾](db/es/key/2020-05-30-es_分片插入机制.md#故障转移 集群容灾)

- primary shard 所在节点发生故障（**red, 因为部分主分片不可用**）

- 当es集群中的master节点发生故障，重新选举master节点。
- master行驶其分片分配的任务。
- master会寻找node1节点上的P0分片的replica shard,  replica shard将被提升为primary shard。**这个升级过程是瞬间完成，集群的健康状态为yellow，因为不是每一个replica shard都是active的**。

- R0 也会重新分配，集群变绿



### [文档保存到分片](db/es/key/2020-05-30-es_分片插入机制.md#文档保存到分片)

![](https://cdn.jsdelivr.net/gh/631068264/img/202402131117701.jpg)

### [集群管理](db/es/2020-10-05-es_集群管理.md#集群管理)

### [性能优化](db/es/2020-10-05-es_性能优化.md)

### [mapping](db/es/2020-10-31-es_mapping.md#mapping)

# docker

[pull 过程](docker/2021-12-10-docker pull.md)

[pid 1](docker/2021-12-11-docker 补充.md)

**container runtime**

主要负责的是容器的生命周期的管理。oci的runtime spec标准中对于容器的状态描述，以及对于容器的创建、删除、查看等操作进行了定义。

**runc**

对于OCI标准的一个参考实现，是一个可以用于创建和运行容器的CLI(command-line interface)工具。runc直接与容器所依赖的cgroup/linux kernel等进行交互，负责为容器配置cgroup/namespace等启动容器所需的环境，创建启动容器的相关进程。

**containerd**

为了兼容oci标准，docker也做了架构调整。将容器运行时相关的程序从docker daemon剥离出来，形成了**containerd**。Containerd向docker提供运行容器的API，二者通过grpc进行交互。containerd最后会通过runc来实际运行容器。

OCI  : 容器镜像标准  容器运行时标准

**kubelet拉起一个容器的过程**

![img](https://cdn.jsdelivr.net/gh/631068264/img/202402282129458.jpg)

- Kubelet 通过 CRI 接口（gRPC）调用 dockershim，请求创建一个容器。CRI 即容器运行时接口（Container Runtime Interface），这一步中，Kubelet 可以视作一个简单的 CRI Client，而 dockershim 就是接收请求的 Server。目前 **dockershim 的代码其实是内嵌在 Kubelet 中的**，所以接收调用的凑巧就是 Kubelet 进程；

- docker-shim收到请求后,转化成Docker Daemon能听懂的请求,发到Docker Daemon上请求创建一个容器

- Docker Daemon 早在 1.12 版本中就已经将针对容器的操作移到另一个守护进程——containerd 中了，因此 Docker Daemon 仍然不能帮我们创建容器，而是要**请求 containerd 创建一个容器**

- containerd 收到请求后，并不会自己直接去操作容器，而是创建一个叫做 containerd-shim 的进程，让 containerd-shim 去操作容器。这是因为容器进程需要一个父进程来做诸如收集状态，维持 stdin 等 fd 打开等工作。而**假如这个父进程就是 containerd，那每次 containerd 挂掉或升级，整个宿主机上所有的容器都得退出了。而引入了 containerd-shim 就规避了这个问题（containerd 和 shim 并不是父子进程关系）**；
- 我们知道创建容器需要做一些设置 namespaces 和 cgroups，挂载 root filesystem 等等操作，**而这些事该怎么做已经有了公开的规范了，那就是 OCI（Open Container Initiative，开放容器标准）。它的一个参考实现叫做 runC。于是，containerd-shim 在这一步需要调用 runC 这个命令行工具，来启动容器**

- runC 启动完容器后本身会直接退出,containerd-shim则会成为容器进程的父进程,负责收集容器进程的状态,上报给containerd，并在容器中 pid 为 1 的进程退出后接管容器中的子进程进行清理，确保不会出现僵尸进程。

[Docker 的资源隔离Namespace](docker/2021-05-30-docker隔离原理.md#Docker 的资源隔离Namespace)

[Docker 的资源限制：cgroups](docker/2021-05-30-docker隔离原理.md#Docker 的资源限制：cgroups)

[cgroup v2](docker/2021-05-30-docker隔离原理.md#cgroup v2)

# k8s

## QA

怎样加强 机器学习平台的GPU 使用率

- 共享GPU  Utilize GPU sharing to maximize GPU usage among multiple users or tasks.
- serverless  dynamically allocate and release GPU resources as needed.
- 调整batch_size, 多卡多级并行  Adjust batch size and explore multi-GPU and multi-node parallelism techniques to optimize GPU usage.
- 训练数据和ck使用对象存储，预热先本地再异步，多级缓存  Store training data and checkpoints in object storage, and implement caching strategies to minimize data transfer and improve efficiency.
- 优化ck保存流式 & 分块上传的方式，存储异步分片 Optimize checkpoint saving by using streaming and asynchronous methods, and consider using asynchronous chunked uploads for storage
- 优化调度策略 Improve scheduling strategies to efficiently allocate GPU resources based on workload demands
- 算法优化 impore algorithm

应付峰值流量

- HPA pod扩缩容/ VPA 自动缩放单个 Pod 可用资源  **避免同时使用 HPA 和 VPA——HPA 和 VPA 不兼容** 
- serverless
- Cluster Autoscaler，将 VPA 与 Cluster Autoscaler 一起使用 - VPA 有时可能会推荐超出可用资源的资源请求值
- **优化Pod调度策略**： 确保Pod在集群中均匀分布，避免某些节点过载
- 模拟高流量情况，测试系统的响应能力和资源分配的有效性。使用Prometheus和Grafana等工具监控资源使用情况和服务性能。Simulate high traffic  to test the system's response capacity .Monitor resource usage and service performance using tools like Prometheus and Grafana.



operator管理上万RC, 最佳实践 有些什么注意的地方  owner reference









## 过程

[k8s 资源更新](k8s/2022-04-30-k8s 更新.md)

[k8spod启动过程](k8s/2023-01-01-k8spod启动过程.md)

[CRI](k8s/2022-01-31-cri.md)    kubelet通过CRI（container runtime interface）的标准来与外部容器运行时进行交互。主要定义两个接口, ImageService和RuntimeService。 CRI is the interface defined by Kubernetes. It is used to communicate with different container runtimes. 

**containerd** is a lightweight container runtime that implements the CRI  (实现CRI). It can manage container lifecycle and image.

**OCI** define  format and content of the image and what is container runtime (规范镜像和容器运行时)

**runc** is a container runtime tool that complies with the OCI standards and  manage the lifecycle of containers.  (符合OCI规范的实现，管理容器生命周期)

[RuntimeClass](k8s/2022-01-31-cri.md#RuntimeClass)

- RuntimeClass 是 Kubernetes 一种内置的全局域资源，主要用来解决多个容器运行时混用的问题；
- RuntimeClass 中配置 Scheduling 可以让 Pod 自动调度到运行了指定容器运行时的节点上。但前提是需要用户提前为这些 Node 设置好 label；
- RuntimeClass 中配置 Overhead，可以把 Pod 中业务运行所需意外的开销统计进来，让调度、ResourceQuota、Kubelet Pod 驱逐等行为更准确。
- Pod配置：当用户创建一个Pod时，他们可以通过在Pod规范中指定RuntimeClassName字段来选择要使用的RuntimeClass。这样，Pod就会与指定的运行时关联起来。

[探针总结](k8s/2021-12-19-k8s 探针.md#探针总结)



[其他资源类型 DaemonSet  Job](k8s/2021-10-16-k8s对象2 其他pod类型.md)



## pod

- 作为Kubernetes中最小的调度单元，用于部署和运行容器。
- 为容器提供网络和存储资源，使得容器可以在网络上通信并且可以共享存储卷。
- 为容器提供访问权限控制，使得不同的容器之间可以相互隔离。
- 为容器提供统一的身份验证和授权机制，使得不同的容器可以使用相同的身份进行认证和授权。

[pause](k8s/2021-10-16-k8s对象1 pod.md#pod 共享)

每个 `Pod` 都有一个特殊的被称为 **“根容器”** 的 `Pause` 容器。`Pause` 容器对应的镜像属于 `Kubernetes` 平台的一部分，通过 `Pause` 容器使工作在对应 `Pod` 的容器之间可以**共享网络**、**共享存储**。

[Init 容器](k8s/2021-10-16-k8s对象1 pod.md#了解 Init 容器)

1. Init容器之间顺序执行 excution in order
2. Init容器不能直接访问(directly access)主容器的网络和存储资源，但可以通过共享的空白卷（emptyDir）或其他共享卷来实现信息传递。
3. 初始化任务：Init容器常用于执行与主容器相关的初始化任务，例如加载配置文件、初始化数据库、执行数据预处理等。通过Init容器，可以确保在主容器启动之前，所需的初始化任务已经完成。 (init tasks)
4. 依赖解决：Init容器还可以用于解决主容器启动所需的依赖关系。(Dependency resolution)
5. 生命周期：一旦所有的Init容器成功完成并退出，主容器将启动并开始正常运行。

[状态和策略](k8s/2021-10-16-k8s对象1 pod.md#状态和策略)

[静态pod](k8s/2021-10-16-k8s对象1 pod.md#静态pod) 使用静态Pod可以有效预防通过kubectl、或管理工具操作的误删除，可以利用它来部署一些核心组件应用，保障应用服务总是运行稳定数量和提供稳定服务。

静态 Pod 直接由特定节点上的`kubelet`进程来管理，**不通过 master 节点上的`apiserver`**。无法与我们常用的控制器`Deployment`或者`DaemonSet`进行关联，**它由`kubelet`进程自己来监控**，当`pod`崩溃时重启该`pod`，`kubelete`也无法对他们进行健康检查。

**静态 pod 始终绑定在某一个`kubelet`，并且始终运行在同一个节点上。**

`kubelet`会自动为每一个静态 pod 在 Kubernetes 的 apiserver 上创建一个镜像 Pod（Mirror Pod），**因此我们可以在 apiserver 中查询到该 pod，但是不能通过 apiserver 进行控制（例如不能删除）。**

[pod 优雅退出](k8s/2021-10-16-k8s对象1 pod.md#pod 优雅退出)

## Deploy sts

**[ReplicationController](k8s/2021-10-16-k8s对象3 rc rs.md#ReplicationController) 简称为 RC**，同时也是 kubectl 命令的快捷方式简写使用方式，是**用来确保容器应用的副本数始终保持在用户定义的副本数**。自动创建新的 Pod 来替代，而如果有异常多出来的容器也会被自动回收掉的。

**[ReplicaSet](k8s/2021-10-16-k8s对象3 rc rs.md#ReplicaSet) ** 是 ReplicationController 的升级版本。它提供了更强大的选择器和筛选功能，支持使用集合表达式来定义 Pod 的副本数量。ReplicaSet 用于定义和维护一组 Pod 的副本，确保它们的数量与所需的副本数量匹配，并在 Pod 发生故障或需要进行扩展时自动进行调整。

**RS 跟 RC 的唯一区别是在选择器的支持上。其中 RS 支持集集合(selector)的选择器，其就意味着其支持通过标签进行 Pod 的选择，而 RC 仅支持基于相等选择器。**



[Deployment](k8s/2021-10-16-k8s对象4 deploy sts.md#Deployment)建立在 ReplicaSet 之上，提供了更高级的功能，如滚动更新和回滚，以及简化的声明式配置。

Deployment 资源对象实际上会**创建和管理不同版本的** **ReplicaSet**。当您创建一个 Deployment 时，它会自动创建一个 ReplicaSet，并根据您定义的副本数量和其他规范来管理 Pod 的副本。

**[滚动更新](k8s/2021-10-16-k8s对象4 deploy sts.md#更新)**是 Deployment 的一个重要功能，用于无缝地更新应用程序。它通过逐步创建和删除 Pod 副本来实现更新。**滚动更新确保在整个更新过程中应用程序始终可用**，并提供可配置的策略，如最大不可用性和最大并发度。

[回滚](k8s/2021-10-16-k8s对象4 deploy sts.md#回滚)

Deployment 生成**新版本的 ReplicaSet** 取决于您对 Deployment 进行的更新操作。这些操作可能包括创建新的 Deployment、执行滚动更新、更新 Deployment 的规范或手动创建新版本的 ReplicaSet。



[sts](k8s/2021-10-16-k8s对象4 deploy sts.md#StatefulSet)

StatefulSet 维护一组有唯一标识的 Pod，这些 Pod 按顺序启动和终止，并且具有稳定的网络标识符和持久性存储。

**StatefulSet 和 Deployment 之间有几个关键区别**：

- Pod 的稳定标识符：StatefulSet 为每个 Pod 分配一个唯一的标识符，而 Deployment 的 Pod 是无序和无标识符的。
- 网络标识符：StatefulSet 中的 Pod 具有稳定的网络标识符，可以在集群内部和外部进行访问，而 Deployment 的 Pod 使用临时的 IP 地址。
- 持久性存储：StatefulSet 中的 Pod 可以使用持久性存储卷，而 Deployment 中的 Pod 通常使用临时存储卷。
- 有序部署和扩展：StatefulSet 可以按照指定的顺序启动和终止 Pod，而 Deployment 并不保证启动和终止的顺序。

[sts 细节](k8s/2021-10-16-k8s对象4 deploy sts.md#注意事项)

## Service

| 编号 | 类型               | 用途介绍                                                     |
| :--- | :----------------- | :----------------------------------------------------------- |
| 1    | **`ClusterIp`**    | 默认类型；自动分配一个仅 `Cluster` 内部可以访问的虚拟 `IP` 地址 |
| 2    | **`NodePort`**     | 在 `ClusterIP` 基础上为 `Service` 在每台机器上绑定一个端口，这样就可以通过 `:NodePort` 来访问该服务 |
| 3    | **`LoadBalancer`** | 在 `NodePort` 的基础上，借助 `cloud provider` 创建一个外部负载均衡器，并将请求转发到 `:NodePort` 来访问该服务 |
| 4    | **`ExternalName`** | 把集群外部的服务引入到集群内部来，在集群内部直接使用。没有任何类型代理被创建，这只有 `Kubernetes1.7` 或更高版本的 `kube-dns` 才支持 |

IPVS与iptables区别：

- **iptables 是一个 Linux 内核功能，是一个高效的防火墙，并提供了大量的数据包处理和过滤方面的能力。**它可以在核心数据包处理管线上用 Hook 挂接一系列的规则。iptables 模式中 kube-proxy 在 `NAT pre-routing` Hook 中实现它的 NAT 和负载均衡功能。这种方法简单有效，依赖于成熟的内核功能，并且能够和其它跟 iptables 协作的应用（例如 Calico）融洽相处。

  然而 **kube-proxy 的用法是一种 O(n) 算法，其中的 n 随集群规模同步增长，这里的集群规模，更明确的说就是服务和后端 Pod 的数量。**

- **IPVS 是一个用于负载均衡的 Linux 内核功能。**IPVS 模式下，kube-proxy 使用 IPVS 负载均衡代替了 iptable。这种模式同样有效，IPVS 的设计就是用来为大量服务进行负载均衡的，它有一套优化过的 API，使用优化的查找算法，而不是简单的从列表中查找规则。

  这样一来，**kube-proxy 在 IPVS 模式下，其连接过程的复杂度为 O(1)。换句话说，多数情况下，他的连接处理效率是和集群规模无关的。**

  另外作为一个独立的负载均衡器，**IPVS 包含了多种不同的负载均衡算法**，例如轮询、最短期望延迟、最少连接以及各种哈希方法等。而 iptables 就只有一种随机平等的选择算法。

- 为什么不用nginx之类的：负载均衡功能都强大，但毕竟还是基于用户态转发或者反向代理实现的，性能必然不如在内核态直接转发处理好

iptables 与 IPVS 虽然都是基于 Netfilter 实现的，但因为定 位不 同，二者有 着本质的差 别: iptables 是为防火墙设计的; IPVS 专门用于高性能负载均衡，并使用更高效的数据结 构 I: 哈希表)，允许几乎无限的规模扩张

**iptables 规则链是一个线性数据结构， ipset 则引入了带索引的数据结构，因此当规则 很多时，也可以高效地查找和匹配 。 我们可以将 ipset 简单理解为一个 IP (段)的集合， 这个集合的内容可以是 IP 地址、 IP 网段 、 端口等， iptables 可以直接添加规则对这个“可 变的集合”进行操作，这样做的好处在于大大减少了 iptables 规则的数量，从而减少了性 能损耗 。**



[Headless](k8s/2021-10-16-k8s对象5 service.md#Headless)
有时不需要或不想要负载均衡，以及单独的 `Service IP`。遇到这种情况，可以通过指定 `Cluster IP`(`spec.clusterIP`) 的值为 **“None”** 来创建 `Headless Service`。这类 `Service` 并不会分配 `Cluster IP`，`kube-proxy` 不会处理它们，而且平台也不会为它们进行负载均衡和路由。







## 流量

service 和 pod 之间可以直接进行通信，它们的通信属于局域网通信。通过**标签选择器 selector**关联service 和 pod

Services and Pods can communicate directly with each other，through label selectors

Endpoint 是 Kubernetes 中的一种资源对象，用于表示一个 Service 的后端 Pod 的集合。  Endpoint is the collection of backend Pods for a Service

kube-proxy 监视和更新 Endpoints 对象，以了解 Service 的后端 Pod 的变化，并相应地更新 iptables 规则，通过NAT 转换实现确保流量能够正确地路由到后端 Pod。kube-proxy monitors and updates the Endpoints object to track changes in the backend Pods of a Service and updates the iptables rules accordingly, using NAT translation to ensure that traffic is correctly routed to the backend Pods.

endpoints 那些都是存储在 etcd 里的，所以 **kube-proxy** 更新的存储在 etcd 里的映射关系。the mapping is stored in etcd, and kube-proxy updates this mapping.

把请求交给 service 后，service 使用 [iptables](k8s/网络/key/2022-06-05-endpoints.md#iptabls流量)，[ipvs](k8s/网络/key/2022-06-05-endpoints.md#ipvs)来实现数据包的分发

the Service uses iptables or IPVS to distribute the traffic among the backend Pods



Service的后端是一组Endpoint列表，为客户端应用提供了极大的便利。但是随着集群规模的扩大及Service数量的增加，特别是Service后端Endpoint数量的增加，kube-proxy需要维护的负载分发规则(例如iptables规则或)pvs规则)的数噩也会急剧增加，导致后续对Service后端Endpoint的添加、删除等更新操作的成本急剧上升。[EndpointSlices](k8s/网络/key/2022-06-05-endpoints.md#端点分片 (EndpointSlices))

the number of Services and backend Endpoints increases in a cluster, kube-proxy needs to maintain a large number of load balancing rules

EndpointSlices provide a more scalable and efficient way to manage and update the backend Pods of a Service, reducing the overhead of maintaining load balancing rules and improving the performance of kube-proxy.





## 网络

CNI is an interface for config and manage the container network , enable different container runtimes to interact with various network plugins.(用于容器网络配置和管理，使得不同的容器运行时可以与各种网络插件进行交互)





[网络命名空间](k8s/网络/key/2022-07-03-网络.md#网络命名空间)

[Veth](k8s/网络/key/2022-07-03-网络.md#网络命名空间) 设备对也是连通容器与宿主 机的主要网络设备，离开它是不行的 。Virtual interface pairs connect different network namespaces or containers.



[网桥](k8s/网络/key/2022-07-03-网络.md#网桥) 用于连接多个网络接口，实现不同网络之间的数据转发。在Kubernetes中，网桥通常用于实现Pod与宿主机之间的网络通信。

connect multiple network interfaces and enable data forwarding between different networks. In Kubernetes, bridges are often used to network communication between Pods and the host machine.

**[Netfilter](k8s/网络/key/2022-07-03-网络.md#iptables 和 Netfilter)**负责在内核中执行各种挂接的规则，运行在内核模式中 

**iptables** 是在用 户模式下运行的进程，hook负责协助和维护内核中 Netfilter 的各种规则表



[docker 网桥](k8s/网络/key/2022-07-03-网络.md#docker网络实现)   它会自动创建三个网络，bridge（创建容器默认连接到此网络）、 none 、host



[k8s 同一个pod  网络实现](k8s/网络/key/2022-07-03-网络.md#同一个pod)

**同一个 Pod 内的容器 (Pod 内的容器是不会跨宿主机的)共享同一个网络命名空间，共享同一个 Linux 协议栈。**In a Pod, the containers share the same network namespace and Linux protocol stack. This means that containers within the same Pod do not cross host boundaries and have their own isolated network environment.

1. Pod 在节点上拥有独立的网络命名空间。当创建 Pod 时，**container running time会给容器创建一个网络命名空间。**When a Pod is created, the container running time will create a network namespace for each container.
2. CNI 负责给 Pod 分配一个 IP 地址，两个容器之间共享端口。(CNI) is responsible for assigning an IP address to the Pod and enabling port sharing between the containers.
3. 两个容器共享相同的网络命名空间，并在本地彼此可见。The two containers within the Pod share the same network namespace and can communicate with each other locally.

当你创建一个 Pod，Pod 被分配给一个节点后，CNI 将：

1. 分配 IP 地址。Allocate an IP address.
2. 将容器连接到网络。Connect the containers to the network.

如果 Pod 包含多个容器，那么这些容器都将被放在同一个命名空间中。**节点上的每一个 Pod 都会有一个对应的 pause 容器。这个`pause`容器负责创建和维持网络命名空间。**Each Pod on a node has a corresponding pause container. This `pause` container is responsible for creating and maintaining the network namespace.

[k8s 不同pod  网络实现](k8s/网络/key/2022-07-03-网络.md#不同pod)

整个工作流依赖于虚拟接口veth pairs对和网桥 bridge

**同一个节点**：Podl 和 Pod2 都是通过 Veth 连接到同一个 dockerO 网桥的，它们的 IP 地址 IPl 、 IP2 都是从 dockerO 的网段上动态获取的，和网桥本身的 IP3 属于同 一 个网段

Pod1 and Pod2 are both connected to the same docker0 bridge via Veth. Their IP addresses, IP1 and IP2,are dynamically obtained from the docker0 network range, and they belong to the same subnet as the IP3 of the bridge itself.

由于它们都关联在同 一 个 dockerO 网桥上，地址段相同，所以它们之间是能直接通信的 。they are both associated with the same docker0 bridge and have the same address range, they can communicate with each other directly.

**不同节点**：

**Pod 的地址是与 dockerO 在同一个网段的，我们知道 dockerO 网段与宿主机网卡是两个 完全不同的 IP 网段**，并且不同 Node 之间的通信只能通过宿主机的物理网卡进行 ， 因此要 想实现不同 Node上 Pod容器之间的通信，就必须想办法通过主机的这个 IP地址进行寻址 和通信 。The IP address of the Pod is in the same subnet as the docker0 bridge. We know that the docker0 subnet is completely different from the IP subnet of the host machine's network interface. Communication between different nodes can only be achieved through the physical network interface of the host machine. Therefore, in order to enable communication between Pod containers on different nodes, we must find a way to address and communicate through the IP address of the host machine.

**这些动态分配且藏在 dockerO 后的“私有 “IP 地址也是可以找到的 。 Kubernetes 会记录所有正在运行的 Pod 的 IP 分配信息，并将这些信息保存在 etcd 中(作 为 Service 的 Endpoint)。**

Kubernetes keeps track of the IP allocation information for all running Pods and stores this information in etcd as the Endpoints of the Service.   

Pod 中的数据在发出 时 ，需要有一个机 制 能够知道对方 Pod 的 IP 地址挂在哪个具体的 Node 上 。 也就是说 ， 先要找到 Node 对应宿 主 机的 IP 地址，将数据 发送到这个宿主机的网卡，然后在宿主机上将相应的数据转发到具体的 dockerO 上 。 一 旦数据到达宿主机 Node, 那个 Node 内部的 dockerO 便知道如何将数据发送到 Pod 了

we need to first find the IP address of the Node corresponding to the Pod and send the data to the network interface of that Node. Then, on the Node, the data will be forwarded to the appropriate Docker container.

Once the data reaches the Node, the Docker container within that Node knows how to send the data to the specific Pod.



[CNI  配置](k8s/网络/key/2022-01-30-k8s网络模型3 CNI.md#Kubernetes 中如何使用 CNI)

Kubelet 监听到这个 Pod 的创建之后，会在本地进行一些创建的操作。

当执行到创建网络这一步骤时，首先它会读取刚才我们所说的**配置目录中的配置文件**，配置文件里面会声明所使用的是哪一个插件，然后去**执行具体的 CNI 插件的二进制文件**，再**由 CNI 插件进入 Pod 的网络空间去配置 Pod 的网络**。配置完成之后，Kuberlet 也就完成了整个 Pod 的创建过程，这个 Pod 就在线了。

[自定义CNI](k8s/网络/key/2022-01-30-k8s网络模型3 CNI.md#开发自己的 CNI 插件)

- **一个二进制的 CNI 插件去配置 Pod 网卡和 IP 地址**。这一步配置完成之后相当于给 Pod 上插上了一条网线，就是说它已经有自己的 IP、有自己的网卡了
- **一个 Daemon 进程去管理 Pod 之间的网络打通**。这一步相当于说将 Pod 真正连上网络，让 Pod 之间能够互相通信。
- **配置Network Policy**（不一定每个插件支持）

![img](https://cdn.jsdelivr.net/gh/631068264/img/202402141710599.jpg)

- Pod 的创建速度

  当我们创建一组 Pod 时，比如业务高峰来了，需要紧急扩容，这时比如说我们扩容了 1000 个 Pod，就需要 CNI 插件创建并配置 1000 个网络资源。**Overlay 和路由模式在这种情况下的创建速度是很快的，因为它是在机器里面又做了虚拟化，所以只需要调用内核接口就可以完成这些操作。但对于 Underlay 模式，由于需要创建一些底层的网络资源，所以整个 Pod 的创建速度相对会慢一些。**因此对于经常需要紧急扩容或者创建大批量的 Pod 这些场景，我们应该尽量选择 Overlay 或者路由模式的网络插件。

- **Pod 的网络性能**

  主要表现在两个 Pod 之间的网络转发、网络带宽、PPS 延迟等这些性能指标上。**Overlay 模式的性能较差，因为它在节点上又做了一层虚拟化，还需要去封包，封包又会带来一些包头的损失、CPU 的消耗等，如果大家对网络性能的要求比较高，比如说机器学习、大数据这些场景就不适合使用 Overlay 模式。**这种情形下我们通常选择 Underlay 或者路由模式的 CNI 插件。

Flannel

- 使用虚拟以太网virtual Ethernet （VXLAN或者UDP封装）来为容器提供网络连接。provide network connectivity for containers
- 特点: Flannel的部署简单，性能较好，适用于需要跨主机通信的多主机容器集群。它支持多种后端驱动，如VXLAN、UDP、Host-GW等。It is known for its simple deployment, good performance, and suitability for multi-host container clusters that require cross-host communication. Flannel supports various backend drivers such as VXLAN, UDP, and Host-GW.

[Calico](k8s/第三方组件/rancher/2023-03-09-rancher cni.md#Calico)

Calico使用标准的IP路由协议（如BGP）来实现容器之间的通信。通过路由表进行转发。容器之间的通信是直接的，无需网络隧道。避免overlay 网络开销 IP routing protocols like BGP to enable communication between containers.  It relies on routing tables for forwarding and allows direct communication between containers without the need for network tunnels which avoid overlay network overhead.

Canal

既具备了Flannel的简单部署和跨主机通信的特点，又具备了Calico的高度可扩展和灵活网络策略的特点。

Canal combines the simplicity of Flannel's deployment and cross-host communication capabilities with Calico's highly scalable and flexible network policy features.

## 存储

CSI  用于容器编排平台与存储系统之间的通信，实现动态挂载和管理容器的持久化存储

communication between k8s and storage systems， It enables dynamic mounting and management of persistent storage for containers.





**K8s 集群中的管控组件，会结合 PVC 和 StorageClass 的信息动态，生成用户所需要的存储（PV），将 PVC 和 PV 进行绑定后，pod 就可以使用 PV 了。**通过 StorageClass 配置生成存储所需要的存储模板，再结合用户的需求动态创建 PV 对象，做到按需分配，在没有增加用户使用难度的同时也解放了集群管理员的运维工作。



[PV的访问模式](k8s/存储/2021-10-17-k8s存储2 pv pvc.md#PV 访问模式)有三种：

- ReadWriteOnce

  - 该卷可以被单个节点以读/写模式挂载，允许运行在同一节点上的多个 Pod 访问卷
  - 在命令行中访问模式缩写为：RWO

- ReadOnlyMany

  - 该卷可以被多个节点以只读模式挂载
  - 在命令行中访问模式缩写为：ROX

- ReadWriteMany

  - 该卷可以被多个节点以读/写模式挂载
  - 在命令行中访问模式缩写为：RWX

[挂载过程](k8s/存储/2022-01-16-k8s-存储架构插件使用.md#k8s挂载volume过程)

有三个阶段：第一个 create 阶段，主要是创建存储；第二个 attach 阶段，就是将那块存储挂载到 node 上面(通常为将存储load到node的/dev下面)；第三个 mount 阶段，将对应的存储进一步挂载到 pod 可以使用的路径。这就是我们的 PVC、PV、已经通过CSI实现的卷从创建到使用的完整流程。

[k8s存储架构](k8s/存储/2022-01-16-k8s-存储架构插件使用.md)

- [**PV Controller**:](k8s/存储/2022-01-16-k8s-存储架构插件使用.md#PV Controller ) 负责 PV/PVC 的绑定、生命周期管理，并根据需求进行数据卷的 Provision/Delete 操作

- **[AD Controller](k8s/存储/2022-01-16-k8s-存储架构插件使用.md#AD Controller)**： 负责存储设备的 Attach/Detach 操作，将设备挂载到目标节点

- **[Volume Manager](k8s/存储/2022-01-16-k8s-存储架构插件使用.md#Volume Manager)**： 管理卷的 Mount/Unmount 操作、卷设备的格式化以及挂载到一些公用目录上的操作

- **[Volume Plugins](k8s/存储/2022-01-16-k8s-存储架构插件使用.md#Volume Plugins)**：它主要是对上面所有挂载功能的实现。

  PV Controller、AD Controller、Volume Manager 主要是进行操作的调用，而具体操作则是由 Volume Plugins 实现的。

- **[Scheduler](k8s/存储/2022-01-16-k8s-存储架构插件使用.md#Kubernetes 存储卷调度)**： 实现对 Pod 的调度能力，会根据一些存储相关的的定义去做一些存储相关的调度。



[pv状态流转](k8s/存储/2022-01-16-k8s-存储架构插件使用.md#PV 的状态迁移图)

![img](https://cdn.jsdelivr.net/gh/631068264/img/202402142051204.jpg)

[PVC 的状态迁移图](k8s/存储/2022-01-16-k8s-存储架构插件使用.md#PVC 的状态迁移图)

![img](https://cdn.jsdelivr.net/gh/631068264/img/202402142052022.jpg)

[CSI 原理](k8s/存储/2022-10-04-k8s-csi.md)

![image-20221004112609766](https://cdn.jsdelivr.net/gh/631068264/img/202402142103271.jpg)

CSI Controller 的主要功能是**提供存储服务视角对存储资源和存储卷进行管理和操作** 。 在 Kubernetes 中建议将其部署为单实例 Pod，可以使用 StatefuISet或 Deployment控制器进 行部署，设置副本数最为 1保证一种存储插件只运行一个控制器实例

- 与 Master (kube-controller-mapager) 通信的辅助 sidecar容器
- CSI Driver存储驱动容器

CSI Node 的主要功能是**对主机 (Node) 上的 Volume 进行管理和操作** 。 在 Kubemetes 中建议将其部署为 DaemonSet, 在需要提供存储资源的各个 Node 上都运行一个 Pod





## 组件

Kubernetes（简称为K8s）是一个开源的容器编排平台，由多个组件组成，用于管理和调度容器化应用程序。以下是Kubernetes的主要组件：

1. Master组件：
- [kube-apiserver](k8s/组件/2022-06-11-api server.md)：提供API服务，用于与Kubernetes集群进行交互。 Provide API services for interacting with Kubernetes clusters

  - [API Server 中资源对象的 List-Watch 机制 ](k8s/组件/2022-06-11-api server.md#API Server 中资源对象的 List-Watch 机制)
  - [集群功能模块之间的通信](k8s/组件/2022-06-11-api server.md#集群功能模块之间的通信)
  - api 并发
    - 并发处理参数调优：kube-apiserver提供了一些可以调整的参数，以优化并发处理能力。
    - APIServer拥有大量高性能的底层代码。在APIServer源码中**使用协程 (Coroutine)+ 队列 (Queue) 这种轻量级的高性能并发代码**，使得单进程的 API Server 具备超强的多核 处理能力，从而以很快的速度并发处理大盘的请求 。
    - 普通 List接口结合异步 Watch接口，不但完美解决了 Kubemetes 中各种资源对象 的高性能同步问题，也极大提升了 Kubemetes 集群实时响应各种事件的灵敏度 。
    - 采用了高性能的 etcd 数据库而非传统的关系数据库，不仅解决了数据的可靠性问 题，也极大提升了 API Server 数据访问层的性能 。
- [kube-controller-manager](k8s/组件/2022-06-12-controller-manager.md)：负责运行控制器，监控集群状态并进行调节。 for running controllers, monitoring cluster status, and making adjustments.

  **它们通过 API Server 提供的 (List-Watch) 接口实时监控集群中特定资源的状态变化，当发生各种故障导致某 资渥对象的状态变化时， Controller 会尝试将其状态调整为期望的状态 。**They use the (List-Watch) interface provided by the API Server to monitor the real-time status changes of specific resources in the cluster. When various failures occur and cause the state of a resource object to change, the Controller will attempt to adjust its state to the desired state.

  每种 Controller都负责一种特定资源的控制流程，而 Controller Manager 正 是这些 Controller 的核心管理者 。
- [kube-scheduler](k8s/组件/2022-06-12-scheduler.md)：负责将Pod调度到集群中的节点上。 scheduling Pods onto nodes in the cluster.

  - [调度过程](k8s/集群调度/2021-10-17-k8s集群调度.md#调度过程)
  - predicate：过滤掉不满足条件的节点 Filter out nodes that do not meet the conditions.
  - priority：然后对通过的节点按照优先级排序   sort the nodes that pass the predicate based on priority
  - 如果在 predicate 过程中没有合适的节点，pod 会一直在 pending 状态，不断重试调度，直到有节点满足条件。经过这个步骤，如果有多个节点满足条件，就继续 priorities 过程  If there are no suitable nodes during the predicate process, the pod will remain in a pending state and continuously retry scheduling until a node meets the conditions. After this step, if multiple nodes meet the conditions, the priorities process continues.
  - 之后，调度器将这个调度决定通知给 kube-apiserver，这个过程叫做 绑定。The scheduler notifies the kube-apiserver of this scheduling decision, a process called binding.
  - [自定义如何扩展调度器](k8s/集群调度/2022-01-09-k8s集群调度3.md)
    
     [Scheduler Extender](k8s/集群调度/2022-01-09-k8s集群调度3.md#Scheduler Extender])
     
     - Filter：用于确定一个 Node 是否可以放置一个 Pod；
     - Priority：用于确定一个 Pod 与一个 Node 的匹配程度；
     - Bind：将一个 Pod 绑定到一个 Node 中；
       
     
     [Scheduler Framework](k8s/集群调度/2022-01-09-k8s集群调度3.md#Scheduler Framework])  多个注入点

     [高级资源调度](k8s/集群调度/2022-01-03-k8s集群调度2.md#资源调度)
     
     [调度优先级](k8s/集群调度/2022-01-03-k8s集群调度2.md#高级调度)

     [节点亲和性 nodeAffinity ](k8s/集群调度/2021-10-17-k8s集群调度.md#节点亲和性)
     
     [pod亲和性 podAffinity](k8s/集群调度/2021-10-17-k8s集群调度.md#Pod 亲和性)
     
     [污点**Taint**](k8s/集群调度/2021-10-17-k8s集群调度.md#污点**Taint**)
     
     [容忍 **Tolerations**](k8s/集群调度/2021-10-17-k8s集群调度.md#容忍 **Tolerations**)
     
     [驱逐](k8s/集群调度/2022-10-06-k8s驱逐机制.md)

2. Node组件：
- [kubelet](k8s/组件/2022-06-18-kubelet.md)：运行在每个节点上，负责管理节点上的容器和Pod。  runs on each node and is responsible for managing the containers and pods on the node.
- [kube-proxy](k8s/组件/2022-06-18-kube-proxy.md)：负责为Pod提供网络代理和负载均衡功能。providing network proxy and load balancing functionality for pods.

3. etcd：
- [etcd](k8s/组件/2022-01-02-k8s etcd.md)是一个分布式键值存储系统，用于保存Kubernetes集群的配置数据。  Etcd is a distributed key-value store system used to store the configuration data of the Kubernetes cluster.

## CRD

[crd controller 概况](k8s/crd/key/2022-07-23-crd.md#controller概况)

**Kubernetes 的 Controller Manager 负责监听这些事件并触发相应的任务来满足用户的期望**。这种方式我们称为**声明式**，**用户只需要关心应用程序的最终状态，其它的都通过 Kubernetes 来帮助我们完成，通过这种方式可以大大简化应用的配置管理复杂度。**The Kubernetes Controller Manager is responsible for listening to these events and triggering corresponding tasks to meet user expectations. This approach is known as declarative, where users only need to focus on the desired final state of the application, and Kubernetes takes care of the rest. This greatly simplifies the complexity of application configuration management.

![](https://cdn.jsdelivr.net/gh/631068264/img/202404051336369.jpg)



**Reflector**

- List 用来在 Controller 重启以及 Watch 中断的情况下，进行系统资源的全量更新；
- 通过 **HTTP 长连接** Watch 不断监听得到 etcd 变化的数据，接收 Kubernetes API Server 发来的资源**变更事件**、定时同步的时候都可以获取到资源的期望状态。By using HTTP long polling, the Watch continuously listens for changes in etcd data and receives resource change events sent by the Kubernetes API Server. It can also obtain the desired state of resources during periodic synchronization.
- 当 Watch 监控到集群中有资源对象变化的事件时，会触发 **watchHandler** 回调，将变化的资源**对象放入 Delta FIFO 中**，**同时更新本地缓存**。When the Watch detects a change in a resource object in the cluster, it triggers the watchHandler callback, which puts the changed resource object into the Delta FIFO and updates the local cache at the same time.
- **Delta 队列**中塞入一个包括**资源对象**信息本身以及资源对象**事件类型**的 Delta 记录，Delta 队列中可以保证同一个对象在队列中仅有一条记录，从而避免 Reflector 重新 List 和 Watch 的时候产生重复的记录。The Delta queue contains Delta records that include information about the resource object itself and the type of event. The Delta queue ensures that there is only one record for the same object in the queue

**Informer** 组件不断地从 Delta 队列中弹出 delta 记录，然后把资源对象交给 **indexer**，之后，再把这个**事件交给事件的回调函数。**The Informer component continuously pops delta records from the Delta queue, then hands the resource objects to the indexer, and finally passes the event to the event callback function.

减轻的 apiserver 和 etcd 的负担

- 一个GroupVersionResource一个informer，Shared Informer 共享机制，同类型的资源对象共享一个 Informer，因此同类型的资源对象获取后只需要进行一次 apiserver 的 List 和 Watch 请求 Each GroupVersionResource has its own informer. The Shared Informer mechanism allows multiple instances of the same resource type to share a single informer. Therefore, after get the resource objects of the same type, only one List and Watch request to the apiserver is needed.

- 维护Indexer 本地存储，Control Loop 通过索引可直接从缓存中获取资源对象的数据，不需要再和 apiserver 进行交互

  The Indexer maintains local storage. The Control Loop can directly retrieve the data of resource objects from the cache through indexing, without the need to interact with the apiserver again.

**Indexer**

用来存储资源对象并自带索引功能的本地存储，Reflector 从 DeltaFIFO 中将消费出来的资源对象存储到 Indexer，Indexer 与 Etcd 集群中的数据完全保持一致。从而 client-go 可以本地读取，减少 Kubernetes API 和 Etcd 集群的压力。

store resource objects。get resource objects from delata and store them  which maintains data consistency with the Etcd cluster,

reducing the load on the Kubernetes API and Etcd cluster.

ThreadSafeStore 是一个**并发安全内存中存储**，通常使用[MetaNamespaceKeyFunc](https://github.com/kubernetes/client-go/blob/master/tools/cache/store.go)定义key（`meta.namespace/meta.name` ），value 用于存储资源对象。

可以被 Controller Manager 或多个 Controller 所共享。

apiextensions-apiserver是Kubernetes中的一个组件，用于支持自定义资源的创建和管理。

![image-20220211113059544](https://cdn.jsdelivr.net/gh/631068264/img/e6c9d24egy1h4118fnnhnj21gs0q4adm.jpg)

[crd是怎么被发现的](k8s/crd/key/2022-07-23-crd.md#crd是怎么被发现的)



## 资源

Requests 调度时所需的最小资源量

limits 使用的资源的最大量

[QoS pod 服务质量](k8s/资源/2021-10-24-k8s管理容器资源.md#QoS pod 服务质量)

[cgroup 管理](k8s/资源/2021-10-24-k8s管理容器资源.md#cgroup 管理)

**GPU**

GPU 容器和普通容器之间的差别，仅仅在于**需要将宿主机的GPU设备和 Nvidia 驱动库映射到容器中**。

部署：Nvidia驱动，docker nvida runtime, [Nvidia device plugin](k8s/资源/2022-01-15-k8s-GPU.md#Device Plugin 工作机制)

**调度器 + device plugin** 组成

device plugin  注册到Kubelet  插件会在`/var/lib/kubelet/device-plugins/`目录下注册一个socket文件，kubelet通过这个socket与插件进行通信。The device plugin registers a socket file in the '/var/lib/kubelet/device-plugins/' directory, allowing communication between the plugin and kubelet.

device plugin 实现ListAndWatch方法来上报节点上的设备资源。在该方法中，插件会定期向kubelet汇报设备的列表，并提供健康检查机制。the device plugin implements the ListAndWatch method. This method periodically sends the list of devices to kubelet and includes a health check mechanism.

当kubelet检测到一个Pod中的容器请求使用某个设备时，它会向设备插件发起Allocate方法的请求。该请求会传递容器需要使用的设备ID。设备插件会根据这些设备ID找到对应的设备路径和驱动目录，并将这些信息返回给kubelet。When kubelet detects a request from a container in a Pod to use a specific device, it sends an Allocate request to the device plugin. This request includes the device ID required by the container. The device plugin then retrieves the device path and driver directory corresponding to the device ID and returns this information to kubelet.

kubelet会将设备插件返回的设备信息添加到容器运行时接口（CRI）请求中。当该CRI请求传递给容器运行时（如Docker）时，容器将获得所需的设备，并将其对应的驱动目录挂载到容器中。Kubelet adds the device information returned by the device plugin to the Container Runtime Interface (CRI) request. When this CRI request is passed to the container runtime, such as Docker, the container will be provided with the required device and the corresponding driver directory will be mounted inside the container.



## [安全](k8s/安全/2022-01-30-k8s-k8s认证授权.md)

[SecurityContext](k8s/资源/2021-10-24-k8s管理容器资源.md#cgroup 管理)

用于定义容器运行时的安全属性和策略。通过设置SecurityContext，可以对容器进行一些安全相关的配置，以增强容器的隔离性和安全性。

[NetworkPolicy](k8s/网络/2021-12-25-k8s网络模型1 network nspolicy 解决方案.md#Network Policy 基本概念)定义了网络规则，用于限制Pod之间的通信。它可以根据IP地址、端口和协议等参数来控制网络访问，提供了细粒度的网络安全配置。

认证和授权是通过使用证书、令牌和凭据来验证用户身份，并根据角色和权限来授权用户访问资源。ServiceAccount用于代表Pod与Kubernetes API进行交互，而Role和RoleBinding定义了特定的角色和权限。

对Kubernetes API的安全性可以通过控制API服务器的访问权限来保护。可以使用TLS证书进行双向认证，使用RBAC配置角色和权限，并使用网络策略限制对API服务器的访问。

敏感数据可以使用Kubernetes的[Secrets](k8s/存储/2021-10-17-k8s存储config sercert.md#Secret)机制进行保护，将敏感信息以加密形式存储在集群中。此外，可以使用TLS证书来加密容器之间的通信。

[审计机制](k8s/日志/2022-10-11-k8s 日志.md#审计机制)

Kubernetes事件和日志可以用于监控和审计集群的安全性。事件可用于记录集群中发生的重要事件，而日志则记录容器和组件的活动，有助于检测潜在的安全问题。

容器镜像的安全性可以通过漏洞扫描工具来评估镜像的安全性，并及时应用补丁来修复已知的漏洞。此外，可以使用容器镜像签名验证机制来确保镜像的完整性和来源可信。

## [K3s](k8s/k3s/2021-12-26-k3s概述.md)

不同点：

- 大小和资源消耗：k3s相对于Kubernetes来说更轻量级，因此它的二进制文件和镜像更小，部署和启动速度更快。k3s还使用较少的内存和CPU资源，适合在资源受限的环境中运行。
- 安装和部署：k3s的安装非常简单，只需要运行一个单独的二进制文件即可。它内置了一些常用的插件和组件，如CoreDNS和kube-proxy，使得整个部署过程更加简化。
- 默认配置：k3s在默认配置中使用了一些不同于Kubernetes的设置。例如，k3s默认启用了本地存储Provider，使用SQLite替代etcd作为默认的数据存储，以及使用Flannel作为默认的网络插件。
- 可插拔组件：k3s支持可插拔的组件，可以选择性地启用或禁用一些Kubernetes的组件。这使得用户可以根据自己的需求进行定制，减少了不必要的资源消耗。

相同点：

- API 兼容性：k3s保持了与标准Kubernetes API的兼容性，因此大多数Kubernetes应用程序和工具可以无缝迁移到k3s上。
- 核心概念和功能：k3s仍然遵循Kubernetes的核心概念和功能，如Pod、Deployment、Service等，因此用户可以使用相同的方式管理和操作容器化应用程序。



RKE1支持在 Docker 容器中运行。它适用于裸机和虚拟化服务器。安装和管理k8s集群。二进制文件，依赖yaml  **基本组件基于docker容器来跑**

k3s k3s server /k3s agent， 基本组件都是二进制跑

RKE2 安全性
![image-20240506195727322](https://cdn.jsdelivr.net/gh/631068264/img/202405061957380.png)

- RKE 1使用Docker作为运行时引擎，RKE 2,k3s已经使用containerd
- RKE2静态pod跑，kubelet管理，RKE1docker容器管理，k3s组件都封装到 二进制，由k3s进程管理
- RKE2继承k3s易用性和部署模式，继承RKE1和k8s的一致性
- RKE2，K3S支持更多的CNI (Cilium 等)
- RKE2, K3s 可以通过rancher的system-upgrade-controller自动升级，RKE不行





## 第三方组件

 [kubeflow.md](k8s/第三方组件/kubeflow/2022-01-28-kubeflow.md) 

![Kubernetes 上的 Kubeflow 架构概述](https://cdn.jsdelivr.net/gh/631068264/img/202406052042064.svg)





 [volcano](k8s/资源/2022-04-15-GPU 适配.md#volcano) 

 [prometheus](k8s/第三方组件/prometheus/2021-11-19-prometheus.md) 

 [karmada](k8s/第三方组件/karmada/2022-07-27-karmada-概念.md) 





网络组件calico 网络类型

kubelet 知道 pod





## 部署

[k3s agent](k8s/k3s/2022-01-15-k3s代理安装.md) 

[k3s coredns](k8s/k3s/2022-03-26-k3s-坑.md)

[集群 备份安装升级](k8s/第三方组件/rancher/2022-04-27-rke k3s升级备份.md)






# 网络IO  同步异步  阻塞

[网络I/O过程](language/py/key/2019-03-05-IO.md#五种IO模型)涉及到**应用进程**以及linux**内核**两个对象，分为两个阶段

- 数据准备：通常涉及等待数据从网络中到达。当所等待分组到达时，它被复制到内核中的某个缓冲区
- 数据拷贝：把数据从内核缓冲区复制到应用进程缓冲区


![](https://cdn.jsdelivr.net/gh/631068264/img/202402091502552.jpg)

## epoll

[epoll 三函数](language/py/key/2019-03-05-IO.md#解决三个问题)

- epoll_create是创建一个epoll句柄
- epoll_ctl是注册要监听的事件类型
- epoll_wait则是等待事件的产生。
  - 水平触发(LT)和边缘触发(ET)是 epoll_wait 的 2 种工作模式
  - 水平触发（LT）模式：
    - 在LT模式下，`epoll_wait`函数会**持续通知应用程序文件描述符上的事件，直到该事件被处理**。
    - 当一个文件描述符上有可读/可写事件发生时，`epoll_wait`会立即返回，并将该事件通知给应用程序。
    - 如果应用程序没有立即处理该事件，下次调用`epoll_wait`时仍然会通知该事件，直到应用程序处理完事件并将文件描述符恢复到非阻塞状态。
  - 边缘触发（ET）模式：
    - 在ET模式下，`epoll_wait`函数只在文件描述符上的事件**状态发生变化时才会通知应用程序**。
    - 当一个文件描述符从无事件状态变为有事件状态时，`epoll_wait`会立即返回，并将该事件通知给应用程序。
    - 如果应用程序没有立即处理该事件，下次调用`epoll_wait`时将不会再通知该事件，直到文件描述符的事件状态再次发生变化。

[对比select poll epoll](language/py/key/2019-03-05-IO.md#对比select poll epoll)

[惊群](anguage/py/key/2019-03-05-IO.md#惊群)

这种情况下，所有被唤醒的线程（或进程）都会竞争获取该资源，导致额外的上下文切换、锁竞争和资源竞争。这会浪费系统资源，并且可能造成性能下降，因为只有一个线程（或进程）能够有效地使用该资源，其他线程（或进程）则需要重新排队等待。

为了避免惊群现象，可以采用以下策略：

- 使用互斥锁或信号量等同步机制，确保只有一个线程（或进程）能够获得资源。
- 使用条件变量或事件通知机制，只唤醒一个线程（或进程），而不是唤醒所有等待的线程（或进程）。
- 使用边缘触发（ET）而不是水平触发（LT）的事件通知机制，避免不必要的多次触发。
- 使用优雅的重试机制，可以通过一定的延迟后再进行重试
- 优化资源分配策略，使用更精细的资源分片、资源池等方式，将资源均匀分配给不同的线程


# 网络协议

## 网络

[计算机网络](network/2018-06-02-computer network.md)

[Ip  子网](network/2019-05-19-ip.md)

## TCP UDP

[TCP 和 UDP 的区别](linux/key/2021-08-11-tcp.md#TCP 和 UDP 的区别)

TCP 是面向连接的协议，可靠有状态的协议。UDP 适用于对实时性要求较高的应用

[三次握手](linux/key/2021-08-11-tcp.md#三次握手)

**为啥三次握手，而不是更少次数**:防止旧的重复连接(网络差延时)请求报文段突然又传送到了服务端，从而产生服务端以为有新的请求过来浪费了文件句柄

**序列号**:用来解决乱序问题等。

**窗口大小**:用来做流量控制,严格来说是确定双方的窗口放大因子(Window size scaling factor)，因为窗口大小在后续的交互中还 会变。



[握手优化](linux/key/2021-08-11-tcp.md#握手优化)

服务端发送完SYN+ACK包后，此时服务器进入SYN_RECV状态。

SYN攻击(半链接攻击)，通过发送大量的半连接请求，耗费CPU和内存资源。正常的客户发送SYN数据包请求连接就会被服务器丢弃。

- 缩短SYN Timeout时间
- 设置SYN Cookie，就是给每一个请求连接的IP地址分配一个Cookie，如果短时间内连续受到某个IP的重复SYN 报文，就认定是受到了攻击，以后从这个IP地址来的包会被一概丢弃。

[四次挥手](linux/key/2021-08-11-tcp.md#四次挥手)

**why 2MSL  TIME_WAIT作用**

- 确保最后一个确认报文能够到达。如果没能到达，服务端就会重发FIN请求释放连接。等待一段时间没有收到重发就说明服务的已经CLOSE了。如果有重发，则客户端再发送一次LAST ack信号
- 确保当前连接所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文

**因为每个TCP报文最大存活时间为MSL，一个往返最大是2*MSL，所以TIME_WAIT需要等待2MSL。**



**为什么是四次挥手而不是三次**

客户端要关闭链接的时候，服务端可能还有数据要发送，等服务端发送完数据后再主动关闭。

**如果是三次挥手会有什么问题？**

等于说服务端将`ACK`和`FIN`的发送合并为一次挥手，这个时候长时间的延迟可能会导致客户端误以为`FIN`没有到达客户端，从而让客户端不断的重发`FIN`。

[优化time_wait](linux/key/2021-08-11-tcp.md#优化time_wait)

[time_wait过多危害](linux/key/2021-08-11-tcp.md#过多危害)

- 占用过多端口，系统几乎停转，任何链接都不能建立。

[why CLOSE_WAIT很多](linux/key/2021-08-11-tcp.md#why CLOSE_WAIT很多)

**TCP为啥可靠**: 发送ACK，重传机制、滑动窗口协议，流量控制、拥塞控制

**TCP校验和** :是用于保护TCP报文完整性的机制。它通过对TCP报文头部和数据计算得出校验值，用于检测传输过程中的错误或数据损坏。



## HTTP



1. 起始行（start line）：描述请求或响应的基本信息；
2. 头部字段集合（header）：使用 key-value 形式更详细地说明报文；
3. 空行
4. 消息正文（entity）：实际传输的数据，它不一定是纯文本，可以是图片、视频等二进制数据。



[HTTPS](linux/key/2021-08-14-http.md#HTTPS)

[Hello 阶段](hack/security/2019-03-30-crypto.md#Hello 阶段)

- Client端发送https请求

> 1. 支持的协议版本
> 2. 随机数 **random1**，稍后用于生成"对话密钥"。
> 3. 支持的加密方法等信息

- Server端

> 1. 确认使用的加密通信协议版本
> 2. 发送随机数 **random2**，稍后用于生成"对话密钥"。
> 3. 确认加密方法等信息
> 4. 发送数字证书

验证数字证书

- **CA身份验证/过期 CA根证书验证**: 浏览器内置一个受信任的**CA机构列表**，并保存了这些CA机构的证书。

- **Server端的数字证书信息与当前正在访问的网站（域名等）一致**: Server端是可信的 -> **获得Server公钥**

> Client端是否能够信任这个站点的证书，首先取决于Client端程序是否导入了证书颁发者的根证书。**抓包工具要抓https也要导入工具的证书**

[HTTP2.0](linux/key/2021-08-14-http.md#HTTP/2.0)

1. 采用二进制格式而非文本格式；
2. 完全多路复用，而非有序并阻塞的、只需一个连接即可实现并行；
3. 使用报头压缩，降低开销
4. 服务器推送

[grpc 过程](linux/key/2021-08-14-http.md#grpc)

[websocket](linux/key/2021-08-14-http.md#websocket)

[数字签名](hack/security/2019-03-30-crypto.md#数字签名)

[数字证书](hack/security/2019-03-30-crypto.md#数字证书)

# 微服务

## [cache](db/cache/2018-08-19-cache 术语.md)

**缓存穿透** 

如果key对应的value是一定不存在的，并且对该key并发请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。

高级用法**布隆过滤器（Bloom Filter）**这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return

**缓存击穿**

缓存突然消失 全打到数据库

**缓存雪崩**

当缓存服务器重启或者大量缓存集中在某一个时间段失效

## 微服务架构

[一些方法](系统架构/微服务/2021-05-09-micro-serice.md)

服务雪崩: 超时机制，防上游服务长时间不响应导致请求积压下游也没有响应从而 整个链路像滚雪球一样雪崩

重试机制:防止网络抖动时(请求或返回)误判服务超时，要重试请求打到网络好的服务去请求成功，grpc_middleware中间件可 做

幂等:返回响应时网络抖动(数据提交是成功的)导致的重试，但数据是真正更新成功了，重试时接收到同样的数据，提交两次、 要去重、幂等

所以保证系统幂等性需要满足3个条件:   [幂等性方案](https://cloud.tencent.com/developer/article/1839609#%E5%B9%82%E7%AD%89%E6%80%A7%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88)

1. 请求唯一标识：每一个请求必须有一个唯一标识。
2. 处理唯一标识：每次处理完请求之后，必须有一个记录标识这个请求处理过了。
3. 逻辑判断处理：每次接收请求需要进行判断之前是否处理过的逻辑处理。根据请求唯一标识查询是否存在处理唯一标识。

链路追踪: 限流: 熔断:

## 分布式

### [CAP](系统架构/key/2021-06-14-分布式算法.md#CAP)

- **一致性（Consistence）**

  所有节点访问同一份最新的数据副本

  - 强一致性

    **任何一次读都能读到某个数据的最近一次写的数据**。系统中的所有进程，看到的操作顺序，都和全局时钟下的顺序一致。简言之，在任意时刻，所有节点中的数据是一样的。

  - 弱一致性

    数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性。

  - 最终一致性

    不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。简单说，就是在一段时间后，节点间的数据会最终达到一致状态。

- **可用性（Availability）**

  每一个操作总是能够在**一定的时间**内**返回结果**

- **分区容错性（Partition tolerance）**

  分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。

ap : 放弃强一致，追求分区容错性和可用性，mysql redis kafka 主从同步，异步同步 最终一致 。
cp : 在网络分区的情况下强调强一致性读。所有设计是为了一致性，当发生网络分区时，为了保证一致性，是不可用的。如:etcd ,zk
ca :无多机器网络隔离 单机

![image-20240212131240204](https://cdn.jsdelivr.net/gh/631068264/img/202402121312332.png)

### [Paxos](系统架构/key/2021-06-14-分布式算法.md#Paxos)

- **Proposer**（提案人）只有一个
- **Acceptor**（接收者）多个
- **Learners**（学习者）多个

- Paxos算法由Leslie Lamport在1990年提出，是一种经典的分布式一致性算法。
- 算法涉及三个角色：提议者、接受者和学习者。
- 算法分为三个主要阶段：提议阶段（Prepare Phase）、接受阶段（Accept Phase）和决策阶段（Decision Phase）。
- 提议者向接受者发送提议编号，并根据接受者的回复选择值。
- 接受者根据自己已接受的提议编号，接受或拒绝提案，并回复提议编号和值。
- 提议者在多数派接受者的回复中选择值，并向多数派发送接受请求。
- 接受者根据提议编号接受或忽略请求。
- 一旦提议者收到多数派接受者对接受请求的回复，可以确定一个值已经被多数派接受，并广播决策消息。
- 学习者接收决策消息并将其应用于自己的状态。

过半以上的Acceptor，接受Proposer的提议

### [Raft](系统架构/key/2021-06-14-分布式算法.md#Raft)

- **Leader**：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。
- **Follower**：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。
- **Candidate**：Leader选举过程中的临时角色。

Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。

- Raft算法将节点划分为领导者、跟随者和候选者三个角色。
- 领导者选举是Raft算法的关键过程，候选者通过选举请求获取其他节点的选票，获得多数派选票的候选者成为新的领导者。
- 日志复制是Raft算法实现一致性的核心，领导者将客户端请求转化为日志项并复制到其他节点的日志中。
- 安全性由递增的任期号和投票机制保证，候选者的任期号必须大于当前节点的任期号才能获得选票。
- Raft算法提供了更清晰的模块化结构，使得开发人员能够更好地理解和调试分布式系统的行为。

### [etcd](系统架构/2021-07-10-service_discovery.md)

### [分布式事务](系统架构/key/2021-07-25-分布式锁.md#分布式事务)

### [**分布式锁**](系统架构/key/2021-07-25-分布式锁.md#分布式锁)

[redis](系统架构/key/2021-07-25-分布式锁.md#redis)

- `set key value nx ex sec`  原子性加锁

- 通过value，防止释放别人的锁

- 防止锁过期自动释放，

  - 将过期时间设置足够长
  - 增加守护线程，为将要过期但未释放的锁续期。

- 防止可重入，重入计数

- client 等待锁释放

  - 客户端轮询
  - 使用 Redis 的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。
  
- 确保主备切换的数据一致性（**当客户端 A 成功加锁，指令还未同步，此时主节点挂掉，从节点提升为主节点，新的主节点没有锁的数据，当客户端 B 加锁时就会成功。**）
  
  - 使用递增token
    - 使用Redis的自增命令（如INCR）来生成递增的token。这个命令会将指定的键的值递增，并返回递增后的值。
    - 在Redis主节点上执行自增命令生成递增token，并将其记录到持久化存储（如数据库）中。这样可以确保即使主节点发生故障，递增token的值不会丢失。
    - 在Redis备份节点上配置为只读，并实时复制主节点的数据。这样备份节点将保持与主节点的数据一致性。
    - 当主节点发生故障或需要切换时，将备份节点升级为主节点。
    - 在切换完成后，新的主节点将继续使用之前记录的递增token值进行自增操作。
- [Redlock](系统架构/key/2021-07-25-分布式锁.md#Redlock)至少要部署 5 个 Redis 实例，而且都是主库，它们之间没有任何关系，都是一个个孤立的实例 **大多数加锁成功，才算成功**   ，解决**主备切换和集群脑裂**

[zk](系统架构/key/2021-07-25-分布式锁.md#zk)

专注于提供强一致性和可靠性，如果业务对于强一致性要求较高，而不太关注性能方面的考虑，推荐使用 ZooKeeper。

- 创建**临时的且有序的子节点**
- 通过检查自己创建的节点是否是当前最小的节点来判断是否获取到了锁。如果是则认为获得锁。 否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁。 执行业务代码，完成后，删除对应的子节点。

临时有序节点的特性和顺序访问的保证。每个客户端都会创建一个唯一的节点，节点的顺序由 ZooKeeper 保证。通过比较节点的顺序，可以确定哪个客户端获得了锁。


# 操作系统

**mmap** 是一项有趣且强大的技术，它在文件 I/O 和内存映射之间建立了桥梁。让我们深入了解一下它的原理和优缺点。

- **mmap** 可以将用户空间的虚拟内存地址与文件进行映射，连续内存
- 映射的是文件的 **页缓存**，而非磁盘中的文件本身。
- 当发生数据修改时，内存出现脏页，与磁盘文件出现不一致。mmap 机制下由操作系统自动完成内存数据落盘（脏页回刷），用户进程通常并不需要手动管理数据落盘。

优点

1. **避免内核空间到用户空间的数据拷贝**，提高了大文件读写效率。
2. **操作文件像操作内存**：适合对较大文件的读写。节约内存

缺点

1. **小文件浪费**：如果文件很小（比如小于 4KB），按页组织的内存会导致部分内存空间浪费。
2. 由于 mmap 使用时必须实现指定好内存映射的大小，因此 mmap 并不适合变长文件



# 排错

redis

[redis  AOF fsync 时间太长](db/redis/2021-03-09-aof_rdb.md)



mysql

[mysql kill 死锁](db/mysql/error/2020-08-08-mysql 排错.md)

[mysql  sqlalchemy  超时   结果集超大](db/mysql/error/2019-08-29-mysql gone away.md)

[mysql关于auto increment的重启坑](db/mysql/error/2019-08-12-auto increment.md)

[mysql 查看慢查询 死锁](db/2021-06-27-db排错.md#mysql)

es

[es 查看慢查询 死锁](db/2021-06-27-db排错.md#es)

[es 坑](db/es/2020-11-03-es_坑.md)

ck

[记一次kafka clickhouse 排错](db/clickhouse/2020-04-23-clickhouse bug.md)

[docker](docker/2020-07-05-docker network 本地ip冲突.md)

k8s

[rke创建集群Failed to set up SSH tunneling for host](k8s/err/rancher rke创建集群Failed to set up SSH tunneling for host.md)

[k8s issue](k8s/err/issue整理.md)

[k3s-坑](k8s/k3s/2022-03-26-k3s-坑.md)

[k8s dns 排错 内核参数被改   resolv.conf 有古怪](_posts/k8s/排错/2022-01-08-k8s-dns排错.md)

[下游集群连不上Rancher排查](k8s/排错/2023-02-13-集群排错.md#下游集群连不上Rancher排查)

[apiserver kubelet CPU占用居高不下](k8s/排错/2023-02-13-集群排错.md#apiserver kubelet CPU占用居高不下)
