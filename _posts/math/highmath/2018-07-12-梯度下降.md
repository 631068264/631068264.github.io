---
layout:     post
rewards: false
title:    梯度下降
categories:
    - 数学
tags:
    - 高数
---

[梯度下降](https://ctmakro.github.io/site/on_learning/gd.html)

![](https://cdn.jsdelivr.net/gh/631068264/img/006tNbRwgy1fudlsx49zlj30jo0eqdfz.jpg)
error函数的图像，看上去像个碗一样，中间是凹的，两边翘起。这个碗的最低点，也就是 error(x) 的最小值，就是我们要寻找的点。

我们发现:

当x在最小值左边的时候，error函数的导数（斜率）是负的；
当x在最小值右边的时候，导数是正的；
当x在最小值附近的时候，导数接近0.
因此，如果我们在：

导数为负的时候增加x；
导数为正的时候减小x；

x = x - derivative * alpha

解释：
derivative 是 error 在 x 处的导数，这里是用导数的定义求的。
x = x - derivative 这就是“导数下降”名称的由来。通过不断地减去导数，x最终会到达函数的最低点。
alpha 参数控制的是点 x 逆着导数方向前进的距离，alpha 越大，x 就会前进得越多，误差下降得越快。alpha 太小会导致下降缓慢，alpha 太大会导致 x 冲得太远，令函数无法收敛。


