---
layout: post
rewards: false
title:  nginx
categories:
    - Linux

---



# 概念

## 进程模型

unix系统中会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程。

nginx**默认**是以多进程的方式来工作的

> 独立的进程，不需要加锁，所以省掉了锁带来的开销。采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master进程则很快启动新的worker进程。

- master进程  

  > 接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态

- worker进程

  > 处理基本的网络事件 

多个worker进程之间是对等的，互相之间是独立。一个请求，只可能在一个worker进程中处理。**为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个进程注册listenfd读事件，在读事件里调用accept接受该连接。**

锁的竞争，**worker_connections 每个worker进程所能建立连接的最大值**可用的连接变少，让出**accept_mutex**的机会变大。

worker进程个数通常等于机器cpu核数，**更多的worker数，只会导致进程来竞争cpu资源了，从而带来不必要的上下文切换。**

## 工作方式

异步非阻塞

同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。

只要有事件准备好了，我们就去处理它，只有当所有事件都没准备好时，才会等待。

这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的事件，事实上就是这样的。与多线程相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。并发数再多也不会导致无谓的资源浪费（上下文切换）。更多的并发数，只是会占用更多的内存而已。 

```
while (true) {
    for t in run_tasks:
        t.handler();
    update_time(&now);
    timeout = ETERNITY;
    for t in wait_tasks: /* sorted already */
        if (t.time <= now) {
            t.timeout_handler();
        } else {
            timeout = t.time - now;
            break;
        }
    nevents = poll_function(events, timeout);
    for i in nevents:
        task t;
        if (events[i].type == READ) {
            t.handler = read_handler;
        } else { /* events[i].type == WRITE */
            t.handler = write_handler;
        }
        run_tasks_add(t);
}
```

### 请求处理

![请求处理流程](https://tva1.sinaimg.cn/large/007S8ZIlgy1ggfv8wjsvdj30c60thwfm.jpg)



# 常用配置

[nginx 变量 index](http://nginx.org/en/docs/varindex.html)

```nginx
server {
	listen 80;
	# http https 重定向
	return 301 https://$host$request_uri;
}

server {
    listen       443 ssl;
    server_name  localhost;
    # 上传大小
    client_max_body_size 50M;
    # ssl
    ssl_certificate      /path/master_server.crt;
    ssl_certificate_key  /path/master_server.key;

    ssl_session_cache    shared:SSL:1m;
    # 客户端连接可以复用sslsession cache中缓存的ssl参数的有效时长
    ssl_session_timeout  5m;

    ssl_ciphers  HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;


	# 实际访问 本地 /xx/dd/update/ 目录下的文件
    location /update/ {
        root /xx/dd/;
    }
    # 实际访问 本地 /xx/dd/ 目录下的文件
  	location /analyses/ {
      alias /xx/dd/;
      autoindex on;
      autoindex_exact_size off;
      autoindex_localtime on;
	}

    location /api {
        proxy_pass http://127.0.0.1:9002;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        # 连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）
        proxy_read_timeout 300s;
    }
	# wss 设置 Upgrade Connection  http://nginx.org/en/docs/http/websocket.html
    location /ws {
        proxy_pass http://127.0.0.1:9002/ws;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_read_timeout 300s;
    }

    error_page 502 /502.json;
    location /502.json {
        return 502 '{"code": -1, "msg": "服务器未响应"}';
    }
    
    # 限制某接口可上传大小
  	location = /api/2/xxx {
        proxy_pass http://127.0.0.1:9002/api/2/xxx;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_read_timeout 300s;
        client_max_body_size 201k;
    }

  
  
}

```



端口转发

```nginx
 #  对domain:dddd的请求转发到本地xxxx端口

upstream redis {
    server 127.0.0.1:xxxx max_fails=3 fail_timeout=60s;
}

server {
    listen domain:dddd;

    proxy_connect_timeout 60s;
    proxy_timeout 300s;
    proxy_pass redis;
}
```



```nginx
#user  nobody;
worker_processes  1;

#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

#pid        logs/nginx.pid;

load_module /usr/lib/nginx/modules/ngx_stream_module.so;

events {
    worker_connections  1024;
}


http {
    include     /etc/nginx/sites-enabled/*;
    include       mime.types;
    default_type  application/octet-stream;

    #access_log  logs/access.log  main;
    sendfile        on;
    keepalive_timeout  65;


}

stream {
    include /etc/nginx/stream-enabled/*;
}

```



[grpc ssl 转发](https://www.nginx.com/blog/nginx-1-13-10-grpc/)

```nginx
server {
                listen 9100 ssl http2;

                ssl_certificate     /path/rpc_server.crt;
                ssl_certificate_key /path/rpc_server.key;

                location / {
                        grpc_pass grpcs://domain:9100;
                }
        }

```







# 负载均衡

- 轮询  每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。

  ```nginx
  upstream api {
      server 127.0.0.1:9002 ;
      server 127.0.0.1:19002 ;
  }
  
  location /api/2/ {
    proxy_pass http://api;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_read_timeout 300s;
  }
  
  
  ```

- weight 

  权重越高，在被访问的概率越大

  ```nginx
  upstream api {
      server 127.0.0.1:9002 backup; # 其它所有的非backup机器down或者忙的时候，请求backup机器)
      server 127.0.0.1:19002 weight=10 max_fails=3 fail_timeout=30s max_conns=1;
      server 127.0.0.1:19003 weight=10 max_fails=3 fail_timeout=30s max_conns=1;
      server 127.0.0.1:19004 weight=10 max_fails=3 fail_timeout=30s max_conns=1;
  }
  ```

  - max_fails 

    默认为1，允许请求失败的次数。当超过最大次数时，返回proxy_next_upstream 模块定义的错误

  - fail_timeout

    默认10秒，max_fails次失败后，在fail_timeout期间内，nginx会认为这台Server暂时不可用，不会将请求分配给它

  - max_conns

  	默认0不限制，限制分配给某台Server处理的最大连接数量，超过这个数量，将不会分配新的连接给它



- ip_hash

  ```nginx
  upstream item { # item名字可以自定义
    ip_hash;
    server 192.168.101.60:81;
    server 192.168.101.77:80;
  }
  ```

  根据客户端IP来分配服务器，解决session共享问题

  

# 缓存

```nginx
location ~* \.(css|js|png|jpg|jpeg|gif|gz|svg|mp4|mp3|ogg|ogv|webm|htc|xml|woff|ttf)$ {
        root /data/;
        access_log off;
        add_header Cache-Control "public,max-age=7*24*3600";
    }

```



# access log fmt

log 打印响应时间，还有upstream addr

**nginx: [emerg] “log_format” directive is not allowed here**  log_format 要放在server外面

```nginx
upstream api {
    server 127.0.0.1:9002 backup;
    server 127.0.0.1:19002 weight=10 max_fails=3 fail_timeout=30s max_conns=10;
    server 127.0.0.1:19003 weight=10 max_fails=3 fail_timeout=30s max_conns=10;
    server 127.0.0.1:19004 weight=10 max_fails=3 fail_timeout=30s max_conns=10;
}

log_format custom_log_fmt '$remote_addr - $remote_user [$time_local]'
                ' ups_resp_time: $upstream_response_time '
                ' req_time: $request_time '
                ' "$request" $status $body_bytes_sent "$http_referer" "$http_user_agent" "$upstream_addr"';

server {
    listen       443 ssl;
    。。。。
    access_log /dev/stdout custom_log_fmt;
}

```

- request_time

  request processing time in seconds with a milliseconds resolution; time elapsed between the first bytes were read from the client and the log write after the last bytes were sent to the client

  请求处理时长，单位为秒，精度为毫秒，从读入客户端的第一个字节开始，直到把最后一个字符发送张客户端进行日志写入为止

  即$request_time包括接收客户端请求数据的时间、后端程序响应的时间、发送响应数据给客户端的时间(不包含写日志的时间)

- upstream_response_time

  keeps time spent on receiving the response from the upstream server; the time is kept in seconds with millisecond resolution. Times of several responses are separated by commas and colons like addresses in the [$upstream_addr](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#var_upstream_addr) variable.

  从Nginx向后端建立连接开始到接受完数据然后关闭连接为止的时间

- upstream_addr

  记录负载均衡分发到那个addr

- /dev/stdout

  docker 容器标准输出
