---
layout:     post
rewards: false
title:   GPU节点 docker k8s 适配
categories:
    - k8s

---

# 准备

在每个工作节点上都安装 NVIDIA GPU 或 AMDGPU 驱动程序，如下所述 。 使用 NVIDIA GPU 的系统要求包括:

- NVIDIA 驱动程序的版本为 384.81 及以上;
- nvidia-docker 的版本为 2.0 及以上;
- kubelet 配置的容器运行时 (Container Runtime) 必须为 Docker;
- Docker 配置的默认运行时 (Default Runtime) 必须为 nvidia-container-runtime, 而不能用runc;
- Kubernetes 版本为 1.11 及以上 。

- [检查系统要求](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#system-requirements)

[参考预安装操作](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions)

```sh
# Verify You Have a CUDA-Capable GPU
lspci | grep -i nvidia

# Verify You Have a Supported Version of Linux
uname -m && cat /etc/*release

# Verify the System Has gcc Installed
gcc --version

# Verify the System has the Correct Kernel Headers and Development Packages Installed
uname -r
```





# NVIDIA Drivers

[docker环境部署参考](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker)

## 查看型号

```
lspci | grep -i nvidia


root@d-ecs-38357230:~# lspci | grep -i nvidia
00:08.0 3D controller: NVIDIA Corporation Device 1eb8 (rev a1)
```

返回一个**1eb8**，可以通过[PCI devices查询](http://pci-ids.ucw.cz/mods/PC/10de?action=help?help=pci)

![image-20220412105920629](https://tva1.sinaimg.cn/large/e6c9d24egy1h1atm5dr4wj21bu0u0wk8.jpg)

![image-20220412105957003](https://tva1.sinaimg.cn/large/e6c9d24egy1h1atm5si9tj21be0l40un.jpg)

## 安装驱动



也可以直接安装[NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-downloads)

> The CUDA Toolkit contains the CUDA driver and tools needed to create, build and run a CUDA application as well as libraries, header files, and other resources.

根据 https://github.com/NVIDIA/nvidia-docker **CUDA Toolkit**不是必须的，驱动是必须的



[查看支持显卡的驱动最新版本及下载，下载之后是.run后缀](https://www.nvidia.com/Download/index.aspx?lang=en-us) （可以直接下载驱动）

![image-20220413095333085](https://tva1.sinaimg.cn/large/e6c9d24egy1h1atm4et97j20yy0fwdhm.jpg)



```sh
sudo sh NVIDIA-Linux-x86_64-384.90.run -no-x-check -no-nouveau-check -no-opengl-files
```

代码注释：

​    -no-x-check  #安装驱动时关闭X服务

​    -no-nouveau-check  #安装驱动时禁用nouveau

​    -no-opengl-files  #只安装驱动文件，不安装OpenGL文件

或者

```
更新软件源，运行
apt-get upgrade
apt-cache search nvidia-* |grep 455 查询455版本的驱动是否存在
nvidia-driver-418-server - NVIDIA Server Driver metapackage
nvidia-driver-440-server - NVIDIA Server Driver metapackage
nvidia-driver-450-server - NVIDIA Server Driver metapackage
nvidia-driver-455 - NVIDIA driver metapackage
安装 apt-get install nvidia-driver-455 -y
安装完reboot系统
```



查看cuda版本

```sh
root@d-ecs-38357230:~# cat /usr/local/cuda/version.txt
CUDA Version 11.0.228
```

查看显卡驱动版本

```bash
root@d-ecs-38357230:~# cat /proc/driver/nvidia/version
NVRM version: NVIDIA UNIX x86_64 Kernel Module  450.89  Thu Oct 22 20:49:26 UTC 2020
GCC version:  gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)
```


验证驱动

```bash
nvidia-smi -L （必须安装好nvidia驱动）

root@d-ecs-38357230:~# nvidia-smi -L
GPU 0: Tesla T4 (UUID: GPU-6b1d3e62-f94c-9236-1398-813bb48aab5a)
```



# docker

`/etc/docker/daemon.json`，修改docker Runtime

```yaml
{
    "default-runtime": "nvidia",
    "runtimes": {
        "nvidia": {
            "path": "/usr/bin/nvidia-container-runtime",
            "runtimeArgs": []
        }
    }
}
```

根据[Setting up Docker 安装nvidia-docker2](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#setting-up-docker)

Setup the package repository and the GPG key:

```sh
$ distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
      && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
      && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
            sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
            sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
```

Install the `nvidia-docker2` package (and dependencies) after updating the package listing:

```sh
$ sudo apt-get update
```



```sh
$ sudo apt-get install -y nvidia-docker2
```



Restart the Docker daemon to complete the installation after setting the default runtime:

```sh
systemctl daemon-reload && systemctl restart docker
```



At this point, a working setup can be tested by running a base CUDA container:

```sh
$ sudo docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
```



This should result in a console output shown below:

```sh
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |
| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```

## 注意事项

如果存在这种现象：
"没有运行程序，nvidia-smi查看GPU-Util 达到100% GPU利用率很高"
需要把驱动模式设置为常驻内存才可以，设置命令：

>  nvidia-smi -pm 1

# k8s

[K8s](https://kubernetes.io/zh/docs/tasks/manage-gpus/scheduling-gpus/) + [Nvidia-Device-Plugin](https://github.com/NVIDIA/k8s-device-plugin)的方式两个限制

- 每一块GPU同时最多只能被一个容器使用(会造成巨大的资源浪费)
- 没有考虑GPU卡之间的通道亲和性(因为不同的连接介质对卡与卡之间的数据传输速度影响非常大)

所以使用[AliyunContainerService 提供Pod 之间共享 GPU解决方案](https://github.com/AliyunContainerService/gpushare-scheduler-extender)

- https://blog.csdn.net/u012751272/article/details/120566202?spm=1001.2014.3001.5502
- https://github.com/AliyunContainerService/gpushare-scheduler-extender/blob/master/docs/install.md



下载

```
curl -O https://raw.githubusercontent.com/AliyunContainerService/gpushare-scheduler-extender/master/config/gpushare-schd-extender.yaml

```

放到 /etc/kubernetes/scheduler-policy-config.json





使用rke安装cluster.yml  [scheduler config](https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-scheduler/)

```
nodes:
  - address: xxxx
    user: root
    role: ["controlplane", "etcd", "worker"]
    ssh_key_path: ~/.ssh/id_rsa
    port: 22
services:
  scheduler:
      extra_args:
        policy-config-file: /etc/kubernetes/scheduler-policy-config.json

cluster_name: cluster01
```



```sh
/rke up -config cluster.yml --ignore-docker-version
```

下载

```
https://raw.githubusercontent.com/AliyunContainerService/gpushare-scheduler-extender/master/config/gpushare-schd-extender.yaml

https://raw.githubusercontent.com/AliyunContainerService/gpushare-device-plugin/master/device-plugin-rbac.yaml

https://raw.githubusercontent.com/AliyunContainerService/gpushare-device-plugin/master/device-plugin-ds.yaml

```

**注意事项**

- 单节点需要修改gpushare-schd-extender.yaml，不然会**0/1 nodes are available: 1 node(s) didn't match Pod's node affinity/selector.**  [参考](https://github.com/AliyunContainerService/gpushare-scheduler-extender/issues/170)

  ```yaml
  #      nodeSelector:
  #         node-role.kubernetes.io/master: ""
  ```

- 默认情况下，GPU显存以GiB为单位，若需要使用MiB为单位，修改**device-plugin-ds.yaml**，将--memory-unit=GiB修改为--memory-unit=MiB

安装

```sh
# Deploy GPU share scheduler extender in control plane
kubectl create -f gpushare-schd-extender.yaml

# Deploy Device Plugin
kubectl create -f device-plugin-rbac.yaml
kubectl create -f device-plugin-ds.yaml
```

加标签

```sh
root@d-ecs-38357230:~# kubectl get nodes
NAME           STATUS   ROLES                      AGE   VERSION
10.81.17.131   Ready    controlplane,etcd,worker   47m   v1.18.6
root@d-ecs-38357230:~# kubectl label node 10.81.17.131 gpushare=true
node/10.81.17.131 labeled
root@d-ecs-38357230:~#
```



测试

```sh
root@d-ecs-38357230:~# kubectl get pods -n kube-system |grep gpushare
gpushare-device-plugin-ds-z27jc           1/1     Running     0          23m
gpushare-schd-extender-56799db8c7-8gshd   1/1     Running     0          25m
```



部署官方测试demo

注意事项：[创建pod报错nvidia-container-cli: device error: unknown device id: no-gpu-has-10MiB-to-run](https://github.com/AliyunContainerService/gpushare-scheduler-extender/issues/80)

```yaml
在container中添加env，如下：

containers:
    - name: cuda
      image: nvidia/cuda:latest
      env:
        - name: NVIDIA_VISIBLE_DEVICES
          value: "all"
      resources:
        limits:
          # GiB
          aliyun.com/gpu-mem: 1
```



```shell
root@d-ecs-38357230:~# kubectl-inspect-gpushare
NAME          IPADDRESS     GPU0(Allocated/Total)  GPU Memory(GiB)
10.81.17.131  10.81.17.131  6/14                   6/14
--------------------------------------------------------
Allocated/Total GPU Memory In Cluster:
6/14 (42%)
```



