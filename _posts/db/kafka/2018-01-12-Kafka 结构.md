---
layout:     post
rewards: false
title:      Kafka 结构
categories:
    - kafka
---

Kafka 是一个高吞吐量、分布式的发布一订阅消息系统。当前的 Kafka己经定位为一个分布式流式处理平台。

Kafka 是一款开源的、轻量级的 、分布式、可分区和具有复制备份的 (Replicated)、基于 ZooKeeper 协调 管理的分布式流平台的功能 强大的消息系统 。与传统 的消息系统相比， Kafka 能够很好地处理活跃的流数据，使得数据在各个子系统中高性能、低延迟地不停流转。

- 能够允许发布和订阅流数据
- 存储流数据时提供相应的容错机制
- 当流数据到达时能够被及时处理

**生产者负责生产消息，将消息写入 Kafka 集群:消费者从 Kafka 集群中拉取消息**

# message
消息是 Kafka通信的基本单位
# topic
topic 对 Message 的一个分类。生产者将消息发送到特定主题，消费者订阅主题或主题的某些分区进行消费。
# partition and duplicate
一组消息归纳为一个主题
每个主题又被分成一个或多个分区
每个分区由一系列有序、不可变的消息组成，一个有序队列。
每个分区又有一至多个 副本( Replica)，分区的副本分布在集群的不同代理上，以提高可用性

物理上：
每个分区在物理上对应为一个文件夹
分区的命名规则为主题名称后接“一”连接符，之 后再接分区编号，分区编号从 0 开始

# 分区
分区有点：
分区使得 Kafka在井发处理上变得更加容易，理论上来说，分区数越多吞吐量越高，但这 要根据集群实际环境及业务场景而定。同时，分区也是 Kafka保证消息被顺序消费以及对消息 进行负载均衡的基础。

Kafka 只能保证一个分区之内消息的有序性，并不能保证跨分区消息的有序性 。 每条消息 被追加到相应的分区中，是顺序写磁盘，因此效率非常高，这是 Kafka 高吞吐率的 一个重要保证。

Kafka 并不会立即删除已被消费的消息，由于磁盘的限制 消息也不会一直被存储(事实上这也是没有必要的)，因此 Kafka提供两种删除老数据的策略， 一是基于消息己存储的时间长度， 二是基于分区的大小

一个分区的多个副本之间数据的一致性， Kafka会选 择该分区的 一个副本作为 Leader 副本，而该分区其他副本即为 Follower 副本，只有 Leader 副 本才负责处理客户端读/写请求， Follower 副本从 Leader 副本同步数据。

# log
分区的副本与日志对象是一一对应的。任何发布到分区的消息会被直接追加到日志文件的尾部

# 代理 Broker

生产环境中 Kafka集群一般包括一台或多台服务器 ，我们可以在一台服务器 上配置一个或多个代理。
每一个代理都有唯一的标识 id，这个 id是一个非负整数。在一个 Kafka 集群中，
每增加一个代理就需要为这个代理配置一个与该集群中其他代理不同的 id, id值可以 选择任意非负整数 即可，只 要保证它在整个 Kafka 集群中唯 一 ，
这个 id 就是代理的名字，也就 是在启动 代理时配置的 broker.id 对应的值，因此在本书中有时我们也称为 brokerId。

每个代理可能每个主题有零个或多个分区。
- 某主题分区数 = Broker数 每个代理将有一个分区
- 某主题分区数 < Broker数 每个代理将有一个分区, 剩余broker没有该主题分区
- 某主题分区数 > Broker数 每个代理将有一个分区或多个分区, Broker之间的负载分配不均衡，不推荐这种情况

# 生产者 Producers

生产者(Producer)负责将消息发送给代理，也就是向 Kafka代理发送消息的客户端。

# 消费者 Consumers

我们可以为每个消费者指定一个消费组，以 groupId代表消费组名称
如果不指定消费组，则该消费者属于默认消费组 test-consumer-group Kafka
会自动为该消费者生成一个全局唯一的
id，格式为`${groupld}-${hostName}-${timestamp}-${UUID 前 8位字符}`

# 基本概念
- 多个消费者分配到同一个消费者
- 多个消费组订阅同一个主题
- 同一主题的一条消息只能被同一个消费组里某一个消费者消费 (**同组里消费者消息共享**)
- 不同消费组的消费者可同时消费该消息
- 一旦新消费者到达，Kafka将其操作切换到共享模式并在**两个消费者之间共享数据**。 util
  Consumers数量 == 该特定主题配置的**分区数量**
  (Kafka的每个消费者都将被分配至少一个分区)
  没有空闲分区，新消费者将不会收到任何进一步的消息，直到现有的任何消费者退订。


# ISR 
在 ZooKeeper 中动态维护了一个ISR,保存同步的副本列表，该列表中保存的是与
Leader 副本保持消息同步的所有副本对应的代理节点 id

# ZooKeeper
Kafka 在启动或运行过程当中会在 ZooKeeper 上创建相应节点来保 存元数据信息， Kafka 通过监昕机制在这些节点注册相应监听器来监昕节点元数据的变化，从 而由 ZooKeeper 负责管理维护 Kafka集群，同时通过 ZooKeeper 我们能够很方便地对 Kafka 集 群进行水平扩展及数据迁移

Kafka 基本结构
![](https://ws3.sinaimg.cn/large/006tNbRwgy1fv95als00rj31kw12zjvh.jpg)


# Why 文件系统来存储数据
- 文件系统存储速度快慢一定程度上也取决于我们对磁盘的用法。线性写的速度约是随机写 的 6000 多倍
- Java 对 象内存消耗非常高， 且随着 Java 对象的增加JVM垃圾回收也越来越频繁和繁琐，这些都加大了内存的消耗 。

数据的持久化队列可以建立在简单地对文件进行追加的实现方案上，因为是顺序追加， 所以
Kafka在设计上是采用时间复杂度O(1)的磁盘结构，它提供了常量时间的性能，即使是存
储海量的信息( TB 级)也如此，性能和数据的大小关系也不大，同时 Kafka将数据持久化到磁
盘上，这样只要磁盘空间足够大数据就可以一直追加，而不会像一般的消息系统在消息被消费
后就删除掉， Kafka 提供了相关配置让用户自己决定消息要保存多久，这样为消费者提供了更
灵活的处理方式，因此 Kafka 能够在没有性能损失的情况下提供一般消息系统不具备的特性 。

# 工作流


- Producers定期向Topic发送消息
- Broker确保消息在分区之间平均分享,如果制作者发送两条消息并且有两个分区，则Kafka将在第一个分区中存储一条消息，并在第二个分区中存储第二条消息。
- Consumers订阅特定Topic
- 当消费者订阅了一个主题，Kafka将向消费者提供该主题的当前偏移量，并且还将该偏移量保存在Zookeeper集合中。
- Consumers 定期pull message
- Kafka收到生产者的消息后，会将这些消息转发给消费者
- 消费者将收到消息并进行处理
- 当消息被处理，消费者将向Broker**发送确认**。
- Kafka收到确认后，会将偏移量更改为新值并在Zookeeper中更新它。 由于在Zookeeper中维护了偏移量，因此即使在服务器繁忙期间，使用者也可以正确读取下一条消息。
- 循环以上
- 消费者可以随时选择倒带/跳至期望的主题偏移量并阅读所有后续消息


