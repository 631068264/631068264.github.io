---
layout:     post
rewards: false
title:      数据
categories:
    - quant
tags:
    - 量化系统
---

# 大量回测数据
- 用二进制文件分日期分股票存储
- 使用sql server，pg这样支持分区表的事务型数据库
- 使用hive这样的离线数据仓库
- 用**Greenplum**这样的开源或商业MPP数据仓库
- kdb+和**DolphinDB**这样的专业时序数据库。 效率高

Greenplum和DolphinDB支持的比较好，**支持库内计算**，不需要移动数据，速度很快。其它的存储方法可以考虑写一个跟通用计算引擎**spark**的适配器，
然后用spark来实现分布式SQL和分布式机器学习，但**性能上会比库内计算差不少**。

如果涉及到分布式计算，或者需要多次迭代，数据本身有可能是动态变化的，**数据的一致性**也要注意。**一般数据仓库本身提供的库内计算，能提供快照级别的隔离**，
保证计算过程总用到的所有数据是一致的。Greenplum和DolphinDB都支持快照级别隔离。Spark不能工作在动态数据上。


# 数据

- 日K单表mysql
- 分钟及Tick数据日期分表存储添加了普通索引

# 交易

- 普通限价下单 主要用于普通的策略回测，
- 拆单限价下单（TWAP及VWAP） 更多用于策略扩大规模时的容量测试，
- 智能优化下单（只限定报单量，由算法自动根据当前市场状态优化报单价格）更多地是与策略本身解耦，单独进行测试，并在实盘中选择是否使用。

## 下单方法
### TWAP

适用于流动性较好的市场和订单规模较小的交易。TWAP(Time Weighted Average Price)，时间加权平均价格算法。**该模型将交易时间进行均匀分割，并在每个分割节点上等量拆分订单进行提交。**


使交易对**市场影响减小**的同时提供一个**较低的平均成交价格**，从而达到**减小交易成本**的目的。在分时成交量无法准确估计的情况下，该模型可以较好地实现算法交易的基本目的。
**订单规模很大**的情况下，均匀分配到每个节点上的下单量仍然较大，当市场流动性不足时仍可能对市场造成一定的冲击。

真实市场的成交量总是在波动变化的，将所有的订单均匀分配到每个节点上显然是不够合理的。

### VWAP

**拆分大额委托单，在约定时间段内分批执行**，以期使得最终买入或卖出**成交均价尽量接近这段时间内整个市场成交均价**的交易策略。
VWAP(Volume Weighted Average Price)，成交量加权平均价格算法，

![](https://ws4.sinaimg.cn/large/006tKfTcly1g1ptaxezufj31hc04yjra.jpg)

VWAP模型的目的就是使得在指定时间段所执行的订单的VWAP值 <= 市场上相应时间段的VWAP值。
从VWAP的定义公式看，如果希望VWAP(实际)能足够接近VWAP(理论)，则需要将拆分订单按**照市场真实的成交量分时按比例**提交，这就需要对**市场分时成交量(成交量比例)进行预测**
**将总单拆分成多少单，分别以怎样的时间频率交易**

VWAP算法交易的目的是最小化冲击成本，并不寻求最小化所有成本

### PoV

用实际成交量作为指标，因此在交易时段内总是按照市场成交量的一定比例交易剩余的头寸.


