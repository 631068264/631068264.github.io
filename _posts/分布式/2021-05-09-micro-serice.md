---
layout:     post
rewards: false
title:      微服务
categories:
    - 分布式
tags:
    - 分布式
---

![](https://tva1.sinaimg.cn/large/008i3skNgy1gqbzgiqi44j30zk0k00tk.jpg)

![](https://tva1.sinaimg.cn/large/008i3skNgy1gqbzgnj3kqj30zk0k0gms.jpg)

![](https://tva1.sinaimg.cn/large/008i3skNgy1gqbzgytvt9j30ug0u0gmk.jpg)

- 注册中心：注册并维护远程服务及服务提供者的地址，供服务消费者发现和调用，为保证可用性，通常基于分布式 kv 存储器来实现，比如 zookeeper、etcd 等；
- 服务框架：用于实现微服务的 RPC 框架，包含服务接口描述及实现方案、向注册中心发布服务等功能，常见的 RPC 框架包括 Spring Cloud、Dubbo、gRPC、 Thrift、go-micro 等；
- 服务网关：介于客户端与微服务之间的网关层，可以理解为「门卫」的角色，以确保服务提供者对客户端的透明，这一层可以进行反向路由、安全认证、灰度发布、日志监控等前置动作；
- 服务监控：对服务消费者与提供者之间的调用情况进行监控和数据展示；
- 服务追踪：记录对每个请求的微服务调用完整链路，以便进行问题定位和故障分析；
- 服务治理：服务治理就是通过一系列的手段来保证在各种意外情况下，服务调用仍然能够正常进行，这些手段包括熔断、隔离、限流、降级、负载均衡等。
- 基础设施：分布式消息队列、日志存储、数据库、缓存、文件服务器、搜索集群等，用以提供服务底层的基础数据服务，可以自建，也可以使用阿里云等公有云提供的服务。



# 服务拆分

- 以业务模型切入：比如产品，用户，订单为一个模型来切入
- 演进式拆分：刚开始不要划分太细，可以随着迭代过程来逐步优化
- 避免环形依赖与双向依赖：尽量不要做服务之间的循环依赖

**具体操作**

- 调整代码结构，分析模块间依赖

  -  一个聚合的代码直接访问另一个聚合的代码或数据表
  -  单元测试代码混杂在一起
  -  跨聚合查询的SQL语句

- 消除业务代码依赖
  - 同时依赖一个工具类，独立出来，最后可以复制到两个服务
  - 上游系统依赖下游系统的接口，需要分析是否上游系统的业务概念中有缺失信息
  - 下游系统通过接口实现数据库实体嵌套，需要分析下游系统是否需要保存这么多上游系统的信息

- 添加测试保护
  - 是否有足够的测试来保护我们的改动
  - 函数级别的单元测试
  - 接口级别的测试





# 依赖消除

![img](https://tva1.sinaimg.cn/large/008i3skNgy1grcul8azm9j30ml09sgm1.jpg)

**循环依赖危害**

- 服务之间的调用没有约束导致的，耦合性非常强，以”微服务“为设计目标的系统会逐渐演变成一个**分布式大单体**。
- 循环调用或并发问题，造成一些复杂难以定位的问题



**消除循环依赖的基本思路**

- 定义服务上下游关系，下游服务可以直接依赖上游服务，反之则不可
- 上游服务的变更对下游服务产生影响需要通过**异步**（消息队列，缓存等）的方式来实现，此时各个微服务之间不再是强一致性，而是基于**事件的最终一致性**
- 服务之间要通过数据 Id（或类 Id，能够唯一代表数据且不变的属性）来进行关联，尽量不做过多的数据冗余
- 一旦需要上游服务调用下游服务才能完成业务时，要考虑是否上游服务缺少业务概念
- 为满足前端逻辑而导致的服务间交互逻辑要放到 BFF（Backend for frontend）中，而不是增加服务间的调用

- 上移、下移

  两个相互依赖组件中的交互部分抽象出来形成一个新的组件，而新组件同时包含着原有两个组件的引用，这样就把循环依赖关系剥离出来并上升到一个更高层次的组件中，**通过在两个相互循环依赖的组件之间添加中间层，变循环依赖为间接依赖。**


# Backends for frontends 网关

这种模式是针对不同的客户端来实现一个不同的 API 网关，也就是「用于前端的后端」（Backends for frontends，检查 BFF）模式，对应的架构图

![](https://tva1.sinaimg.cn/large/008i3skNgy1gqc59d3vuzj30sg0lcmzy.jpg)

# 注册中心

服务的发布和订阅，当你通过服务提供者提供了一个新的服务，如何让服务消费者感知呢？这个时候就需要一个类似注册中心的角色，服务提供者将自己提供的服务以及 IP 地址登记到注册中心，服务消费者则从注册中心查询所需要调用服务的地址信息，然后发起网络请求。



- 服务提供者在启动时，根据服务发布文件中配置的发布信息向注册中心注册自己的服务。
- 服务消费者在启动时，根据消费者配置文件中配置的服务信息向注册中心订阅自己所需要的服务。
- 注册中心返回服务提供者地址列表给服务消费者。
- 当服务提供者发生变化，比如有节点新增或者销毁，注册中心将变更通知给服务消费者。



1. 当 `GreeterService` 服务端启动时，会向 Consul 发送一个 POST 请求，告诉 Consul 自己的 IP 和端口；
2. Consul 接收到 `GreeterService` 的注册请求后，每隔 10s（默认）会向 `GreeterService` 发送一个健康检查的请求，检验 `GreterService` 是否有效（心跳检测）；
3. 当客户端以 HTTP 接口方式发送 GET 请求 `/greeter/say/hello` 到 `GreeterService` 时，会先从 Consul 中拿到一个存储对应服务 IP 和端口的临时表，并从表中查询 `GreeterService` 的 IP 和端口，再发送 GET 方式请求到 `/greeter/say/hello`。该临时表每隔 10s 会更新，只包含有通过了健康检查的 Service。此外，为了提高性能和系统可用性，往往会缓存服务信息到本地，如果服务部署在多个机器，还会使用负载均衡算法选择指定服务端通信。



传入指定服务名称，再通过默认 Registry 实现 Consul 获取对应的服务实例列表并缓存。应用过滤器后最后通过默认负载均衡实现（这里是 Random 算法）返回指定节点，获取到远程服务实例节点后，就可以发起远程服务请求了，发起远程网络请求（通过协程实现），如果请求处理出错则返回相应错误信息，然后对服务调用成功与否通过 Selector 的 Mark 函数进行标记（以便后续对服务进行监控和治理）如果服务调用失败，则进行重试或报错处理

# 服务框架

- 服务通信采用什么协议？就是说服务提供者和服务消费者之间以什么样的协议进行网络通信，是采用四层 TCP、UDP 协议，还是采用七层 HTTP 协议，还是采用其他协议？
- 数据传输采用什么方式？就是说服务提供者和服务消费者之间的数据传输采用哪种方式，是同步还是异步，是在单连接上传输，还是多路复用。
- 数据压缩采用什么格式？通常数据传输都会对数据进行压缩，来减少网络传输的数据量，从而减少带宽消耗和网络传输时间，比如常见的 JSON 序列化、Java 对象序列化以及 Protobuf 序列化等。

# 服务监控

一旦服务消费者与服务提供者之间能够正常发起服务调用，你就需要对调用情况进行监控，以了解服务是否正常。通常来讲，服务监控主要包括三个流程。

- 指标收集。就是要把每一次服务调用的请求耗时以及成功与否收集起来，并上传到集中的数据处理中心。
- 数据处理。有了每次调用的请求耗时以及成功与否等信息，就可以计算每秒服务请求量、平均耗时以及成功率等指标。
- 数据展示。数据收集起来，经过处理之后，还需要以友好的方式对外展示，才能发挥价值。通常都是将数据展示在 Dashboard 面板上，并且每隔 10s 等间隔自动刷新，用作业务监控和报警等。

# 服务追踪

除了需要对服务调用情况进行监控之外，你还需要记录服务调用经过的每一层链路，以便进行问题追踪和故障定位。

服务追踪的工作原理大致如下：

- 服务消费者发起调用前，会在本地按照一定的规则生成一个 requestid，发起调用时，将 requestid 当作请求参数的一部分，传递给服务提供者。
- 服务提供者接收到请求后，记录下这次请求的 requestid，然后处理请求。如果服务提供者继续请求其他服务，会在本地再生成一个自己的 requestid，然后把这两个 requestid 都当作请求参数继续往下传递。
- 以此类推，通过这种层层往下传递的方式，一次请求，无论最后依赖多少次服务调用、经过多少服务节点，都可以通过最开始生成的 requestid 串联所有节点，从而达到服务追踪的目的。

要实现链路跟踪，每次服务调用会在 HTTP 的 HEADERS 中记录至少记录四项数据：

- traceId：traceId 标识一个用户请求的调用链路。具有相同 traceId 的调用属于同一条链路。
- spanId：标识一次服务调用的ID，即链路跟踪的节点 ID。
- parentId：父节点的 spanId。
- requestTime & responseTime：请求时间和响应时间。

# 服务治理

服务监控能够发现问题，服务追踪能够定位问题所在，而解决问题就得靠服务治理了。服务治理就是通过一系列的手段来保证在各种意外情况下，服务调用仍然能够正常进行。

在生产环境中，你应该经常会遇到下面几种状况。

- 单机故障。通常遇到单机故障，都是靠运维发现并重启服务或者从线上摘除故障节点。然而集群的规模越大，越是容易遇到单机故障，在机器规模超过一百台以上时，靠传统的人肉运维显然难以应对。而**服务治理可以通过一定的策略，自动摘除故障节点，不需要人为干预，就能保证单机故障不会影响业务**。
- 单 IDC 故障。你应该经常听说某某 App，因为施工挖断光缆导致大批量用户无法使用的严重故障。而服务治理可以通过自动切换故障 IDC 的流量到其他正常 IDC，可以避免因为单 IDC 故障引起的大批量业务受影响。
- 依赖服务不可用。比如你的服务依赖依赖了另一个服务，当另一个服务出现问题时，会**拖慢甚至拖垮你的服务。而服务治理可以通过熔断，在依赖服务异常的情况下，一段时期内停止发起调用而直接返回。这样一方面保证了服务消费者能够不被拖垮，另一方面也给服务提供者减少压力，使其能够尽快恢复。**



## 熔断

调用链出问题

下游系统本身就出现了问题，不断的请求又把系统问题加重了，恢复困难

上游有问题可能会拖慢下游整个进度增加了整个链路的请求时间

熔断模式可以防止应用程序不断地尝试可能超时和失败的服务

![](https://tva1.sinaimg.cn/large/008i3skNgy1grfslkb09ej30te0x575s.jpg)

## 降级

解决资源不足和访问量增加的矛盾

停止不重要的功能，从而释放出更多的资源

## 限流

根据一定的用户规则进行拒绝策略

降级甚至关掉后台的某些服务

利用队列把请求缓存住。削峰填谷。

流量就像进入漏斗中的水一样，而出去的水和我们系统处理的请求一样，当流量大于漏斗的流出速度，就会出现积水，水对了会溢出。

漏斗很多是用一个队列实现的，当流量过多时，队列会出现积压，队列满了，则开始拒绝请求。



常见的限流算法有：令牌桶、漏桶。计数器也可以进行粗暴限流实现。

漏桶(Leaky Bucket)算法思路很简单,水(请求)先进入到漏桶里,漏桶以一定的速度出水(接口有响应速率),当水流入速度过大会直接溢出(访问频率超过接口响应速率),然后就拒绝请求,可以看出漏桶算法能强行限制数据的传输速率.示意图如下:

![](https://tva1.sinaimg.cn/large/008i3skNgy1gqoxmx57ihj30cb08b0sp.jpg)

令牌桶算法(Token Bucket)和 Leaky Bucket 效果一样但方向相反的算法,更加容易理解.随着时间流逝,系统会按恒定1/QPS时间间隔(如果QPS=100,则间隔是10ms)往桶里加入Token(想象和漏洞漏水相反,有个水龙头在不断的加水),如果桶已经满了就不再加了.新请求来临时,会各自拿走一个Token,如果没有Token可拿了就阻塞或者拒绝服务.

![](https://tva1.sinaimg.cn/large/008i3skNgy1gqoxn8gjf0j30bp06p3yh.jpg)

令牌桶的另外一个好处是可以方便的改变速度. 一旦需要提高速率,则按需提高放入桶中的令牌的速率. 一般会定时(比如100毫秒)往桶中增加一定数量的令牌, 有些变种算法则实时的计算应该增加的令牌的数量.