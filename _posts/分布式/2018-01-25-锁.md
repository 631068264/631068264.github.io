---
layout:     post
rewards: false
title:      锁
categories:
    - mysql
---

# InnoDB 排他锁
* for update仅适用于InnoDB，且必须在事务块(BEGIN/COMMIT)中才能生效。
* 其他线程对该记录的更新与删除操作都会阻塞
* 排他锁包含行锁、表锁 (没有用到索引引起表锁  还有like <> )
* 部分条件符合也会针对索引字段锁上(会做成多行锁) 只有所有条件完全不符合的时候才不会上锁

# 一致性解决方案
## 悲观锁

加排他锁 适合写入频繁的场景
```
begin;
select * from goods where id = 1 for update;
update goods set stock = stock - 1 where id = 1;
commit;
```

## 乐观锁
乐观锁方案：每次获取商品时，不对该商品加锁。在更新数据的时候需要比较程序中的库存量与数据库中的库存量是否相等，如果相等则进行更新，反之程序重新获取库存量，再次进行比较，直到两个库存量的数值相等才进行数据更新。乐观锁适合读取频繁的场景

```
#不加锁获取 id=1 的商品对象
select * from goods where id = 1

begin;
#更新 stock 值，这里需要注意 where 条件 “stock = cur_stock”，只有程序中获取到的库存量与数据库中的库存量相等才执行更新
update goods set stock = stock - 1 where id = 1 and stock = cur_stock;
commit;
```

# 共享锁

获准共享锁的事务只能读数据，不能写。 共享锁下其它用户可以并发读取，查询数据。但不能修改，增加，删除数据。

# 排它锁

若事务T对数据对象A加上X锁，则只允许T读取和修改A，其他任何事务都不能再对A加任何类型的锁，直到T释放A上的锁

# 间隙锁



- Record lock：单个行记录上的锁
- Gap lock：间隙锁，锁定一个范围，不包括记录本身
- Next-key lock：record+gap 锁定一个范围，包含记录本身



- innodb对于行的查询使用next-key lock
- Next-locking keying为了解决Phantom Problem幻读问题
- 当查询的索引含有唯一属性时，将next-key lock降级为record key
- Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生
- 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1

间隙锁是innodb中行锁的一种， 但是这种锁锁住的却不止一行数据，他锁住的是多行，是一个数据范围。间隙锁的主要作用是为了防止出现幻读，但是它会把锁定范围扩大，有时候也会给我们带来麻烦。



间隙锁会封锁该条记录相邻两个键之间的空白区域，防止其它事务在这个区域内插入、修改、删除数据，这是为了防止出现 幻读 现象,**只会阻塞insert操作**；

避免更新或者删除不存在的记录，虽然更新存在的记录也会产生间隙锁，但是间隙锁锁住的范围会更小；更新不存在的记录会锁住意想不到的区间范围，极其容易导致死锁问题

唯一索引

1. 对于指定查询某一条记录的加锁语句，**如果该记录不存在，会产生记录锁和间隙锁，如果记录存在，则只会产生记录锁**，如：WHERE `id` = 5 FOR UPDATE;
2. 对于查找某一范围内的查询语句，会产生间隙锁，如：WHERE `id` BETWEEN 5 AND 7 FOR UPDATE;
3. 唯一索引只有锁住多条记录或者一条不存在的记录的时候，才会产生间隙锁，指定给某条存在的记录加锁的时候，只会加记录锁，不会产生间隙锁

普通索引

1. 在普通索引列上，**不管是何种查询，只要加锁，都会产生间隙锁，这跟唯一索引不一样；**
2. 在普通索引跟唯一索引中，数据间隙的分析，数据行是优先根据普通索引排序，再根据唯一索引排序。

![](https://tva1.sinaimg.cn/large/008i3skNgy1gqs8dj8eukj30c20fkglq.jpg)



# 分布式锁

## redis

setnx命令，意思就是 set if not exist，如果lockKey不存在，把key存入Redis，保存成功后如果result返回1，表示设置成功，如果非1，表示失败，别的线程已经设置过了。

expire，设置过期时间，防止死锁，假设，如果一个锁set后，一直不删掉，那这个锁相当于一直存在，产生死锁。

setnx与expire不是一个原子操作 如果程序执行完第一步后异常了，第二步expire没有得到执行，相当于这个锁没有过期时间，有产生死锁的可能。正对这个问题如何改进

set key value nx px sec



判断锁与解锁 非原子  也可以value是特殊的value, value不对就不删了

A 执行完，判断key exist，key expire, B get lock，A del key 。=> A把B的lock解了。

```lua
//lua脚本删除key原子操作
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```



你的线程执行时间超过ttl过期时间，用来给快要过期的锁“续航”





Rdis只保证最终一致性，副本间的数据复制是异步进行（Set是写，Get是读，Reids集群一般是读写分离架构，存在主从同步延迟情况），主从切换之后可能有部分数据没有复制过去可能会「丢失锁」情况，故强一致性要求的业务不推荐使用Reids，推荐使用zk。

Redis集群各方法的响应时间均为最低。随着并发量和业务数量的提升其响应时间会有明显上升（公有集群影响因素偏大），但是极限qps可以达到最大且基本无异常



操作失败后，需要轮询，占用cpu资源;

锁删除失败 过期时间不好控制

## zk

Zookeeper 的有序节点

- 永久节点：不会因为会话结束或者超时而消失

- 临时节点：如果会话结束或者超时就会消失 

- 有序节点：会在节点名的后面加一个数字后缀，并且是有序的，例如生成的有序节点为 /lock/node-0000000000，它的下一个有序节点则为 /lock/node-0000000001，依次类推

创建一个锁目录 /lock。 在 /lock 下创建**临时的且有序的子节点**（临时的就不会死锁），

第一个客户端对应的子节点为 /lock/lock-0000000000，第二个为 /lock/lock-0000000001，以此类推。
客户端获取 /lock 下的子节点列表，判断自己创建的子节点**是否为当前子节点列表中序号最小的子节点**，如果是则认为获得锁。
否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁。 执行业务代码，完成后，删除对应的子节点。



使用ZooKeeper集群，锁原理是使用ZooKeeper的临时节点，临时节点的生命周期在Client与集群的Session结束时结束。因此如果某个Client节点存在网络问题，与ZooKeeper集群断开连接，Session超时同样会导致锁被错误的释放（导致被其他线程错误地持有），因此ZooKeeper也无法保证完全一致。

ZK具有较好的稳定性；响应时间抖动很小，没有出现异常。但是随着并发量和业务数量的提升其响应时间和qps会明显下降




# 事务

事务具有4个特性：原子性、一致性、隔离性、持久性。这四个属性通常称为 ACID 特性。

- **原子性（atomicity）：**一个事务应该是一个不可分割的工作单位，事务中包括的操作要么都成功，要么都不成功。
- **一致性（consistency）：**事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。
- **隔离性（isolation）：**一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据在事务未提交前对并发的其他事务是隔离的，并发执行的各个事务之间不能互相影响。
- **持久性（durability）：**一个事务一旦成功提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。

## 并发事务存在问题

**脏读**

脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。



**不可重复读**

不可重复读是指在对于数据库中的某条数据，一个事务范围内多次查询返回不同的数据值(这里不同是指某一条或多条数据的内容前后不一致，但数据条数相同)，这是由于在查询间隔，该事务需要用到的数据被另一个事务修改并提交了。

**不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了其他事务提交的数据。需要注意的是在某些情况下不可重复读并不是问题。**



**幻读**

幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。

而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。

幻读和不可重复读都是读取了另一条已经提交的事务(这点就脏读不同)，所不同的是不可重复读可能发生在update,delete操作中，而幻读发生在insert操作中。



# 在事务中存在以下几种隔离级别

**读未提交(Read Uncommitted)**

解决更新丢失问题。如果一个事务已经开始写操作，那么其他事务则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现，即事务需要对某些数据进行修改必须对这些数据加 X 锁，读数据不需要加 S 锁。

**读已提交(Read Committed)**

解决了脏读问题。读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。这可以通过“瞬间共享读锁”和“排他写锁”实现， 即事务需要对某些数据进行修改必须对这些数据加 X 锁，读数据时需要加上 S 锁，当数据读取完成后立刻释放 S 锁，不用等到事务结束。

**可重复读取(Repeatable Read)**

禁止不可重复读取和脏读取，但是有时可能出现幻读数据。读取数据的事务将会禁止写事务(但允许读事务)，写事务则禁止任何其他事务。

Mysql默认使用该隔离级别。这可以通过“共享读锁”和“排他写锁”实现，即事务需要对某些数据进行修改必须对这些数据加 X 锁，读数据时需要加上 S 锁，当数据读取完成并不立刻释放 S 锁，而是等到事务结束后再释放。

**串行化(Serializable)**

解决了幻读的问题的。提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，不能并发执行。仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。



# 分布式事务

**分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上**。例如在大型电商系统中，下单接口通常会扣减库存、减去优惠、生成订单 id, 而订单服务与库存、优惠、订单 id 都是不同的服务，下单接口的成功与否，不仅取决于本地的 db 操作，而且依赖第三方系统的结果，这时候分布式事务就保证这些操作要么全部成功，要么全部失败。本质上来说，**分布式事务就是为了保证不同数据库的数据一致性。**



## 一致性

- 强一致性

  **任何一次读都能读到某个数据的最近一次写的数据**。系统中的所有进程，看到的操作顺序，都和全局时钟下的顺序一致。简言之，在任意时刻，所有节点中的数据是一样的。

- 弱一致性

  数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性。

- 最终一致性

  不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。简单说，就是在一段时间后，节点间的数据会最终达到一致状态。

## CAP

- **一致性（Consistence）**

  在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）

- **可用性（Availability）**

  每一个操作总是能够在**一定的时间**内**返回结果**(对数据更新具备高可用性)

- **分区容错性（Partition tolerance）**

  分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。

  这里的网络分区是指由于某种原因，网络被分成若干个孤立的区域，而区域之间互不相通。




## XA协议的两阶段提交（2PC）

存在一个负责协调各个本地资源管理器的**事务管理器**，**本地资源管理器**一般是由数据库实现，

事务管理器在第一阶段的时候询问各个资源管理器是否都就绪？如果收到每个资源的回复都是 yes，则在第二阶段提交事务，如果其中任意一个资源的回复是 no, 则回滚事务。

<img src="https://tva1.sinaimg.cn/large/008i3skNgy1grgg6soh4gj30xn0u0gol.jpg" style="zoom: 45%;" />

- 第一阶段（prepare）：事务管理器向所有本地资源管理器发起请求，询问是否是 ready 状态，所有参与者都将本事务能否成功的信息反馈发给协调者；
- 第二阶段 (commit/rollback)：事务管理器根据所有本地资源管理器的反馈，通知所有本地资源管理器，步调一致地在所有分支上提交或者回滚。



**缺点**

> 同步阻塞：当参与事务者存在占用公共资源的情况，其中一个占用了资源，其他事务参与者就只能阻塞等待资源释放，处于阻塞状态。

> 单点故障：一旦事务管理器出现故障，整个系统不可用

> 数据不一致：在阶段二，如果事务管理器只发送了部分 commit 消息，此时网络发生异常，那么只有部分参与者接收到 commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。

> 不确定性：当协事务管理器发送 commit 之后，并且此时只有一个参与者收到了 commit，那么当该参与者与事务管理器同时宕机之后，重新选举的事务管理器无法确定该条消息是否提交成功。

## TCC

Try-Confirm-Cancel

1. 解决了协调者单点，由主业务方发起并完成这个业务活动。业务活动管理器也变成多点，引入集群。
2. 同步阻塞：引入超时，超时后进行补偿，并且不会锁定整个资源，将资源转换为业务逻辑形式，粒度变小。
3. 数据一致性，有了补偿机制之后，由业务活动管理器控制一致性



- Try 阶段：

  尝试执行，完成所有业务检查（一致性）, 预留必须业务资源（准隔离性）

- Confirm 阶段：

  确认执行真正执行业务，不作任何业务检查，只使用 Try 阶段预留的业务资源，Confirm 操作满足幂等性。要求具备幂等设计，Confirm 失败后需要进行重试。

- Cancel 阶段：

  取消执行，释放 Try 阶段预留的业务资源 Cancel 操作满足幂等性 Cancel 阶段的异常和 Confirm 阶段异常处理方案基本上一致。

基于 TCC 实现分布式事务，会将原来只需要一个接口就可以实现的逻辑拆分为 Try、Confirm、Cancel 三个接口，所以代码实现复杂度相对较高。



## 本地消息表

![](https://tva1.sinaimg.cn/large/008i3skNgy1grggt09425j30xc0feq3m.jpg)

- A（消息生产方）**需要额外建一个消息表，并记录消息发送状态**

  同一数据库同一事务操作

  - 更新数据库的业务表
  - 更新消息表

- 消息会经过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送。
- B 消费 MQ 中的消息，并处理业务逻辑。
  - 如果本地事务处理失败，会在继续消费 mq 中的消息进行重试
  - 如果业务上的失败，生产方发送一个业务补偿消息，可以通知系统 A 进行回滚操作

- 生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一遍。

## kafka事务

![](https://tva1.sinaimg.cn/large/008i3skNgy1grgifspiixj30v50erjrt.jpg)

- 上图中的 Transaction Coordinator 运行在 Kafka 服务端，下面简称 TC 服务。

- __transaction_state 是 TC 服务持久化事务信息的 topic 名称，下面简称事务 topic。

- Producer 向 TC 服务发送的 commit 消息，下面简称事务提交消息。

- TC 服务向分区发送的消息，下面简称事务结果消息。

### 事务场景

- **生产者发送多条消息可以封装在一个事务中，形成一个原子操作。**多条消息要么都发送成功，要么都发送失败。
- **read-process-write模式：将消息消费和生产封装在一个事务中，形成一个原子操作。**在一个流式处理的应用中，常常一个服务需要从上游接收消息，然后经过处理后送达到下游，这就对应着消息的消费和生成。



- [kafka系列九、kafka事务原理、事务API和使用场景](https://www.cnblogs.com/wangzhuxing/p/10125437.html)

- [Kafka 事务实现原理](https://zhmin.github.io/2019/05/20/kafka-transaction/)

