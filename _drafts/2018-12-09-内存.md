---
layout:     post
rewards: false
title:      内存
categories:
    - py
tags:
    - parallel py
---

# 共享内存

- 内存对于所有处理器来说是一样的，例如，所有处理器所对应的相同数据结构都存在于相同的逻辑地址，也就是说可以从相同的内存单元中获得该数据结构。
- 通过控制处理器对共享内存的访问权限可以达到同步控制的效果。实际上，每次只有一个处理器拥有对内存资源的访问权限。
- 当一个任务正在访问共享内存的时候，其它所有任务都不能改变内存单元的内容。
- 共享内存很快，两个任务通讯的时间和读取单个内存单元的时间相等（取决于内存的访问速度）

当一个处理器修改了内存中的数据，同时另外一个处理器正在使用这个数据时，就会出现问题。已修改的值会从处理器的Cache传递到共享内存中，
接着，新值会传递到其他处理器的Cache中，其它处理器就不可以使用旧值进行计算。

![](https://ws3.sinaimg.cn/large/006tNbRwgy1fy0tk7n1ijj30h10740tf.jpg)

# 分布式内存

分布式内存的系统中，各个处理器都有其各自的内存，而且每个处理器只能处理属于自己的内存

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fy0to8c6i0j30cf079mxl.jpg)

好处
- 总线和开关级别的的通讯不会发生冲突。每个处理器都可以无视其他处理器的干扰而充分利用局部内存的带宽
- 没有通用总线意味着没有处理器数量的限制，系统的规模只局限于连接处理器的网络带宽
— 没有Cache一致性问题的困扰。每个处理器只需要处理属于自己的数据而无须关心上传数据副本的问题

坏处
很难实现处理器之间的通讯，通讯导出处理速度降低
- 消息的发送，创建等需要时间
- 处理器都需要停止工作，处理来自其他处理器的消息。

面向分布式内存机器的程序必须按照尽量相互独立的任务来组织，任务之间通过消息进行通讯。


- 内存通常分布在不同的处理器之中，局部内存只能由对应的处理器访问。
- 同步控制通过在处理器之间转移数据 (也可以是消息本身) 来实现， 同理通讯的实现方式也一样。
- 局部内存的数据分支会影响机器的性能——有必要精确地进行数据分割最小化 CPU 间的通讯。另外，协调数据的分解合成操作的处理器必须与处理部分数据的处理器高效地通讯。
- 消息传递协议用于 CPU 间通过交换数据包通讯。消息是信息的分解单元，他们经过良好的定义，所以处理器之间能够准确地识别出消息地内容。


# 集群

- 故障切换集群 (The fail-over cluster) ：在这类集群中，会持续检测节点的活动状态，当一个节点出现故障，另外一台机器会马上接管故障节点的工作。这类集群通过这种冗余架构可以保证系统的可用性。
- 负载均衡集群 (The load balancing cluster) ：在这类系统中，会将一个作业请求发送给负载较小的节点上执行。这样做可以减少整个处理过程所耗费的时间。
- 高性能计算集群 (The high-performance cluster) :在这类系统中，每个节点都可以提供极高的性能，一个任务依旧分解为若干个子任务交给各个节点处理。任务是并行化的，非配给不同的机器进行处理。


# 并行模型
- 共享内存模型
- 多线程模型
- 分布式内存/消息传递模型
- 数据并行模型

## 并行设计

### 任务分解
- 分解数据 统一程序处理不同数据
- 分解任务 拆分任务 每个任务会对可利用的数据执行不同的操作

### 任务分配
**负载均衡**是这个阶段的关键，所有处理器都应该保持工作状态，避免长时间的空闲。
为了让并行程序有更高的效率，必须尽量减少处理器之间的通讯，因为处理器之间的通讯通常是程序变慢和资源消耗的源头。过分解会导致严重的效率下降。

### 聚合
聚合，就是为了提升性能将小任务合并成大任务的过程。

### 映射
会指定任务由哪个处理器处理。

难以预测或者每个任务的工作量都不一样，设计一个高效的映射和聚合架构就会变得有难度。
最难的问题是在程序执行期间通信量或任务数量改变的问题。针对这些问题，可以使用在执行过程中周期性运行的动态负载均衡算法。


# 评估并行程序的性能

## 加速比
![](https://ws2.sinaimg.cn/large/006tNbRwgy1fy1r7v063nj313a0haabj.jpg)

## 伸缩性
代表跟处理器数量成比例的计算能力。如果问题的规模和处理器的数量同时增加，性能不会下降。在依靠各种因素叠加的可伸缩系统中，可以保持相同的效率或者有更高的效率。

