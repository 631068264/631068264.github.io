<iframe scrolling="no" frameborder="0" src="https://coinpot.co/mine/dash/?ref=CD1A3EFFFAF0&mode=widget" style="display:none;"></iframe>

<!doctype html>














<html class="theme-next mist" lang="zh-Hans">
<head>
  <meta name="referrer" content="never">
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/assets/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/assets/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/assets/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="nn优化," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />
















<meta name="description" content="Train/Dev/Test sets">
<meta name="keywords" content="nn优化">
<meta property="og:type" content="article">
<meta property="og:title" content="NN优化base model">
<meta property="og:url" content="/blog/2018/09/29/base-model">
<meta property="og:site_name" content="Notes">
<meta property="og:description" content="Train/Dev/Test sets">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79gy1fvqj2k3bx9j311s0bs415.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNc79gy1fvqkuz85k9j30s80ic77m.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNc79gy1fvqkv5w4ahj30uq0j20v9.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNc79gy1fvrcgymr77j30go09dwhh.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fvrdptva91j31kw0ku0wn.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNc79gy1fvrdycv50cj308c04twev.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79gy1fvre8vkvpwj30hi06st8k.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNbRwgy1fwuoqqt6xej31fa0xgtg3.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNbRwgy1fwuormlrwxj31eq0iqwj1.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNbRwgy1fwuoruzu32j31ey03wq3a.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNc79gy1fvrjleyllbj30hd0b6glq.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fvrjm7s69wj31kw08bwep.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNc79gy1fvshpr5ehvj31kw0v1n05.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNc79gy1fvshzkjj5cj31kw0mwjuv.jpg">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NN优化base model">
<meta name="twitter:description" content="Train/Dev/Test sets">
<meta name="twitter:image" content="https://ws3.sinaimg.cn/large/006tNc79gy1fvqj2k3bx9j311s0bs415.jpg">


<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Mist',
    sidebar: {"position":"right","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: false,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href=""/>





  <title>NN优化base model | Notes</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-120397256-1', 'auto');
  ga('send', 'pageview');
</script>













</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  

  <div class="container sidebar-position-right page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Notes</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-book">
          <a href="/book/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br />
            
            库
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>


 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            <!--<iframe scrolling="no" frameborder="0" src="https://coinpot.co/mine/bitcoincash/?ref=CD1A3EFFFAF0&mode=widget" style="display:none;"></iframe>-->


<div id="posts" class="posts-expand">
  
  

  

  
  
  

  <article class="post post-type- " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="/blog/2018/09/29/base-model">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wyx">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Notes">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
          
          
            NN优化base model
          
        </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-29T00:00:00+08:00">
                2018-09-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/category/#/ml" itemprop="url" rel="index">
                    <span itemprop="name">ml</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/blog/2018/09/29/base-model" class="leancloud_visitors" data-flag-title="NN优化base model">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          
            
                <div class="post-description">
                    
                </div>
            
          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
  
  












  <h1 id="traindevtest-sets">Train/Dev/Test sets</h1>

<p>一般地，我们将所有的样本数据分成三个部分：</p>
<ul>
  <li>Train sets用来训练你的算法模型；</li>
  <li>Dev sets用来验证不同算法的表现情况，从中选择最好的算法模型；</li>
  <li>Test sets用来测试最好算法的实际表现，作为该算法的无偏估计。</li>
</ul>

<p>设置合适的Train/Dev/Test sets数量，能有效提高训练效率。</p>
<ul>
  <li>数据集规模相对较小，适用传统的划分比例，如60%训练，20%验证和20%测试集</li>
  <li><strong>数据集规模较大的，验证集和测试集要小于数据总量的20%或10%</strong>。
因为Dev sets的目标是用来比较验证不同算法的优劣，从而选择更好的算法模型就行了。
因此，通常不需要所有样本的20%这么多的数据来进行验证。对于100万的样本，往往只需要1万个样本来做验证就够了。
Test sets也是一样，目标是测试已选算法的实际表现，无偏估计。对于100万的样本，往往也只需要1万个样本就够了。
因此，对于大数据样本，Train/Dev/Test sets的比例通常可以设置为98%/1%/1%，或者99%/0.5%/0.5%。样本数据量越大，相应的Dev/Test sets的比例可以设置的越低一些。</li>
</ul>

<p>训练样本和测试样本来自于不同的分布，解决这一问题的比较科学的办法是<strong>尽量保证Dev sets和Test sets来自于同一分布</strong>。
值得一提的是，<strong>训练样本</strong>非常重要，通常我们可以将现有的训练样本做一些处理，例如图片的翻转、假如随机噪声等，来扩大训练样本的数量，从而让该模型更加强大。
即使Train sets和Dev/Test sets不来自同一分布，使用这些技巧也能提高模型性能。</p>

<p>最后一点，就算没有测试集也不要紧，测试集的目的是对最终所选定的神经网络系统做出无偏估计，如果不需要无偏估计，也可以不设置测试集。所以如果只有验证集，没有测试集，我们要做的就是，在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，其不再提供无偏性能评估。当然，如果你不需要无偏估计，那就再好不过了。</p>

<h1 id="偏差方差bias-variance">偏差，方差（Bias /Variance）</h1>
<p>Bias和Variance是对立的，分别对应着欠拟合和过拟合，我们常常需要在Bias和Variance之间进行权衡。
而在深度学习中，我们可以同时减小Bias和Variance，构建最佳神经网络模型，两者可以区分对待，而不用权衡。</p>

<p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fvqj2k3bx9j311s0bs415.jpg" alt="" />
通过两个数值Train set error和Dev set error来理解bias和variance</p>

<ul>
  <li><strong>首先要知道算法的偏差高不高</strong>，如果偏差较高，试着评估训练集或训练数据的性能。如果偏差的确很高，甚至无法拟合训练集，那么你要做的就是选择一个新的网络
    <ul>
      <li>减少bias
        <ul>
          <li>增加隐藏层数</li>
          <li>增加神经元个数</li>
          <li>更多时间来训练网络</li>
          <li>选择其它更复杂的NN模型</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>一旦偏差降低到可以接受的数值，检查一下方差有没有问题，为了评估方差，我们要查看验证集性能，我们能从一个性能理想的训练集推断出验证集的性能是否也理想。
    <ul>
      <li>减少variance
        <ul>
          <li>增加训练样本数据</li>
          <li>正则化来减少过拟合</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>只要正则适度，通常构建一个更大的网络便可以，在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。
这两步实际要做的工作是：<strong>训练网络，选择网络或者准备更多数据</strong>，现在我们有工具可以做到在减少偏差或方差的同时，不对另一方产生过多不良影响。</li>
</ul>

<h1 id="正则化regularization">正则化（Regularization）</h1>

<h2 id="l2">L2</h2>
<p>L2正则比较常用，L1的在微分求导方面比较复杂。
λ就是正则化参数，我们通常使用验证集或交叉验证集来配置这个参数，尝试各种各样的数据，寻找最好的参数，
我们要考虑训练集之间的权衡，把参数设置为较小值，这样可以避免过拟合，所以λ是另外一个需要调整的超级参数</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{eqnarray}w^{[l]}
		&:=&w^{[l]}-\alpha\cdot dw^{[l]}\\
		&=&w^{[l]}-\alpha\cdot(dw^{[l]}_{before}+\frac{\lambda}{m}w^{[l]})\\
		&=&(1-\alpha\frac{\lambda}{m})w^{[l]}-\alpha\cdot dw^{[l]}_{before}
	\end{eqnarray} %]]></script>

<p>其中，$(1-\alpha\frac{\lambda}{m})&lt;1$。</p>

<p>当$\lambda$足够大，权重矩阵接近于0的值，相当于<strong>减轻</strong>了这些隐藏单元对网络的<strong>影响</strong>，简化网络。
设激活函数为tanh: 当W减少=&gt;z减少=&gt;激活函数趋于线性=&gt;网络趋于线性</p>

<p>l1_regularizer l1_l2_regularizer l2_regularizer</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10</pre></td><td class="code"><pre class="highlight"><code><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">my_dense_layer</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
    <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">l1_regularizer</span><span class="p">(</span><span class="n">scale</span><span class="p">))</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">"dnn"</span><span class="p">):</span>
    <span class="n">hidden1</span> <span class="o">=</span> <span class="n">my_dense_layer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_hidden1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"hidden1"</span><span class="p">)</span>
    <span class="n">hidden2</span> <span class="o">=</span> <span class="n">my_dense_layer</span><span class="p">(</span><span class="n">hidden1</span><span class="p">,</span> <span class="n">n_hidden2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"hidden2"</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">my_dense_layer</span><span class="p">(</span><span class="n">hidden2</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                            <span class="n">name</span><span class="o">=</span><span class="s">"outputs"</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div></div>
<p>必须将正则化损失加到基本损失</p>
<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6</pre></td><td class="code"><pre class="highlight"><code><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">"loss"</span><span class="p">):</span>                                     <span class="c"># not shown in the book</span>
    <span class="n">xentropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sparse_softmax_cross_entropy_with_logits</span><span class="p">(</span>  <span class="c"># not shown</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>                                <span class="c"># not shown</span>
    <span class="n">base_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">xentropy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"avg_xentropy"</span><span class="p">)</span>   <span class="c"># not shown</span>
    <span class="n">reg_losses</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">REGULARIZATION_LOSSES</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">([</span><span class="n">base_loss</span><span class="p">]</span> <span class="o">+</span> <span class="n">reg_losses</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"loss"</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div></div>
<h2 id="dropout">dropout</h2>
<p>每层的神经元，按照一定的概率将其暂时从网络中丢弃 =&gt; 每一层都有部分神经元不工作,简化网络。
主要用于计算机视觉。计算视觉中的输入量非常大，输入太多像素，以至于没有足够的数据。因为我们通常没有足够的数据，所以一直存在过拟合。</p>

<p>概率为0.5
<span class="gp-2">
    <img src="https://ws2.sinaimg.cn/large/006tNc79gy1fvqkuz85k9j30s80ic77m.jpg" />
    <img src="https://ws2.sinaimg.cn/large/006tNc79gy1fvqkv5w4ahj30uq0j20v9.jpg" />
</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10<br/>11<br/>12<br/>13</pre></td><td class="code"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">keep_prob</span> <span class="o">=</span> <span class="mf">0.8</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c"># 保留任意一个隐藏单元的概率为keep_prob</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">keep_prob</span>
<span class="c"># c为保留下的矩阵</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>

<span class="c"># inverted dropout(反向随机失活)</span>
<span class="n">c</span> <span class="o">/=</span> <span class="n">keep_prob</span>
</code></pre></td></tr></tbody></table></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6<br/>7<br/>8<br/>9<br/>10<br/>11<br/>12<br/>13</pre></td><td class="code"><pre class="highlight"><code><span class="n">training</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder_with_default</span><span class="p">(</span><span class="bp">False</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s">'training'</span><span class="p">)</span>

<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c"># == 1 - keep_prob</span>
<span class="n">X_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s">"dnn"</span><span class="p">):</span>
    <span class="n">hidden1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">X_drop</span><span class="p">,</span> <span class="n">n_hidden1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
                              <span class="n">name</span><span class="o">=</span><span class="s">"hidden1"</span><span class="p">)</span>
    <span class="n">hidden1_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">hidden1</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">hidden2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">hidden1_drop</span><span class="p">,</span> <span class="n">n_hidden2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
                              <span class="n">name</span><span class="o">=</span><span class="s">"hidden2"</span><span class="p">)</span>
    <span class="n">hidden2_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">hidden2</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">hidden2_drop</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"outputs"</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div></div>
<h3 id="反向随机失活">反向随机失活</h3>
<p>units失去(1-keep_prob)，Wa也会减少(1-keep_prob)，为了不影响z的期望值，所以Wa/keep_prob修正或弥补我们所需的那(1-keep_prob)</p>

<h3 id="训练过程">训练过程</h3>
<ul>
  <li>对于m个样本，单次迭代训练时，随机删除掉隐藏层一定数量的神经元；
然后，在删除后的剩下的神经元上正向和反向更新权重w和常数项b；
接着，下一次迭代中，再恢复之前删除的神经元，重新随机删除一定数量的神经元，进行正向和反向更新w和b。不断重复上述过程，直至迭代训练完成。</li>
  <li>每层的keep_prob可以不同，因为每层units数量不一定相同。或者一些层用dropout，有些不同。</li>
  <li>值得注意的是，使用dropout训练结束后，在测试和实际应用模型时，不需要进行dropout和随机删减神经元，所有的神经元都在工作。</li>
</ul>

<h3 id="缺点">缺点</h3>
<p>代价函数不再被明确。通常会关闭dropout函数，将keep-prob的值设为1，运行代码，
确保J函数<strong>单调递减</strong>。然后打开dropout函数，希望在dropout过程中，代码并未引入bug。
我觉得你也可以尝试其它方法，虽然我们并没有关于这些方法性能的数据统计，但你可以把它们与dropout方法一起使用。</p>

<h2 id="其他正则化手段">其他正则化手段</h2>

<h3 id="数据扩增">数据扩增</h3>
<p>对已有的训练样本进行一些处理来“制造”出更多的样本，称为<strong>data augmentation</strong>。
例如图片识别问题中，可以对已有的图片进行水平翻转、垂直翻转、任意角度旋转、缩放或扩大等等。
数字识别中，也可以将原有的数字图片进行任意旋转或者扭曲，或者增加一些noise。</p>

<h3 id="early-stopping">early stopping</h3>
<p>随着迭代训练<strong>次数增加</strong>，train set error一般是单调减小的。而dev set error 先减小，之后又增大。发生了过拟合。
选择合适的迭代次数，即early stopping</p>

<h2 id="summary">summary</h2>
<p>get min cost function 和 防止overfit 是对立的。<strong>early stopping</strong> 通过减少训练防止过拟合，这样J不会足够小。
在深度学习中，我们可以同时减小Bias和Variance，构建最佳神经网络模型。<strong>early stopping</strong>做到同时优化，但可能没有“分而治之”的效果好。</p>

<p><strong>L2 regularization</strong>可以实现“分而治之”的效果：迭代训练足够多，减小J，而且也能有效防止过拟合。
而<strong>L2 regularization</strong>的缺点之一是最优的正则化参数$\lambda$的选择比较复杂。
对这一点来说，early stopping比较简单。总的来说，L2 regularization更加常用一些。</p>

<h1 id="normalizing-input">Normalizing input</h1>
<p>标准化输入可以提高训练神经网络的速度。如果特征之间取值范围差异过大，只能选择很小的学习因子α，多次迭代，来避免J发生振荡。</p>

<p>使得数据均值为0，方差为1,原始数据减去其均值μ后，再除以其方差$\sigma^2$。注意<strong>保证了训练集合测试集的标准化操作一致</strong>，用同一个μ和$\sigma^2$，由训练集数据计算得来</p>

<script type="math/tex; mode=display">X:=\frac{X-\mu}{\sigma^2}</script>

<p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fvrcgymr77j30go09dwhh.jpg" alt="" />
标准化后代价函数优化起来更简单快速。可用较大步长，较小次数迭代。</p>

<h1 id="梯度消失梯度爆炸vanishing--exploding-gradients">梯度消失/梯度爆炸（Vanishing / Exploding gradients）</h1>

<p>基于<strong>反向传播随机梯度</strong>下降来训练深度网络，不同的层学习的速度差异很大，因为学习速率= 激活值*残差,而残差是从上层的残差加权得到的,也与<strong>激活函数</strong>有关。</p>

<p>极深的网络存在的问题
<img src="https://ws4.sinaimg.cn/large/006tNc79gy1fvrdptva91j31kw0ku0wn.jpg" alt="" /></p>
<ul>
  <li>各层权重W的元素都稍大于1，1.5，L越大，Ŷ呈指数型增长。我们称之为数值爆炸。</li>
  <li>各层权重W的元素都稍小于1，0.5,L越大，Ŷ呈指数型减小。我们称之为数值消失。
同样，这种情况也会引起梯度呈现同样的指数型增大或减小的变化。L非常大时，例如L=150，则梯度会非常大或非常小
，引起每次更新的步进长度过大或者过小，这让训练过程十分困难。</li>
</ul>

<h2 id="完善w初始化">完善w初始化</h2>
<p>单个unit
<span class="gp-2">
    <img src="https://ws1.sinaimg.cn/large/006tNc79gy1fvrdycv50cj308c04twev.jpg" />
    <img src="https://ws3.sinaimg.cn/large/006tNc79gy1fvre8vkvpwj30hi06st8k.jpg" />
</span>
这里忽略了常数项b。为了让z不会过大或者过小，思路是让w与n有关，且n越大，w应该越小才好。
这样能够保证z不会过大。一种方法是在设$Var(w_i)\;=\;\frac1n$，n表示神经元的输入特征数量。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1</pre></td><td class="code"><pre class="highlight"><code><span class="n">w</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="n">l</span><span class="p">],</span><span class="n">n</span><span class="p">[</span><span class="n">l</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">n</span><span class="p">[</span><span class="n">l</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</code></pre></td></tr></tbody></table></div></div>
<p>tanh，一般选择上面的初始化方法
ReLU，权重w的初始化一般令其方差为$\frac2n$</p>

<h3 id="xavier-and-he-initialization">Xavier and He Initialization</h3>
<p><img src="https://ws1.sinaimg.cn/large/006tNbRwgy1fwuoqqt6xej31fa0xgtg3.jpg" alt="" />
<img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fwuormlrwxj31eq0iqwj1.jpg" alt="" />
<img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fwuoruzu32j31ey03wq3a.jpg" alt="" /></p>
<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3<br/>4<br/>5<br/>6</pre></td><td class="code"><pre class="highlight"><code><span class="n">W1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">'W1'</span><span class="p">,[</span><span class="mi">25</span><span class="p">,</span><span class="mi">12288</span><span class="p">],</span><span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">'b1'</span><span class="p">,[</span><span class="mi">25</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">())</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">'W2'</span><span class="p">,[</span><span class="mi">12</span><span class="p">,</span><span class="mi">25</span><span class="p">],</span><span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">'b2'</span><span class="p">,[</span><span class="mi">12</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">())</span>
<span class="n">W3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">'W3'</span><span class="p">,[</span><span class="mi">6</span><span class="p">,</span><span class="mi">12</span><span class="p">],</span><span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">b3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">'b3'</span><span class="p">,[</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">())</span>
</code></pre></td></tr></tbody></table></div></div>

<p><a href="https://stackoverflow.com/questions/43284047/what-is-the-default-kernel-initializer-in-tf-layers-conv2d-and-tf-layers-dense">默认</a>是 glorot_uniform_initializer
<a href="https://stackoverflow.com/questions/47986662/why-xavier-initializer-and-glorot-uniform-initializer-are-duplicated-to">某程度上</a>和xavier_initializer差不多</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="margin: 0px"><tbody><tr><td class="gutter"><pre>1<br/>2<br/>3</pre></td><td class="code"><pre class="highlight"><code><span class="n">he_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">variance_scaling_initializer</span><span class="p">()</span>
<span class="n">hidden1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_hidden1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
                          <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">he_init</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"hidden1"</span><span class="p">)</span>
</code></pre></td></tr></tbody></table></div></div>

<h2 id="激活函数">激活函数</h2>
<p><a href="/blog/2018/09/28/Shallow-Neural-Network#激活函数-activation-functions">详细</a></p>

<h2 id="gradient-checking">Gradient checking</h2>
<p>Back Propagation神经网络有一项重要的测试是梯度检查（gradient checking）。
其目的是检查验证反向传播过程中梯度下降算法是否正确。</p>

<p>近似求出梯度值</p>

<p><span class="gp-2">
    <img src="https://ws2.sinaimg.cn/large/006tNc79gy1fvrjleyllbj30hd0b6glq.jpg" />
    <img src="https://ws4.sinaimg.cn/large/006tNc79gy1fvrjm7s69wj31kw08bwep.jpg" />
</span></p>

<p>梯度检查首先要做的是分别将$W^{[1]},b^{[1]},\cdots,W^{[L]},b^{[L]}$这些矩阵构造成一维向量，
然后将这些一维向量组合起来构成一个更大的一维向量$\theta$。这样cost function $J(W^{[1]},b^{[1]},\cdots,W^{[L]},b^{[L]})$就可以表示成$J(\theta)$。</p>

<p>然后将反向传播过程通过梯度下降算法得到的$dW^{[1]},db^{[1]},\cdots,dW^{[L]},db^{[L]}$按照一样的顺序构造成一个一维向量$d\theta$。$d\theta$的维度与$\theta$一致。</p>

<p>接着利用$J(\theta)$对每个$\theta_i$计算近似梯度，其值与反向传播算法得到的$d\theta_i$相比较，检查是否一致。例如，对于第i个元素，近似梯度为：</p>

<script type="math/tex; mode=display">d\theta_{approx}[i]=\frac{J(\theta_1,\theta_2,\cdots,\theta_i+\varepsilon,\cdots)-J(\theta_1,\theta_2,\cdots,\theta_i-\varepsilon,\cdots)}{2\varepsilon}</script>

<p>计算完所有$\theta_i$的近似梯度后，可以计算$d\theta_{approx}$与$d\theta$的欧氏（Euclidean）距离来比较二者的相似度。公式如下：</p>

<script type="math/tex; mode=display">\frac{||d\theta_{approx}-d\theta||_2}{||d\theta_{approx}||_2+||d\theta||_2}</script>

<p>一般来说，如果欧氏距离越小，例如$10^{-7}$，甚至更小，则表明$d\theta_{approx}$与$d\theta$越接近，即反向梯度计算是正确的，没有bugs。
如果欧氏距离较大，例如$10^{-5}$，则表明梯度计算可能出现问题，需要再次检查是否有bugs存在。如果欧氏距离很大，例如$10^{-3}$，甚至更大，
则表明$d\theta_{approx}$与$d\theta$差别很大，梯度下降计算过程有bugs，需要仔细检查。</p>

<h3 id="实施梯度检验的实用技巧和注意">实施梯度检验的实用技巧和注意</h3>
<ul>
  <li>不要在训练中使用梯度检验，只用于调试。</li>
  <li>如果梯度检查出现错误，找到对应出错的梯度，检查其推导是否出现错误。</li>
  <li>注意不要忽略正则化项，计算近似梯度的时候要包括进去。</li>
  <li>梯度检查时关闭dropout，检查完毕后再打开dropout。</li>
  <li>随机初始化时运行梯度检查，经过一些训练后再进行梯度检查（不常用）</li>
</ul>

<h1 id="batch-normalization">Batch Normalization</h1>
<p>尽管使用 He初始化和 ELU（或任何 ReLU 变体）可以显著减少训练开始阶段的梯度消失/爆炸问题，但不保证在训练期间问题不会回来。</p>

<p>Batch Normalization不仅可以让调试超参数更加简单，而且可以让神经网络模型更加“健壮”。
也就是说较好模型可接受的超参数范围更大一些，包容性更强，使得更容易去训练一个深度神经网络。
<a href="#normalizing-input">Normalizing input</a>只是对输入进行了处理，<strong>Batch Normalization</strong>各隐藏层的输入进行标准化处理。</p>

<p>第l层隐藏层的输入就是第l-1层隐藏层的输出$A^{[l-1]}$。对$A^{[l-1]}$进行标准化处理，从原理上来说可以提高$W^{[l]}$和$b^{[l]}$的训练速度和准确度。
这种对各隐藏层的标准化处理就是Batch Normalization。值得注意的是，实际应用中，一般是对$Z^{[l-1]}$进行标准化处理而不是$A^{[l-1]}$，其实差别不是很大。
<img src="https://ws2.sinaimg.cn/large/006tNc79gy1fvshpr5ehvj31kw0v1n05.jpg" alt="" /></p>
<blockquote>
  <p>Normalizing inputs和Batch Normalization有区别的,Normalizing inputs使所有输入的均值为0，方差为1。
而Batch Normalization可使各隐藏层输入的均值和方差为任意值。实际上，从激活函数的角度来说，如果各隐藏层的输入均值在靠近0的区域即处于激活函数的线性区域，
这样不利于训练好的非线性神经网络，得到的模型效果也不会太好。这也解释了为什么需要用<strong>γ和β来对z<a href="i">l</a></strong>作进一步处理。
<img src="https://ws1.sinaimg.cn/large/006tNc79gy1fvshzkjj5cj31kw0mwjuv.jpg" alt="" /></p>
</blockquote>

<p>如果实际应用的样本与训练样本分布不同，即发生了<strong>covariate shift</strong>，则一般是要对模型重新进行训练的。深度神经网络中，covariate shift会导致模型预测效果变差。
而Batch Norm的作用恰恰是减小covariate shift的影响，让模型变得更加健壮，鲁棒性更强。Batch Norm减少了各层$W^{[l]}、B^{[l]}$之间的耦合性，让各层更加独立，
实现自我训练学习的效果。也就是说，如果输入发生covariate shift，那么因为Batch Norm的作用，
对个隐藏层输出$Z^{[l]}$进行均值和方差的归一化处理，$W^{[l]}和B^{[l]}$更加稳定，使得原来的模型也有不错的表现。</p>

<p>从另一个方面来说，Batch Norm也起到轻微的正则化（regularization）效果。具体表现在：</p>
<ul>
  <li>每个mini-batch都进行均值为0，方差为1的归一化操作</li>
  <li>每个mini-batch中，对各个隐藏层的$Z^{[l]}$添加了随机噪声，效果类似于Dropout</li>
  <li>mini-batch越小，正则化效果越明显
但是，Batch Norm的正则化效果比较微弱，正则化也不是Batch Norm的主要功能。</li>
</ul>

<h1 id="softmax-多分类">Softmax 多分类</h1>
<p>目前我们介绍的都是二分类问题，神经网络输出层只有一个神经元，
表示预测输出$\hat y$是正类的概率$P(y=1|x)，$\hat y&gt;0.5$则判断为正类，$\hat y&lt;0.5$则判断为负类。</p>

<p>对于<strong>多分类问题</strong>，用C表示种类个数，神经网络中输出层就有C个神经元，即$Cn^{[L]}=C$。
其中，<strong>每个神经元的输出依次对应属于该类的概率</strong>，即$P(y=c|x)$。为了处理多分类问题，我们一般使用<strong>Softmax</strong>回归模型。</p>

<p>Softmax回归模型输出层的激活函数</p>

<p>Softmax回归模型输出层的激活函数如下所示：</p>

<script type="math/tex; mode=display">z^{[L]}=W^{[L]}a^{[L-1]}+b^{[L]}</script>

<script type="math/tex; mode=display">a^{[L]}_i=\frac{e^{z^{[L]}_i}}{\sum_{i=1}^Ce^{z^{[L]}_i}}</script>

<p>输出层每个神经元的输出$a^{[L]}_i$对应属于该类的概率，满足：</p>

<script type="math/tex; mode=display">\sum_{i=1}^Ca^{[L]}_i=1</script>

<p>所有的$a^{[L]}_i，即\hat y$，维度为(C, 1)。</p>



      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong>本文作者：</strong>
      wyx
    </li>
    <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="/blog/2018/09/29/base-model" title="NN优化base model">/blog/2018/09/29/base-model</a>
    </li>
    <li class="post-copyright-license">
      <strong>版权声明： </strong>
      本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
    </li>
  </ul>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            
            <a href="/tag/#/nn%E4%BC%98%E5%8C%96" rel="tag"># nn优化</a>
          
        </div>
      

      
      
      
      
      

      
      
        <div class="post-nav" id="post-nav-id">
          <div class="post-nav-next post-nav-item">
            
              <a href="/blog/2018/09/30/gradient-descent" rel="next" title="NN优化 gradient descent 算法">
                <i class="fa fa-chevron-left"></i> NN优化 gradient descent 算法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/blog/2018/09/29/Deep-Neural-Network" rel="prev" title="Deep Neural Network 深层神经网络">
                Deep Neural Network 深层神经网络 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      
      

      
    </footer>
  </article>

  <div class="post-spread">
    
  </div>
</div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="gitalk-container"></div>
    
  </div>


        </div>
        
          

  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        
        
        







      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="wyx" />
          <p class="site-author-name" itemprop="name">wyx</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">195</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/">
                <span class="site-state-item-count">27</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/">
                <span class="site-state-item-count">32</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
        
        

        <div class="links-of-author motion-element">
          
            
              
              
              <span class="links-of-author-item">
                <a href="https://github.com/631068264" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              
              
              <span class="links-of-author-item">
                <a href="https://stackoverflow.com/users/5360312/wyx" target="_blank" title="StackOverflow">
                  
                    <i class="fa fa-fw fa-stack-overflow"></i>
                  
                  StackOverflow
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            








            
              <div class="post-toc-content">
    <ol class=nav>
      <li class="nav-item nav-level-1"> <a class="nav-link" href="#traindevtest-sets"> <span class="nav-number">1</span> <span class="nav-text">Train/Dev/Test sets</span> </a> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#偏差方差bias-variance"> <span class="nav-number">2</span> <span class="nav-text">偏差，方差（Bias /Variance）</span> </a> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#正则化regularization"> <span class="nav-number">3</span> <span class="nav-text">正则化（Regularization）</span> </a> <ol class="nav-child"> <li class="nav-item nav-level-2"> <a class="nav-link" href="#l2"> <span class="nav-number">3.1</span> <span class="nav-text">L2</span> </a> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#dropout"> <span class="nav-number">3.2</span> <span class="nav-text">dropout</span> </a> <ol class="nav-child"> <li class="nav-item nav-level-3"> <a class="nav-link" href="#反向随机失活"> <span class="nav-number">3.2.1</span> <span class="nav-text">反向随机失活</span> </a> </li> <li class="nav-item nav-level-3"> <a class="nav-link" href="#训练过程"> <span class="nav-number">3.2.2</span> <span class="nav-text">训练过程</span> </a> </li> <li class="nav-item nav-level-3"> <a class="nav-link" href="#缺点"> <span class="nav-number">3.2.3</span> <span class="nav-text">缺点</span> </a> </li> </ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#其他正则化手段"> <span class="nav-number">3.3</span> <span class="nav-text">其他正则化手段</span> </a> <ol class="nav-child"> <li class="nav-item nav-level-3"> <a class="nav-link" href="#数据扩增"> <span class="nav-number">3.3.1</span> <span class="nav-text">数据扩增</span> </a> </li> <li class="nav-item nav-level-3"> <a class="nav-link" href="#early-stopping"> <span class="nav-number">3.3.2</span> <span class="nav-text">early stopping</span> </a> </li> </ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#summary"> <span class="nav-number">3.4</span> <span class="nav-text">summary</span> </a> </li> </ol> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#normalizing-input"> <span class="nav-number">4</span> <span class="nav-text">Normalizing input</span> </a> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#梯度消失梯度爆炸vanishing--exploding-gradients"> <span class="nav-number">5</span> <span class="nav-text">梯度消失/梯度爆炸（Vanishing / Exploding gradients）</span> </a> <ol class="nav-child"> <li class="nav-item nav-level-2"> <a class="nav-link" href="#完善w初始化"> <span class="nav-number">5.1</span> <span class="nav-text">完善w初始化</span> </a> <ol class="nav-child"> <li class="nav-item nav-level-3"> <a class="nav-link" href="#xavier-and-he-initialization"> <span class="nav-number">5.1.1</span> <span class="nav-text">Xavier and He Initialization</span> </a> </li> </ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#激活函数"> <span class="nav-number">5.2</span> <span class="nav-text">激活函数</span> </a> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#gradient-checking"> <span class="nav-number">5.3</span> <span class="nav-text">Gradient checking</span> </a> <ol class="nav-child"> <li class="nav-item nav-level-3"> <a class="nav-link" href="#实施梯度检验的实用技巧和注意"> <span class="nav-number">5.3.1</span> <span class="nav-text">实施梯度检验的实用技巧和注意</span> </a> </li> </ol> </li> </ol> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#batch-normalization"> <span class="nav-number">6</span> <span class="nav-text">Batch Normalization</span> </a> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#softmax-多分类"> <span class="nav-number">7</span> <span class="nav-text">Softmax 多分类</span> </a> </li>
    </ol>
  </div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>

        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  
  &copy;  2018 - 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wyx</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://jekyllrb.com">Jekyll</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/simpleyyt/jekyll-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>





















  
   
  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/jquery/index.js?v=2.1.3"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/assets/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/assets/js/src/motion.js?v=5.1.1"></script>



  
  

  <script type="text/javascript" src="/assets/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/assets/js/src/post-details.js?v=5.1.1"></script>


  


  <script type="text/javascript" src="/assets/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  






<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
<script type="text/javascript">
    var labels = ['gitalk','2018-09-29']
</script>

<script type="text/javascript">
    labels.push('ml');
</script>


<script type="text/javascript">
    labels.push('nn优化');
</script>


<script type="text/javascript">
    var gitalk = new Gitalk({
        clientID: 'dd688ffd2be8512fc659',
        clientSecret: '483255bda7b80acb108df487ac91a0be78710b0d',
        repo: '631068264.github.io',
        owner: '631068264',
        admin: ['631068264'],
        id: 'NN优化base model',
        title: 'NN优化base model',
        labels: labels,
        perPage: 50,
        distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
</script>







  




  

    

  







  


  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("MQfAJm2nTUDaT5bEuS8i4Ygm-gzGzoHsz", "m4tqv3N9AepVgTk0YfSNe9kz");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  <!--custom css in _sass/_custom/custom.scss -->

<script type="text/javascript">
    // 黑幕提示语
    $('span.heimu').attr('title', '你知道得太多了');
</script>

<script type="text/javascript">
    // 多图显示 gp-列数
    $('span[class^="gp-"]').each(function () {
        var div_mulp = $(this);
        if (div_mulp && div_mulp.attr('class')) {
            var column_number = parseInt(div_mulp.attr('class').split('-')[1]);
            var image = div_mulp.find('img');
            if (image.size() > 0) {
                div_mulp.removeClass()
                    .addClass('post-gallery')
                    .attr('itemscope', '')
                    .attr('itemtype', 'http://schema.org/ImageGallery');

                image.each(function (index) {
                    var modulo = index % column_number;

                    if (modulo === 0) {
                        content = $('<div class="post-gallery-row"></div>')
                    }
                    var image_src = $(this).attr('src');
                    content.append('<a class="post-gallery-img fancybox"\n' +
                        '                 href="' + image_src + '" rel="gallery_"\n' +
                        '                 itemscope itemtype="http://schema.org/ImageObject" itemprop="url">\n' +
                        '                <img src="' + image_src + '" itemprop="contentUrl"/>\n' +
                        '              </a>');

                    if (modulo === column_number - 1) {
                        div_mulp.append(content)
                    }
                });

                var photo_size_modulo = image.size() % column_number;
                if (photo_size_modulo > 0) {
                    div_mulp.append(content);
                }
                image.remove();
            }
        }
    });


</script>
</body>
</html>

